year,text
2019,hi im pretty sure its possible to define units equivalences from the userend but i cant find back how its done in the cookbook little help
2019,i dont actually think there is a public api to do that you may need to poke around in the code to figure this out
2019,in codesnippet im trying to write code that will automagically check what codesnippet version were on and then deal with the octrees accordingly is this reasonable as a check or is there a better way to discern in code if were on 3x or 4xcodesnippetif yt__version__ 40dev0 blahcodesnippet
2019,thatll break when yt40 comes out
2019,maybe just check the first digit of the version string
2019,you could also do what yt does internally for version checks
2019,hyperlink
2019,and just do less than and greater than comparisons
2019,id check to make sure looseversion does the right thing with the dev0 version number
2019,ah maybe i misremember something i saw as exposed when developing my frontend
2020,hi everyoneim using yt to run the rockstar halo finder is it somehow possible to output the particle data of each halo according to the rockstar users guide this is doable but i couldnt figure out how in yt thanks in advance for your support
2020,hi benedikt the version of rockstar that yt uses is a bit older and may not support this although it could be contained within the binary outputs yt doesnt currently have the capability to read it in that much i know for sureseparately rockstargalaxies the latest rockstar im aware of does output particles by default you have to run it standalone though
2020,user has joined the channel
2020,user hi and welcome im glad to see you here
2020,depending on the nature of your simulations this might be a useful tool written by user that can help you analyze rs outputhyperlink
2020,user has joined the channel
2020,user thank you very much
2018,hey folks im trying to create a particle field but for a derived particle field but it seems that i cant do that
2018,to be more precise i have a derived particle field named codesnippet which derives from codesnippet im trying to create a field called codesnippet but id like to avoid requiring codesnippet
2018,im confused this is a derived particle field but its deriving its quantities from a gridbased field ie codesnippet
2018,what does your field definition look like
2018,let me be more precise for now i have the raw particle codesnippet and a derived one codesnippet and id like to do the exact operation as a particleongrid deposition gridonparticle deposition so that i could access eg the temperature of the cell containing each codesnippet
2018,use a gist for the code
2018,im not sure we support that atm
2018,actually huh i think there is something that does something similar
2018,let me see if i can find the example
2018,you want to look at the codesnippet particle deposit operation
2018,presumably we could generalize that to allow getting the value of any field instead of just the grid id
2018,
2018,hyperlink there you go
2018,although i guess looking at it wed need to do a substantial refactor since theres no way to get field data there
2018,i think user had ideas about this i have vague memories of a conversation about something similar
2018,actually that was with me
2018,ah
2018,i gave a try at using codesnippet but never succeeded essentially i was a bit lost in that part of the code and couldnt ahve access to the the field data there
2018,yeah like i said wed need a substantial refactor to get that working
2018,i dont see anything obviously wrong in your code but youre doing something im pretty sure no one has tried before
2018,what goes wrong when you try to use this
2018,it works but let me show you the output
2018,codesnippetgt spgas_tracer cell_densityderived field io cell_density units mpcm3 particle field npart11180202 ncell1089077derived field io cell_density units mpcm3 particle field npart11180202 ncell1089077derived field io cell_density units mpcm3 particle field npart11180202 ncell1089077derived field io cell_density units mpcm3 particle field npart11180202 ncell1089077ytarray261569105e05 252232177e05 257807361e05 877901157e05 877901157e05 721347805e05 mpcm3codesnippet
2018,ok what am i supposed to see here
2018,the fact that there are multiple prints happening
2018,so the issue is only performancewise i only care about the 1e5 gas tracer particles but here its first sampling the cell on all the 1e7 io cells
2018,ah i see slightly_smiling_face
2018,thanks that clears things up
2018,and then i guess yt internally masks all but the gas tracers
2018,yeah
2018,codesnippet is implemented as a particle filter in the ramses frontend right
2018,yup
2018,im not sure offhand why its not giving you data for the particle filter in your derived field definition id need to poke at it with a debugger
2018,if you can make a runnable example i might be able to give more concrete advice
2018,_working on it_
2018,
2018,i posted a simple example on the channel
2018,note that in the example it is pointless as all the particles are stars
2018,so the relevant code is here
2018,hyperlink
2018,in this case codesnippet is the codesnippet field
2018,and then we do the filtering after generating the field data
2018,i guess in principle we dont need to do this for derived particle fields
2018,so maybe you need to modify this logic to only do this for ondisk particle fields
2018,mmh im going to drop a debugger there and see what is what
2018,user has joined the channel
2019,ok i feel like im missing something obvious how do i get the star formation rate _now_ doing like codesnippet gives me an array vs time but the most recent codesnippet is eg codesnippet not codesnippet
2019,hey is it possible to use a particle dataset loaded using codesnippet with codesnippet
2019,i dont think that works in yt3x it does work in yt40 user has an open pr that makes that workflow a lot more straightforward too
2019,user has joined the channel
2019,user has joined the channel
2019,im having trouble with installing yt in my home directory of a secure shell
2019,user how so
2020,hey codesnippet needs to be set as a field parameter for a data container in codesnippet the codesnippet function get called on a bunch of vector fields including velocity
2020,ah so if i read the tests correctly its up to the user to set the bulk velocity
2020,hey im trying to plot mass enclosed as a function of radius from different simulations on the same panel is this possible with yt
2020,yeah thats right
2020,user its possible to generate the values but probably better to grab them from the codesnippet and codesnippet attributes on multiple profile objects and use matplotlib directly
2020,thanks a lot
2020,user has joined the channel
2020,hi is anybody familiar with this error message
2020,max_hii_densityspmaxhii_density file homesslavcondaenvsytenvlibpython38sitepackagesytdata_objectsdata_containerspy line 789 in max rv self_compute_extremaf1 file homesslavcondaenvsytenvlibpython38sitepackagesytdata_objectsdata_containerspy line 755 in _compute_extrema mi ma selfquantitiesextremafield file homesslavcondaenvsytenvlibpython38sitepackagesytdata_objectsderived_quantitiespy line 542 in __call__ rv superextrema self__call__fields non_zero file homesslavcondaenvsytenvlibpython38sitepackagesytdata_objectsderived_quantitiespy line 69 in __call__ storesult selfprocess_chunkds args kwargs file homesslavcondaenvsytenvlibpython38sitepackagesytdata_objectsderived_quantitiespy line 549 in process_chunk field data_determine_fieldsfield0 file homesslavcondaenvsytenvlibpython38sitepackagesytdata_objectsdata_containerspy line 1165 in _determine_fields finfo selfds_get_field_infounknown fname file homesslavcondaenvsytenvlibpython38sitepackagesytdata_objectsstatic_outputpy line 798 in _get_field_info raise ytfieldnotfoundftype fname selfytutilitiesexceptionsytfieldnotfound could not find field all hii_density in redshift0045
2020,hi shai this means that the field codesnippet isnt in your dataset beware that the field names are casesensitive you can inspect the field names by running codesnippet or codesnippet where ds is the dataset object
2020,thank you this has been very helpful
2018,user thanks you are a life saver
2018,hi very quick question for a complete ytbeginner here what should the argument of codesnippet be all i found in the documentation is aa not really helpful but that seems like a rare exception
2018,i think its either set to codesnippet or codesnippet
2018,thanks
2018,a quick patch fixing that docstring would be a great first pull request if youre interested totally cool if youre not though
2018,sure thing im cloning the repo atm
2018,still having a little trouble getting my vector fields recognized i added the fields i want explicitly herehyperlink and it seems like that proceeds fine but then they arent included in the codesnippet later
2018,seems like theyre being set as invalid somewhere but i cant seem to track down where any ideas
2018,sorry not sure any chance you can make an example one of us could run to trigger the issue youre running into
2018,yup will do
2018,code hyperlink output hyperlink code diff hyperlink
2018,i feel like im just missing something simple but i dont have intuition right now about how yt sets up and checks the fields
2018,takes a look
2018,ok so theres basically lots of fiddly issues that your script is hitting
2018,im able to get it to work if i modify your script to look like this hyperlink
2018,your fields didnt have units that was one of the issues the field machinery inside yt was also expecting field names like codesnippet so i had to change that too
2018,i also needed to make a number of modifications to the yt codebase
2018,or really just one change i guess
2018,codesnippetdiff git aytfieldsfield_detectorpy bytfieldsfield_detectorpyindex ad908933ea3a73857c 100644 aytfieldsfield_detectorpy bytfieldsfield_detectorpy 2048 20412 class fielddetectordefaultdict return selffield_parametersparam selfrequested_parametersappendparam if param in center normal or paramstartswithbulk return selfdsarr nprandomrandom3 1e2 selffp_unitsparam try return selfdsarr nprandomrandom3 1e2 selffp_unitsparam except keyerror if paramendswithvelocity return selfdsarrnprandomrandom3 1e2 cms elif param in surface_height return selfdsquan00 code_length elif param in axiscodesnippet
2018,we recently made it so all the vector fields respect the codesnippet field parameters
2018,but in so doing made things a bit more restrictive so its harder to set up what youre looking for
2018,this should definitely be made easier and nicer i still think we need something like codesnippet or something like that
2018,that handles all this mess automatically
2018,user does that sound reasonable
2018,i think so
2018,so in the part that you added if you wanted to be able to define an arbitrary vector field youd have to add a section that sets up a corresponding bulk parameter with the correct units
2018,or wed need to add a way for codesnippet to optionally not insist on defining a relative version of the field
2018,really we need something like a field parameter registry that people can register field parameters with so the field detection system knows about them
2018,right now the field detection system has to basically guess about field parameter names and units that people might want to use
2018,got it
2018,user yes its 2d i tried changing line 4 to zgrid nparray0005
2018,user did that help
2018,hm i am not sure if i understand if viridisdatashape is a 3d array then how do i display this data with imshow or contourf or anything else i have put what i thought i understood in this gist hyperlink is there a way to attach my original rgb image
2018,you could save it as a png and upload it to eg imgur
2018,you wouldnt display an rgb image with contourf
2018,youd use the original greyscale image
2018,i think imshow handles rgba arrays out of the box
2018,well yes it shows it but then i still dont know how to link a colormap to this rgb image did a drag and drop to imgur can you see this hyperlink
2018,sure
2018,sorry im not sure what you mean by link a colormap
2018,sorry im having issues with my python installation so its hard for me to reproduce what youre seeing exactly
2018,one sec
2018,ah ok
2018,so in your gist codesnippet is already an rgba image array
2018,yes from the start
2018,so it doesnt make sense to apply a colormap to it
2018,do you not have the original grayscale image anymore
2018,no i do not
2018,ah i see
2018,so you want to back out the grayscale image from the rgba image
2018,sort of yes but the danger is when going through the grayscale there may be double values that are cancelled out
2018,why do you not have the original image anymore
2018,im not sure what youre doing is welldefined
2018,it might be i guess if you know the colormap
2018,so i am not sure if there is an uncomplicated an quick way to convert the colors back into real data and then be able to manipulate and display that data
2018,yeah i think ideally youd want to have saved the original grayscale image
2018,i think i remember seeing a talk about doing something like this at scipy years ago
2018,let me see if i can find the talk
2018,ok
2018,hyperlink
2018,i dont know offhand if that code ever made it into a usable package
2018,hyperlink
2018,ah very cool let me dig into this
2018,thank you
2018,sounds like this will only plug into python27 i have already switched to 35 though
2018,yeah it hasnt been updated since 2013 it looks like
2018,i dont know offhand if theres anything like it thats more recently updated
2018,is it possible to have 27 and 35 running at the same time or is this not advisable
2018,i used to do that
2018,recently i switched to using pyenv
2018,you can definitely do that although it might get confusing which python python refers to
2018,i have two anaconda setups though the 27 one is just so i can use hg for a certain project
2018,same
2018,how do i install yoink
2018,hyperlink as cited in the setuppy does not exist
2018,yeah i don
2018,i dont think its been touched in five years
2018,you probably need to clone the repo
2018,btw these arent really yt questions it might be best to take this to eg stackoverflow instead of the yt slack
2017,user has joined the channel
2018,user has joined the channel
2018,hi are vtr files supported by yt how can i try and use yt with vtr files
2018,user whats a codesnippet file
2018,visualization toolkit rectilinear grid data
2018,user yesfyi hyperlink
2018,i dont think yt can parse generic vtk datafiles we only support specific flavors created by computational codes eg athena
2018,we dont have support for that format no
2018,this is the second time in a month weve had a similar request though adding support for more generic cfd formats would be a great project
2018,thats a shame i dont think its too difficult to do though there is a vtk library hyperlink they have reader functions then i guess that data just need to be fed correctly into yt might try and hack something like this for my purpose
2018,an optional dependency on vtk would certainly be the easiest approach
2018,especially with the modularization it might even make sense to work more closely with vtk functions in some cases
2018,im trying to make a phase plot of codesnippet vs codesnippet for a sphere object its easy to do codesnippet vs codesnippet for the sphere object but its tricky to extend this to include the free fall time the reason is that freefall time cannot be calculate on the fly for each gas cell as it is dependent on the codesnippet so i can make a bunch of spheres of different radii to calculate t_ff as a sphericallysymmetric profile but im not sure how to feed that back into the yt infrastructure to make the original desired phase plot of codesnippet vs codesnippet any ideas on how to do this crazy feat
2018,user use the profiles accumulation argument to get the enclosed mass as a function of radius
2018,user if you use a profile youll get the enclosed spherically symmetric at the same points as a similarly spaced phase
2018,user thats useful i had forgotten about the accumulation kwarg thanks but is there a way to put that enclosed mass profile info back into the data for the phase plot the issue is that there is a diversity of stuff going on in the halo and i dont want to flatten it into a single radial profile and lose all the structure seen in a full phase plot vs radius but maybe that isnt possible
2018,i guess i could read out the phase plot info out of the plot and manually combine it with the profile data and then out it back into a pcolormesh mpl instance maybe hmm ill try and report back
2019,i seem to be having some trouble with ytreerockstarconsistent treesi am not sure this is the best place to ask butusing something like a ytreeloadrockstar_halosout_0list gives me nodes but then aprog only returns the original entry treenode generating merger trees with consistent trees and loading them via a ytreeloadtree_0_0_0dat fixes this problem and allows me to find progenitorsdescendants however for some reason this changes the mass position etc of the original rockstar halos and i can no longer figure out which treenodes correspond to the halos i was originally interested in this is not the case if i take the approach given abovecan anyone help with either issue
2019,is it possible to do volume rendering the data in a 3d numpy array the data is either continuous or segmented only 0 or 1 in 3d
2019,user has joined the channel
2018,hi just wondering for a ray data is there a simple to do the integration along the ray rayintegrate seems to only work along the cartesian axis
2018,user good question i believe you need to manually integrate rays you can get the length from the field codesnippet
2019,hey is there a way to use yts plotting machinery at somehow a lower level i have a bunch of particles that id like to plot
2019,however i want to change their position by adding some noise
2019,i guess you could reload the particles using load_particles i dont think theres a way to modify particle fields in memory yt plots need to be created using a dataset or a yt data object so youll need to figure out how to get your data in that format
2019,or dont use yts plotting system at all and just use matplotlib
2019,sometimes thats easier than trying to get yts plotting system to work in a way that it wasnt really intended
2019,ok
2019,it might be interesting to think of modifying existing fields at some point in the future user wanted to do this as well last week with the coordinate fields to affect a global coordinate transform could be interesting but seems like a pretty deep change
2019,in that vein of setting fields to rotate my coordinates im trying to access a field i set within another field im defining and its returning a value thats different from what i set when i print it outside the function it existscodesnippetadset_field_parameterrotation_vectors adprincipal_axes_vectorsadget_field_parameterrotation_vectorsarray464385979e01 291482979e01 836291418e01 708714933e01 443966940e01 548285053e01 531101502e01 847308108e01 406318212e04codesnippetthen within the function im definingcodesnippetdef _rotate_coordinatesfield data if datahas_field_parameterrotation_vectors printreading rotation vectors rv dataget_field_parameterrotation_vectorsin_unitscms else rv datadsarrnpeye3 printthe rotation vectors are rv return get_coordinates_rotateddatacoordinates rvcodesnippetwhich when i call codesnippet printscodesnippetyt info 20190326 142614139 allocating for 2002e08 particles index particle type allyt info 20190326 142659358 identified 1257e07 octsreading rotation vectorsthe rotation vectors are 00codesnippet
2019,ah so this is because field parameters need to be scalars
2019,unless its a limited set that we have specifically enumerated in yt that can be nonscalar
2019,basically during the field detection process yt needs to have dummy values for field parameters
2019,but for field parameters yt doesnt know about yet it cant guess values with the proper shape
2019,the real fix for this is to add a field parameter registry to yt
2019,but that would take some work and is well beyond what you want
2019,another way to fix this is to use a global variable instead of field parameters
2019,sorry this is confusing this is something weve seen from other people in the past
2019,see_no_evil do you know how i could get a precomputed rotation matrix into my function codesnippet
2019,yes using a global variable
2019,ah sorry just saw that
2019,also out of curiosity why do you want to do this with a field
2019,like whats your ultimate goal here
2019,its possible that whatever youre trying to do can be accomplished without rotating the data
2019,im trying to put the simulation into the same frame as the ananke synthetic gaia survey of a latte simulation which is defined by a pre computed center center velocity and rotation matrix and then an lsr center and velocity
2019,ok but what ultimately do you want to do that would be sensitive to how the dataset is rotated
2019,oh and then reconstruct the metallicity weighted gas density on a grid of positions around that position at the same positions im inferring what my model thinks the metallicity weighted gas density is
2019,i think you could do that with an offaxis slice
2019,i want to feed a grid of positions into my model and the latte simulation and compare my prediction with the truth
2019,whats an offaxis slice
2019,i guess we dont have an api for nonaxisaligned covering grids that would be worth adding at some point
2019,you can create yt slices at arbitrary angles to the coordinate axes
2019,i have the properly rotated particles in a python array can i somehow add that to a yt dataset
2019,ytload_particles
2019,it has to fit in memory though
2019,oh it fits in memory
2019,be sure to pass a smoothing_length field to load_particles so it gets recognized as sph data
2019,awesome will try this route slightly_smiling_face
2019,also i dont think it would be terribly hard to optionally let people rotate particle data eg by passing a rotation matrix to ytload or something i think for particle data this is a reasonable feature request
2019,does it make sense to consider a rotation matrix in the codesnippet fields so its translation rotation
2019,ah yeah thats a good point they already respect normal_vector
2019,so guess thats what user wants up to a rotation
2019,user i think the name we standardized on was codesnippet
2019,ah yeah i was thinking of that one but forgot the name
2019,this is probably not too difficult to implement
2019,that field knows about codesnippet and codesnippet so its already implemented
2019,i guess it could also respect codesnippet
2019,ah thats even easier just need to wire them all up
2019,i think this would be a really good idea and could probably be implemented without touching too many bits in the code
2019,user or user what type of kernel does codesnippet use for generating the field at each position on the grid im trying to understand how to convert the smoothing lengths output from fire simulations to make the calculation accurate
2019,the default is a cubic spline kernel but its configurable
2019,hyperlink
2019,although i dunno offhand if the ability to use alternate kernels is exposed at the moment in the highlevel interface
2019,user if it works codesnippet spline kernel should be used for gizmo theres also a subtlety that when doing spatial interpolation gizmos normalization is different from usual sph computationally it is similar to the gather method since gather is already implemented by user it might be worth adding this gizmo method too
2019,ah i was hoping to use the codesnippet method because its faster but youre suggesting i should stick to codesnippet for normalization issues
2019,how big is your dataset i mean gather is certainly slower but it isnt too slow
2019,for visualization purpose codesnippet should be fine if youd like to keep as close as possible to what gizmo code would do theres a need to slightly modify codesnippet its not in yt yet but it wont be too difficult to implement the heavylifting is already done in the codesnippet code
2019,what is the subtlety is this instead of taking the kth neighbour
2019,heres the equation normal gather assumes omegax 1
2019,and a visual comparison
2019,hyperlink
2019,ah i see i didnt realise the smoothing length calculation was different
2019,i use traditional gather when analysing arepo or sph data i never worry too much about it maybe i should worry more
2019,the addition of gather is already a great improvement probably the gather method could be modified to optionally switch to the gizmo normalization
2019,yeah i guess its something which we can just switch on if we detect the ds is gizmo
2019,user if you have time and would like to contribute to yt this might be worth taking a further look
2019,no worries if you just want to use the code wed happy to implement these if you need the functionality
2019,issue created hyperlink
2019,how would one compute the normalization is it simply the smooth number density of particles within the kernel thats what i gathered no pun intended from the paper
2019,thanks for the details user i might punt this for the future work user suggests i just use a cubic sph kernel for my application
2019,user haha yeah i think so
2019,user no problem slightly_smiling_face for anyone interested to follow up ive created an issue hyperlink
2019,user when i do the dsarbitrary_grid example in the documentationcodesnippetarbitrary_grid dsarbitrary_grid00 00 00 099 099 099 dims128 128 128ag_density arbitrary_gridgas particle_densityag_densityshapecodesnippetit prints codesnippet which doesnt seem right shouldnt the shape be 1283
2019,also while i have your attention what are the units of codesnippet and codesnippet id like to make a grid on a 1 kpc box around the center of the simulation
2018,user has joined the channel
2018,hello yt community i having some difficulties creating a parallelized volume_render in yt essentially the problem occurs at the end of the codesnippet loop when the stored objects attempt to be recombined so all the processors have the same stored data i am simply launching the code codesnippet from the shell running in serial is no problem and works fine the python script and data are attached below any help would be greatly appreciated thanks
2018,stripped version of code
2018,
2018,and the error i am getting is codesnippetfile pelecodepele_make_movie_strippy line 30 in ltmodulegt for fr sto ds in enumeratetspiterstoragemy_scenes file usrlocallibpython27sitepackagesytdata_objectstime_seriespy line 283 in piter storagestorage dynamicdynamic file usrlocallibpython27sitepackagesytutilitiesparallel_toolsparallel_analysis_interfacepy line 520 in parallel_objects to_share datatype dict op join file usrlocallibpython27sitepackagesytutilitiesparallel_toolsparallel_analysis_interfacepy line 284 in passage return funcself args kwargs file usrlocallibpython27sitepackagesytutilitiesparallel_toolsparallel_analysis_interfacepy line 725 in par_combine_object selfcommsenddata dest0 tag0 file mpi4pympicommpyx line 1156 in mpi4pympicommsend file mpi4pympimsgpicklepxi line 174 in mpi4pympipympi_send file mpi4pympimsgpicklepxi line 104 in mpi4pympipickledump file mpi4pympimsgpicklepxi line 91 in mpi4pympipicklecdumps file usrlocallibpython27sitepackagesytdata_objectsdata_containerspy line 1040 in __reduce__ getattrself n for n in self_con_args codesnippet
2018,can you create an issue on github please
2018,that way we wont lose track
2018,sure thing
2018,ill try to take a look at this tomorrow
2018,thanks i just reported the problem on github
2017,user has joined the channel
2017,user has joined the channel
2020,i want to visualize amr data produced by amrex i dont like amrexs standard format because it creates too many files to be efficient can you recommend another generic amr file format that yt supports for example i can also produce silo data
2020,yt doesnt support silo data
2020,does it support some other similar format thats efficient
2020,im looking for blockstructured amr with vertexcellfaceedgecentred grids
2020,i dont know offhand
2020,hyperlink this page lists all the data formats yt supports
2020,have you tested working with the normal amrex format with yt or is the inefficiency on the application side not on the analysis side
2020,its inefficient when writing because there are so many files i have runs with gt10 million output files my file system quota stopped the run
2020,its not a yt problem at all
2020,fair enough
2020,fwiw writing a silo frontend has come up before
2020,i dont think theres anything blocking it besides an interested person to write the code
2020,its much easier to write a write hence my question is there a different format that yt understands
2020,i think the answer is no particularly if you need support for all those different kinds of centering schemes but someone might be able to correct me
2020,at the moment i am using codesnippet from hyperlink
2020,i agree the results should be closer i really think changing to eq 9 as is common in other codes doing similar things will be a step in the right direction i plan to implement this tomorrow locally and assess the differences
2020,alright i look forward to seeing if that improves things slightly_smiling_face
2020,hi there i just issued a pull request hyperlink which is a one line change from a collaborators fork is it preferable to do this from a branch within the yt repo
2020,nope you did the right thing
2020,thank you for the pr if youre interested in contributing more check out the development channel too slightly_smiling_face
2019,im having some difficulty extracting unit data from a dataset
2019,it seems to be stored in a dict but i cant seem to get it out
2019,anyone know how to pull what kind of unit code_length is from ds without having to use dsunit_systemsbase_units
2019,and pulling them out by hand
2019,like is there a way to just getcode_length and have it return cm
2019,user has joined the channel
2019,i cannot change the background color in a slice plot i have an exodus file to visualize where the geometry is in an xy plane in 3d so i just created a slice plot at z 0codesnippetds ytloadouteslc ytsliceplotds z c_o2 originnative width20 nmslcset_background_colorc_o2 colorblack slcsaveblack_backgroundcodesnippethowever the background color is still the minimum value color of the colorbar rouge in my case how could i change the background correctly
2019,are you certain that youre looking at the background and not an area that is contained within the dataset
2019,i think so the geometry shown in paraview is in the first attached picture and what i got with the background setting is the second one
2019,that is weird
2019,have you tried plotting it using matplotlib or some such
2019,i havent done that with matplotlib i am not sure if i can do that because i have an unstructured mesh
2019,user could you check if it works if you set the first argument in codesnippet to codesnippet my hunch is that it expects a tuple cause otherwise it sets it for a wrong field
2019,user i got codesnippet
2019,interesting looks like our docs are out of date
2019,user im not sure what the proper first component should be
2019,if you could docodesnippetds ytloadouteprintdsfield_listcodesnippet
2019,and see if theres something c_o2 field in there
2019,try to use that in set_background_color
2019,user ok
2019,actually while were both online at the same time is there any chance i could convince you to send me the data your working with im sorely lacking in unstructured mesh datasets
2019,just for testing sake
2019,user i just checked that i can reproduce that with a different dataset so it looks like a bug
2019,user theres a plenty of examples here hyperlink
2019,ah perfect thanks
2019,user you wouldnt happen to know off the top of your head how to get unit data would you
2019,user unit data
2019,user just fyi i tried codesnippet and codesnippet but they didnt work i have two blocks in my mesh
2019,if you load up a dataset and fetch a field the array it returns usually contains the units
2019,but in the form code_length or something like that
2019,is there a way to fetch the unit its actually using for code_length
2019,meaning cm or ft or whatever
2019,likewise the same questions exists for things like density temperature and angle
2019,user i dont know if theres a helper for that but you can do something like thatcodesnippetds ytloadlength dsquan1 code_lengthlengthin_cgscodesnippet
2019,it will print out 1 code_length in cms
2019,or codesnippet
2019,thats not really what i need thought it seems that the unit and the field are matched together in a dictionary type object
2019,temp k angle rads style
2019,and i cant seem to actually pull from the dictionary
2019,not sure i understand what you want to achieve
2019,let me take a screenshot that may help me explain it better im awful at explaining stuff
2019,see how every field length time mass ect has a unit that goes with it and this information seems to be stored in the ds object
2019,do you know a way to say get me length and have it return cm
2019,yt seems to be able to automatically find the appropriate units when plotting but im not having such luck
2019,wait
2019,i think i got it
2019,dsunit_systemlength
2019,nevermind
2019,yeah that does it earlier i was looking at the dictionary internally which seems harder to pull from
2019,dsunit_systemlength seems to work
2019,thanks for you help
2019,im not sure thats the thing youre looking for
2019,id need to check it on a dataset that doesnt use cgs
2019,user could you file an issue at hyperlink related to the background problem youre seeing
2019,my assumption is that the units would change if you use a different unit system
2019,user i will
2019,thank you
2019,user yup youre right im not really familiar with our unit system so i had to double check
2019,tanfastic that makes everything easier
2019,hyperlink shows how it works
2019,user i posted a new issues here hyperlink
2019,i am wondering if the function is collectedly implemented the background will be in that color all over the place or just outside the smallest rectangle which encloses the geometry
2019,quick followup to this user apparently this linecodesnippetspset_field_parameterbulk_velocity vx vy vzcodesnippetcauses problems downstream in eg projections unless you feed in a ytarray instead of a list for vxvyvz
2019,i had to add a couple lines to make everything work correctlycodesnippetfrom yt import ytarrayvelocities ytarrayvxvyvzspset_field_parameterbulk_velocity velocitiescodesnippet
2019,ah good point user
2019,thanks
2020,user has joined the channel
2018,user it works for me if i explicitly load as an amrexdataset
2018,
2018,got it that is much easier than i expected thank you
2018,user i guess we need a fancier _is_valid somewhere
2018,user yeah
2016,user has joined the channel
2019,user ive updated my pr this should do the work now
2018,hi everyone im installing yt on a new system using the codesnippet and it just failed for a numpy versioning thingcodesnippetinstalling the miniconda python environmentinstalling the necessary packages for ytthis may take a while but dont worry yt loves youinstalling pythoninstalling setuptoolsinstalling numpyinstalling jupyterinstalling ipythoninstalling sphinxinstalling gitinstalling gitpythoninstalling h5pyinstalling matplotlibinstalling cythoninstalling noseinstalling scipyinstalling astropyinstalling condabuildinstalling sympyinstalling netcdf4building yt from sourcesetting yt_dirhomechummelssrcytcondasrcytgit failure report self_add_defaults_ext file homechummelssrcytcondalibpython36sitepackagessetuptoolscommandpy36compatpy line 119 in _add_defaults_ext build_ext selfget_finalized_commandbuild_ext file homechummelssrcytcondalibpython36distutilscmdpy line 299 in get_finalized_command cmd_objensure_finalized file homechummelssrcytcondalibpython36distutilscmdpy line 107 in ensure_finalized selffinalize_options file setuppy line 317 in finalize_options if looseversionnumpy__version__ lt looseversion1104attributeerror module numpy has no attribute __version__codesnippet
2018,interesting
2018,yeah ive never seen this
2018,someone else hit the exact same thing today
2018,maybe its an issue with condaforge
2018,or wait
2018,did numpy remove that or something
2018,possibly
2018,tries running the install script
2018,so you set inst_yt_source1
2018,make any other modifications
2018,yup
2018,and astropy and scipy1
2018,thats it
2018,weird codesnippetgtgtgt import numpygtgtgt printnumpy__version__1133codesnippet
2018,are you running this on a supercomputer with a module system by any chance
2018,yes
2018,caltechs local cluster
2018,whats codesnippet
2018,i module loaded a python module
2018,ah can you try running with that unloaded
2018,but i figured wed override that
2018,i dont think we can
2018,with this local conda install
2018,module systems do funky things with injecting stuff into various environment variables
2018,sure i can unload that python install
2018,and retry
2018,there might be a way to do that but im not sure what it is
2018,one sec trying
2018,thanks for the suggestion
2018,hmm same error even using the default python install on the system py27
2018,not using the systemwide conda python install
2018,sorry what did you do
2018,error codesnippetawesome here we gousing curldownloading hyperlinkinstalling the miniconda python environmentinstalling the necessary packages for ytthis may take a while but dont worry yt loves youinstalling pythoninstalling setuptoolsinstalling numpyinstalling jupyterinstalling ipythoninstalling sphinxinstalling gitinstalling gitpythoninstalling h5pyinstalling matplotlibinstalling cythoninstalling noseinstalling scipyinstalling astropyinstalling condabuildinstalling sympyinstalling netcdf4building yt from sourcesetting yt_dirhomechummelssrcytcondasrcytgit failure report self_add_defaults_ext file homechummelssrcytcondalibpython36sitepackagessetuptoolscommandpy36compatpy line 119 in _add_defaults_ext build_ext selfget_finalized_commandbuild_ext file homechummelssrcytcondalibpython36distutilscmdpy line 299 in get_finalized_command cmd_objensure_finalized file homechummelssrcytcondalibpython36distutilscmdpy line 107 in ensure_finalized selffinalize_options file setuppy line 317 in finalize_options if looseversionnumpy__version__ lt looseversion1104attributeerror module numpy has no attribute __version__codesnippet
2018,so you used the install script with the default python
2018,what
2018,whats your codesnippet
2018,so i unloaded the python module codesnippet
2018,and then my python is just the default python installation on the system which is 27
2018,and then reran the installer
2018,and got the error above
2018,can i see the output of codesnippet
2018,codesnippetgtgtgt import numpygtgtgt printnumpy__path__usrlib64python27sitepackagesnumpycodesnippet
2018,codesnippetchummelswheeler src module listcurrently loaded modulefiles 1 hdf51817 2 gcc530 3 gsl21 4 openmpi201codesnippet
2018,im running the install script over here lets see if i trigger this
2018,ok cool
2018,just on my mac
2018,yeah fair enough
2018,i havent installed it locally for a while so i wasnt sure if this was a new global bug or if it was just some problems on this machine
2018,someone else reported this exact issue today
2018,its possible that they modified the numpy version
2018,i havent seen it before today
2018,but codesnippet definitely exists on the latest release of numpy
2018,where was the other person finding this error what sort of system cluster
2018,it was a cluster yeah
2018,look at c046hvb59particles
2018,ok
2018,can you show me the output of codesnippet
2018,sure
2018,
2018,these are all just defaults i havent messed with anything yet
2018,i dont see anything particularly suspicious
2018,seems to have not crashed on my machine
2018,yeah seemed reasonable to me
2018,did it get to actually installing yt from source
2018,yes its building yt
2018,my error occurred as soon as it started on that step
2018,so i guess it must be a bug specific to clusters or something
2018,weirdness
2018,you could try doing what the install script does but just manually
2018,eg install miniconda3 in your home directory
2018,edit your path
2018,and install yts dependencies into that new environment then build yt
2018,if it dies thats something you can take to your sysadmin
2018,i can give that a shot
2018,ill try and report back
2018,thanks for the suggestions
2018,can you link me to this script ive never heard of it before
2018,hyperlink
2018,codesnippet wget hyperlinkcodesnippet
2018,hyperlink
2018,user its an artifact of a bygone era when it was way harder to get a python env setup
2018,its still listed as the first option in the installation directions in the docs
2018,we keep it around because even installing anaconda manually is too much for complete beginners
2018,oh
2018,yeah install script ran fine on my mac
2018,ok thanks for the update
2018,i think ive got it working
2018,installing manually seems to be fine
2018,i dont know what was going wrong with the installer script though
2018,thanks for the help everyone
2018,perhaps i should update the tridentyt40 installer instructions to just forego using the install_script
2018,up to you
2018,if you want to spend some time debugging why its breaking that would be helpful
2018,unfortunately i dont have a way to reproduce so cant help much
2018,it would be nice to figure out what codesnippet is when it fails
2018,if i want to run the commandline version of yt eg codesnippet or codesnippet where is the python script that i can put in my path to do this
2018,since the manual install of yt doesnt include the commandline functionality
2018,yes it does
2018,i guess by just codesnippet and then codesnippet it doesnt for me
2018,itll be in the bin folder associated with your miniconda install
2018,hmm
2018,got it my mistake path weirdness here
2018,those scripts get installed by yts setuppy so theyll always be there no matter how you invoke it
2018,1
2018,ok thats great
2018,user could you try running codesnippet and see if anything pops up
2018,on that cluster where you saw the failure
2018,ok one sec
2018,well i wiped out the ytconda directory after the failed install with the install_script and then reinstalled conda from scratch in that directory
2018,when i run that command now i see no such files
2018,im currently trying to pull an codesnippet out of the image plane of a codesnippet in the same way i do for codesnippet objects but it seems like this isnt an option is there another way to pull the image data out of the codesnippet to dump to a matplotlib codesnippet call or something similar
2018,user its not an frb but you can access it via a dict on the codesnippet attribute of the codesnippet
2018,gotchajust found that
2018,thanks
2019,user has joined the channel
2018,user has joined the channel
2019,user ive issued hyperlink which i think addresses one of the issues you mentioned
2019,user has joined the channel
2018,is there any way to easily make cartesian xyz slices from a spherical dataset im seeing stuff about make slices along the spherical axes hyperlink but havent found anything about being able to slice along axes besides how the dataset is saved
2018,no thats not how the support for spherical data works right now
2018,user would be the person to talk with about this he has ideas related to making this easier
2018,and has a better idea of how things work right now
2018,cool thanks
2019,user some of us are away at scipy but will try to reply to you when we are back
2019,matt i found that using the tuple boxlib phi as field name is working
2019,hi i have a problem about adding a derived field if i just use ytadd_fieldenzoure function_unit_rpsiforce_overridetrue
2019,the field will not show up in dsderived_field_list
2019,after i call adenzoure it is finally added to the dsderived_field_list
2019,is there any way that the field will be added immediately after i do yt_add_field
2019,user my guess is that you need to add that field before index is created for enzo dataset eg before you do ytloadyour_datasets or use codesnippet on dataset directly codesnippet
2019,also its not a bad thing its not initially there it should be created when its gonna be required
2019,user thanks its great i just copy the code from the documentation
2019,which part
2019,user just change ytadd_field to dsadd_field
2019,checkout the following codecodesnippetimport ytfrom ytunits import dimensionsdef _pressurefield data return datadsgamma 10 datadensity datathermal_energyytadd_fieldgaspressure1 function_pressure unitsauto dimensionsdimensionspressureds ytloadisolatedgalaxygalaxy0030galaxy0030printgas pressure1 in dsderived_field_listytadd_fieldgaspressure2 function_pressure unitsauto dimensionsdimensionspressureprintgas pressure2 in dsderived_field_listdsadd_fieldgaspressure3 function_pressure unitsauto dimensionsdimensionspressureprintgas pressure3 in dsderived_field_listcodesnippet
2019,if you run it you may need to change codesnippet to your dataset youll notice that codesnippet wont be on the list but codesnippet and codesnippet will
2019,how can i find the maximum of a field
2019,ah i see its output by default when the field is read thanks
2019,user has joined the channel
2018,is there an equivalent of codesnippet for particle plots i want access to the bitmap thats produced so i can fiddle with itfound how to do the particular thing i needed but it would be nice to know if the image data is accessible
2018,if i load up a time series via codesnippet is there an easy way to plot timeaverage fields from that
2018,or maybe there is another way to do this i am not thinking of
2019,im trying to select particles in a box with a side length of 150 kpc so i think my left and right edges are 75 kpc from the center but when i run this code i see a bunch of distance components that are outside 75 75 is this a bug or am i misunderstanding the codesnippet selectorcodesnippetds ytloaddatadir snapshot_1720hdf5region dsboxcenter dsquan750 kpc center dsquan750 kpcoutput regionparttype0 coordinatestokpcdistance_components output centerprintnpsortdistance_componentsflattencodesnippet
2019,is this an isolated simulation were the particles cut out did you check that the origin is not at 325 325 325 instead of 0 0 0
2019,the way selection works for sph data particles will be selected if their sphere of influence eg the sphere centered on the particle with a radius given by a constant factor times the smoothing length the factor is 2 for gadget flavored sph data iirc intersects with the selection box
2019,i bet the particles that are formally outside the box have smoothing regions that overlap
2019,the idea was that if you wanted to reconstruct an sph field inside a selection region youd need not only the particles inside the box but also the particles whose sphere of influence overlap with the region
2019,at least with scatterstyle smoothing it doesnt really make as much sense to do it that way for gather style smoothing
2019,ah that makes a lot of sense thanks
2020,user has joined the channel
2020,hi ive been playing around using yt project to import simulations from openfoam is it possible to construct datasetseries in memory
2020,the examples ive found all seem to construct it from a glob of filenames
2020,you can create a codesnippet from a list of datasets iirc
2020,i will look for this functionality thank you
2019,user has joined the channel
2019,can yt export to obj files
2019,yup let me find the relevant place in the docs
2019,hyperlink
2019,in particular surfaceexport_obj
2019,hyperlink
2019,user can you export volumetric rendering to obj
2019,user not really no we only support mesh obj files i didnt realize obj had support for volumetric fields
2019,so the meshes can be extracted into isocontours and put into obj
2019,user i dont know if they do wink
2019,okay cool
2019,or rather volumetric data gt isocontours gt obj
2019,trying to create a fake dataset withcodesnippetfrom yttesting import fake_particle_dsmy_data fake_particle_dsmy_dataall_datacodesnippetbut im getting a codesnippet on the last line am i doing something wrong here
2019,wait could be an autoreload error
2019,yep
2019,nevermind
2019,reloading scream
2020,hi all im trying to extract a fixed resolution 2d array from an offaxis projection plot and save it to disk the following script works for the gridaligned projectioncodesnippetplt ytprojectionplot ds z my_field pltdata_sourcesave_as_datasetcodesnippetbut it doesnt work for the offaxis projectioncodesnippetplt ytoffaxisprojectionplot ds normal111 my_field pltdata_sourcesave_as_datasetattributeerror traceback most recent call lastltipythoninput36c002fa3b88aagt in ltmodulegtgt 1 pltdata_sourcesave_as_datasetattributeerror offaxisprojectiondummydatasource object has no attribute save_as_datasetcodesnippetshould i use the image returned by the codesnippet method i also notice there is an codesnippet function any suggestion is appreciated
2020,yeah you should just save the image buffer
2020,codesnippet is just a wrapper around codesnippet so it doesnt really matter which one you use
2020,it does make sense to save the projection data object as a dataset since theres an intermediate state for the data a 2d projected version of the amr structure of your data
2020,for offaxis projections we use the volume rendering infrastructure in yt to generate the image so theres no intermediate state to save we go directly to the image buffer from the amr data
2020,user hope that makes sense
2020,if all you want is an image in the end for both cases then it may make sense to just always save an image the you wont notice this difference
2020,user thanks for the elaboration i only need a fixed resolution array so storing an image buffer should be sufficient
2018,im working through this yt gadget tutorial hyperlink in cell 3 ytprojectionplot is called to plot the density of gas is it possible to do an analogous thing for the dark matter particles only i was hoping something like parttype1 would work but i cant figure it out
2018,deposit parttype1_density
2018,its not quite the same thats nn interpolation not sph smoothing
2018,theres also deposit parttype1_cic for cic interpolation
2018,see hyperlink
2018,hope that helps
2018,you may also want to try ytparticleprojectionplot for the dark matter particles
2018,hyperlink
2018,user user thanks i got it working with projectionplot which is sufficient for my needs right now
2020,user has joined the channel
2020,user morning i dont know how to do it better than what i pasted above
2020,thank u so much
2020,user
2020,would u have a look please
2020,user i dont know what to suggest can you fill out a concise bug report where i can iterate with you that might be more productive right now
2020,yes 1 to what matt said since this might be a bigger problem having a bug report would help make sure your issue doesnt get lost
2019,user has joined the channel
2018,user its ok to spam this channel people can mute it
2018,just try not to spam general slightly_smiling_face
2018,sounds good
2019,i think i asked this question here before but it is not in the archive anymorehow do i rotate a plot or flip the axis if i do codesnippet the zaxis is on the xaxis and the xaxis on the yaxis of the plot i would like to flip those ie have the zaxis on the yaxis any simple way of doing thisi tried to play around with codesnippet and codesnippet but no success unfortunately also the search feature of the website seems to be broken at the moment
2019,user see hyperlink
2019,hey regarding vadlamani question on the mailing list
2019,it happens that their ramses output is invalid the output is broken
2019,however old version of yt used to be able to read them but the new one cant
2019,yet the old version was reading invalid files while the new one fails on them
2019,hey all when downloading the codesnippet tnghalo fromhyperlinkit reports that the codesnippet is gadget is this a common feature for all codesnippet simulationscodesnippetin 5 ds ytloadhalo_59hdf5yt info 20190503 150842038 calculating time from 1000e00 to be 4356e17 secondsyt info 20190503 150842039 assuming length units are in kpch comovingyt info 20190503 150842059 parameters current_time 4355810528213309e17 syt info 20190503 150842059 parameters domain_dimensions 1 1 1yt info 20190503 150842060 parameters domain_left_edge 0 0 0yt info 20190503 150842060 parameters domain_right_edge 205000 205000 205000yt info 20190503 150842061 parameters cosmological_simulation 1yt info 20190503 150842061 parameters current_redshift 00yt info 20190503 150842061 parameters omega_lambda 06911yt info 20190503 150842061 parameters omega_matter 03089yt info 20190503 150842061 parameters hubble_constant 06774in 6 dsdataset_typeout6 gadget_hdf5codesnippet
2019,are you on the yt40 branch and have you pulled recently
2019,if yes then user is the guy to talk to
2019,hmm i havent let me do so and report back
2019,aha user an update does itcodesnippetin 4 dsdataset_typeout4 arepo_hdf5codesnippet
2019,that pr was merged very recently let us know if anything seems odd
2019,will do
2019,hi useryes let me know if something odd happens
2019,user am i right that the codesnippet front end is only in yt40
2019,im making a final push this summer to get codesnippet ready for release cc user and eventually am going to transition it fully to yt40 whether this happens sooner or later probably will depend on the answer to the above question
2019,user thats right only 40
2019,okay thanks thats very helpful
2020,whats a good way to quickly visualise a gradient field for a 2d dataset i tried the obviouscodesnippetdsadd_gradient_fieldsgas densityytplot_2dds density_gradient_xcodesnippetbut it raisescodeblockas it should but then i do not understand how i can select a smaller region to perform the ploti think what _should_ work is something like thiscodesnippetgrad_defined_region dsr19 19 19 here i assume the full domain extends from 0 to 10 code_units in all directionsdsadd_gradient_fieldsgas densityytplot_2dds density_gradient_x data_sourcegrad_defined_regioncodesnippethowever the slicing mechanism in codesnippet seems somewhat impossible to satisfy with my 2d dataset the example above raisescodeblockmeanwhile if i attempt to perform a 2d region selection i getcodesnippetgrad_defined_region dsr19 19gtgtgt ytdimensionalityerror dimensionality specified was 2 but we need 3codesnippetim hesitant to report this as an issue since im not certain im doing things correctly here
2020,codesnippet works i remember someone had a question similar to this one in the chat before i think you have to overrite the boundary condition in the 3rd dimension to be periodic is it not already
2018,within the last couple days ive been getting memoryerror exceptions running things on blue waters that i would have thought were just fine
2018,someone just contacted me about getting similar errors using ytree on that machine as well
2018,perhaps run with tracemalloc
2018,or unless youre saying its an issue with blue waters itself
2018,user if we can track it down to just the broad outline of which section of code it happens in that might help we have a memory profiler i think
2019,user has joined the channel
2020,submitted hyperlink
2020,i see slightly_smiling_face
2020,a little annoying that cantera doesnt publish packages on pypi
2020,so i suspect if you just call that function directly instead of using codesnippet itll work yts unit system doesnt know about codesnippet at all
2020,or cast to ndarray before calling a codesnippet ufunc
2020,im installing cantera so i can confirm
2020,ive tried that but codesnippet doesnt accept the yt data i getcodesnippet file interfacescythoncanterathermopyx line 1000 in cantera_canterathermophasetpx__set__typeerror only size1 arrays can be converted to python scalarscodesnippet
2020,ok still building cantera
2020,ill try some things once i can actually run the test script slightly_smiling_face
2020,thanks
2020,i guess supporting codesnippet in general would be tricky for any unit system you dont know what kind of math is happening inside of the function and thus what kind of unit transformations need to happen
2020,could just convert the arguments to ndarray and print a warning
2020,user what are the units of codesnippet
2020,hmm not sure how to fix codesnippet
2020,maybe i didnt build cantera in a way that gives me that
2020,anyway it looks like casting to ndarray at least gets you past the error youre seeing
2020,codesnippetdef _nufield data vfunc npfrompyfuncset_tpx 2 1 dyn_visc vfuncdatatempd datapressured dyn_visc ytytarraydyn_visc pas return dyn_visc datadensitycodesnippet
2020,the codesnippet attribute returns an ndarray view its equivalent to doing codesnippet
2020,im gonna open an separate issue about supporting vectorize and frompyfunc
2020,codesnippet is dynamic viscosity so should be masslengthtime
2020,your workaround with codesnippet seems to be working thanks
2020,user has joined the channel
2020,hi there im a grad student just starting with yt this might be a simple question and im not sure if this is the right place to ask this but here we are when going through different fields with artio data and seeing what units are associated with them im noticing that pressure does not have units associated with it is there maybe some unit conversion thing happening in there or am i missing something more fundamentaladditional details im using yt 36dev0 to access the units i usecodesnippetimport yt as ytds ytloadsizmbhlozclref04snthrs9_a09011sizmbhlozclref04snthrs9_a09011artdsindexdsfield_infogastemperaturedsfield_infogasdensitydsfield_infogaspressurecodesnippettemperature and density are included to show that i do get correct units displaying for theseif i make pressure using my own derived field i can use my own units but i just want to see if im missing something or if this is a bug
2020,this would need to be fixed by patching yt
2020,fields that are known to yt get metadata attached to them
2020,eg all these fields
2020,hyperlink
2020,in codesnippet
2020,it looks like codesnippet is in there though
2020,oh wait but the units are blank arent they
2020,so yeah youd need to replace the empty string in the tuple herecodesnippet
2020,with whatever the units should be
2020,im not sure what that codesnippet comment is about
2020,okay cool so follow up question should these units be included automatically since it does whenever i make my own derived field for pressure or perhaps theres some internal unit conversion with constants that im not aware ofthanks for your speedy response btw
2020,so if you make a derived field from density and temperature the units will happen automatically because of yts unit system
2020,eg the units will come out of the arithmetic
2020,but if the pressure is getting read from disk
2020,then yt uses that codesnippet tuple to infer what the units should be
2020,right now that tuple is saying that codesnippet is dimensionless so thats why youre getting those units back
2020,does that make sense
2020,yes absolutely thank you slightly_smiling_face
2020,if youd like assistance with making a pull request to fix this im happy to help out
2020,it sounds like youre already running from a git clone of the repository so youre like 90 of the way there slightly_smiling_face
2020,i would love some help with that if you have the time i dont want to encroach if you have other things to get done
2020,i would start with the instructions here hyperlink
2020,alright cool thanks again i appreciate it
2020,user or anyone else who happens to know im trying to create a codesnippet of the new viscosity field and its giving the following error stackcodesnippetsx ytsliceplotdsznu originnative center2324 635001 38100001 width3328cm127cm file phomewhitmansytcondasrcytgitytgeometrycoordinatescartesian_coordinatespy line 240 in _ortho_pixelize period intperiodic file ytutilitieslibpixelization_routinespyx line 64 in ytutilitieslibpixelization_routinespixelize_cartesiancodesnippetany idea what could be causing this do i need to enforce codesnippet in some way
2020,probably that cython code shouldnt be using float64 explicitly i guess
2020,i dont see the full stack trace
2020,what does your field definition look like and what is the dtype of the nu field like if you get the data from a data object
2020,its getting to be late on friday so i may not be able to help today opening an issue for things like stack traces from normal usage is totally ok
2020,i have the following definitionscodesnippetdef get_mutemppres gas ctsolutionaircti gastpx temp pres o210 n2376 return gasviscositydef _nufielddata vfunc npfrompyfuncget_mu 2 1 dyn_visc vfuncdatatempd datapressured dyn_visc ytytarraydyn_visc gcms return dyn_visc datadensitycodesnippetand am adding the field withcodeblockand then having issues with sliceplotcodeblock
2020,i can open an issue later tonight with the full stack if need be
2020,it may help to replace this linecodeblockwithcodeblock
2020,just a guess though
2020,yeah its working once i enforce the float64 type thanks
2019,user thanks for answering grinning
2020,using a projection plot on a changa datasetcodeblockis the center in this example calculated based on the gas center of mass baryon center of mass or total including dm center of mass
2020,im trying to calculate the coordinates that this projection plot is centered on
2020,using yt4x
2020,user my guess is the xyz of the particle with highest value for density whether computed or on disk
2020,thanks
2018,hi user im at a conference in japan for the week so i may be a little slow at responding but i have some more ideas that may help ive been thinking for some time about a way to speed up the codesnippet function and what id like to do is implement a ytree frontend for codesnippet this would allow one to access all nodes at once and do the type of things you want it only just occurred to me that this is exactly what youre looking for anyway i think i can do this sometime this weekin the mean time this might be a little bit faster than using the codesnippet functioncodesnippet tsize nparrayttreesize for t in a all_nodes npemptytsizesum dtypeobject offset 0 for i ts in enumeratetsize all_nodesoffsetoffsetts aitree offset tscodesnippet
2019,user no i didnt can we set up a call to talk through this
2019,hi is there a way to plot the negative of a quantity in codesnippethyperlink
2019,user youll have to make a derived field like socodesnippetpythonytderived_fieldnamenegative_of_whateverdef neg_fieldfield data return datawhatevercodesnippet
2019,there are some other options you can specify to get a prettyprinted name and stuff
2019,thanks and how do i specify that in the sliceplot command
2019,user whatever you name the field is the new field you should plot note that if youre using a script you should do this field definition before you load the dataset and if not you have to call codesnippet
2019,that worked thanks i used codesnippet
2019,hooray
2019,sure if youre available im pretty much free all day tomorrow time zone is us pst
2019,user
2018,hmm i thought codesnippet worked with phase plots but maybe not
2018,matt i was thinking of adding annotate_mean_profile or something like that
2018,ah neat
2019,two codesnippet questions im looking at hyperlink and trying to only draw the star particles within a sphere codesnippet works but codesnippet gives codesnippet likewise id like to only mark the stars which is codesnippet 2 but setting codesnippet gives codesnippet so maybe im passing that in wrong
2019,for the second question these are two slightly different uses of the term particle_type in the enzo frontend codesnippet is a field associated with each particle whereas in particlebased datasets the particle_type is equivalent to the field_type eg gas to do what you want youll have to create a particle filter like thishyperlinkthen you would be able to do codesnippet for example
2019,for the first question it doesnt look like there is a particularly simple way to do what you want but i think you could do it by making a particle filter in the manner discussed above or it might be possible to implement a codesnippet keyword
2019,hmm ok partially i was trying to test if my stars filter was working upside_down_face
2019,update it doesnt crash with the codesnippet option but it also doesnt plot any points which i think answers my question thanks
2019,im having problems with certain codesnippet datasets but not all of them after initializing the coarse index it breaks ive uploaded two datasets at hyperlink one works g263e10 and one doesnt g826e11 and i cant see why they look substantially the same im using yt40 from source and this is an sph codemy script iscodesnippetimport ytdsname testnihaoinputg263e10g263e1000320ds ytloaddsnameprint dsfield_listcodesnippetthe error im getting is in codesnippet herecodesnippetusersclaytonstrawnytytfrontendstipsyiopyc in _yield_coordinatesself data_file needed_ptype 310 mas npempty3 dtypefloat64 311 for axi ax in enumeratexyzgt 312 mi ppcoordinatesaxmin 313 ma ppcoordinatesaxmax 314 mylogdebugvalueerror zerosize array to reduction operation minimum which has no identitycodesnippetcan others reproduce this
2019,edit doing this again on a different simulation runs into the same problemi think it breaks when the redshift gets too low zgt2 is ok zlt2 doesnt work
2018,hi im generating a angular moment vector from a sphere im expecting the result to be an unitless array like 0 0 1 showing the direction of the angular momentum but the code actually gives me some huge numbers with units of cm2s which seem to be the unit of rmv with m being a unit mass not even sure if this interpretation is correct how should i get the vector array that shows the direction of the angular momentum instead thanks
2018,here is what i did
2018,yes specific angular momentum has units of cm2s
2018,you could divide l_vector by its norm
2018,norm would be npsqrtl02 l12 l22
2018,yup
2018,sounds good thanks
2018,another question i used yt about 4 years ago at that time there was an allsky projection function called ytvisualizationvolume_renderingcameraallsky_projection but it is not there anymore i wonder are there other similar functions in the new yt
2018,so that had to be removed when we relicensed from gpl to bsd since it used healpix which is a gpl library
2018,since then the astropy community created a bsdlicensed healpix implementation that we could use
2018,someone would need to port the old code to use the new healpix library
2018,hyperlink
2018,i see so that isnt any module existing for this at the moment
2018,nope unfortunately no
2018,that was the one piece of functionality we had to stub out unfortunately
2018,wed like to bring it back the last i heard about it user wanted to do that
2018,yeah too bad there was a license issue it was such a nice function
2018,thanks a lot for the info ill shop around to see what else i can use
2018,is the function still in the old code and where i can find the old version of yt
2018,so theres this wip pull request hyperlink
2018,the old interface was removed but the old version of the code is still in the repo on the yt2x branch
2018,hyperlink
2018,1 thanks
2019,user has joined the channel
2019,does anybody know how i can load gridded _cosmological_ data codesnippet does not allow for the parameters codesnippet or codesnippet
2019,so far i tried manually setting eg codesnippet and the other cosmological params but then the cosmological units eg codesnippet do not get registered
2019,hey user ive done stuff like this for running halo finding on generic particle data long story short you have to set a lot of things manually but here is a script that i put together that you can probably alter for your purposeshyperlinkmaybe we can pr some of this functionality at some point
2019,great thanks ill check it out
2019,worked like a charm thanks slightly_smiling_face
2019,excellent
2019,user hi sam to address the deeper issue do you think that i could get you to store to an hdf5 file the contents of all the codesnippet arrays this is the full amr hierarchy and would help me replicate it here to see if the issue is something i can recreate without the full dataset
2019,i created a new issue for this problemhyperlink
2019,in a slice plot is it possible to align the numbers of the color bar in the picture the number in the bottom has a minus sign and the digits are shifted to the right it would be great if i can add a white space or plus sign to the positive numbers to align the digits
2018,yeah good call that will be a bit faster i think i can speed up my code even further with a technique like this itll still much slower than i think it could be though ultimately im spending a lot of time just accessing the properties of each node so if there properties of all the nodes were exposed in a way like im describing most of my script would be reduced to reindexing those arrays ill give this a shot and let you know what i find and let me know if you want to chat more about the type of interface im hoping for
2018,is it possible to create a derived field of an averaged field along one axis only something like codesnippet i can do this by extracting fixed resolution data but i can not see how to do this more easily by defining a derived field thanks
2018,sure youll need to use a codesnippet validator
2018,and make your field definition do a finite difference along the axis you want to average along
2018,codesnippet ensures that your field function is passed a spatial 3d data chunk
2018,passing 1 to it tells yt to generate 1 layer of ghost zones for the chunk before calling the field function
2018,hyperlink
2018,thank you ill check it out
2018,user has joined the channel
2018,i think the yt frontend will help quite a bit since youll be able to access the merger tree data like a conventional particle dataset hopefully i can get that done soon
2018,user has joined the channel
2018,hi user i was able to do this altering the codesnippet in codesnippet as you had tried
2018,i noticed that when i did codesnippet in the rockstar directory that it did not actually delete codesnippet so you might want to that
2018,ah we should probably patch the makefile to do that
2018,yeah
2020,hi all i am trying to plot a figure using a dat file created by amrvac i use spherical coordinates and want plot a slice at a certain distance r from the origin i would like this plot to be theta phi or phi theta but plotted as if it where a plane not a sphere what i tried to far a slice at r produces a full sky 2d image like is usual in astronomy see attached however i would like to create an image similar to the second attachment i cant seem to figure out how to do this
2020,hi i coauthored the amrvac frontend as of now there is no ytwise solution for this but the good news is that there is a workaround for amrvac data you can load your dataset as if it was written in cartesian coordinates using codesnippet then perform an xslice which should correspond to the r axis
2020,this method should produce the plot you are trying to make however it will require a little more work on your part because youll need to manually update the axes labels
2020,hope this helps please let me know if you need additional info user
2020,perfect exactly what i need
2020,happy to help fyi i think i tested this with different non cartesian coordinate systems though only used it with polar datasets let me know if youre having any issues
2018,user has joined the channel
2018,not sure where to put this so i figured this is a good place to start i fixed several problems with the art frontend and put them on hte ytdev mailer and was wondering if i should puttalk to anyone here about them
2018,here is fine theres also cbe6579czdevelopment
2018,did you see i replied to you
2018,on ytdev
2018,i did not
2018,hyperlink
2018,not sure why you didnt get that
2018,also not sure why youre doublemailing
2018,yeah just saw it and made a request
2018,1
2018,looks noncontroversial to me but lets see what the tests say
2018,i pinged kenza over email
2018,thanks for the contribution slightly_smiling_face
2018,no problem i am also looking into trying to fix a few other things that may or may not be broken will let kenza know
2018,yup i havent heard from her in a few years so she may or may not engage
2018,good to know
2019,hi all quick question here is it possible to show 3d streamlines velocity or magnetic field when making a volume rendering and while im at it what about annotations of the physical scale on the domain box as well
2019,if you mean invert the x and y axes in cartesian geometry theres a trick for that
2019,otherwise i dont know but i would be very interested in the answer as well
2019,heres the trick for the narrow case i know how to deal with codesnippet flipping the axesdscoordinatesx_axis2 1dscoordinatesx_axisz 1dscoordinatesy_axis2 0dscoordinatesy_axisz 0 plottingytsliceplotds density zcodesnippet
2019,no to the former at the moment yes to the latter see the volume rendering docs
2019,oh wait just the domain box for the latter
2019,oh yes i have the domain box but i was wondering if i could label the axes as well
2019,theres save_annotated but that doesnt include the physical scale
2019,could be extended to probably
2019,alright thanks maybe ill see if i can extend it at some point and submit a pr for that
2020,user has joined the channel
2019,hey is there the equivalent of codesnippet but for the grid
2019,looks like no
2019,codesnippet currently doesnt have any logic to deal with field parameters
2019,ok
2019,and how do you create a vector field in yt
2019,i think right now they need to be set up in a hardcoded manner inside the yt field system
2019,i might be wrong about that
2019,might be easier to just work with the components of the vector
2019,yeah the sticking point is field detection as soon as we make that smarter it gets easier to handle this but right now if you add a new vector field youd need to add a line here so that field detection generates data with the correct shape
2019,hyperlink
2019,also it looks like it has to be a particle field so vector mesh fields will likely require more work to get working besides adding it to that line
2019,oh wait user im totally wrong there is a relative_x field excuse me
2019,is there
2019,i see it referenced inside the yt source code let me make an example
2019,or im misreading things
2019,ah wait no
2019,theres a codesnippet but no codesnippet
2019,sorry yeah i guess we need relative position fields we dont have
2019,ftr we have a globus endpoint for large files
2019,if you search for dxl it should pop up
2019,hi all i have been having a problem with codesnippet that i recently posted about on the forum but i wanted to reach out to people here to see if they can reproduce my problem or have seen it before or know how to fix iti recently updated to yt v350 and now there are some fields in my plugins file which are not being loaded in properly i have a sample data set codesnippet a problem script codesnippet the error i receive from codesnippet codesnippet a script which works codesnippet and my plugins file codesnippet within this dropbox link hyperlink please note that the dataset is about 275 mb there are a few fields in my plugins file that are not working properly one specifically is my definition for codesnippet see attached code snippet it would be great if someone could run my short scripts with yt v350 and see if they get a similar error thanks in advance for taking the time to look at this please let me know if you have any questions
2019,
2019,user thanks for all the info im going to try to look at this today slightly_smiling_face
2019,awesome thank you
2019,do you have a github account i can ping when i open an issue about this
2019,yes my username is drenniks
2019,1
2019,user ive staged the file at hyperlink it weighs in at 14 gb compressed we use the compressed size for the datafilesjson file
2019,good stuff
2019,do you know why although a simple codesnippet gives me correct units now without any tweak codesnippet displays my x axis in cm moreover depending on values it can display a tick label but no unit or unit but no tick label hereafter related figures
2019,
2019,
2019,for the second plot it looks like the label is getting cut off thats a bug it shouldnt be happening
2019,you can customize the units of the x axis iirc
2019,yeah codesnippet
2019,for the first plot not sure offhand why its not displaying a tick label it could be theres not enough dynamic range to do so and switching to linear scaling for the y axis will fix that
2019,codesnippet works i will start with that cheers
2019,user has joined the channel
2019,hi all im using trident to generate spectra from lagrangian simulations and ive found that slow loading of data in yt can lead to very long times to generate rays is anyone familiar with this or related issues heres some more explicit information the loading times mean it can take 10 min to generate a ray depending on simulation resolution 626 of the 627 seconds spent generating a ray are spent calling codesnippet its not clear why it takes so long to read the data using h5py to open the same data directly and perform simple calculations takes 5 seconds im using updated demeshenedcompatible versions of trident and yt version 13dev1 yt version 40dev0 changeset 947ebdc22c48for interested parties ive attached a notebook capable of reproducing these issues thanks
2019,can you file an issue against trident on github please
2019,user wow im not sure this is a trident issue it may very well be a yt one it spending its tiem in that function suggests its yt taking way too long can you say more about the data source youre using is it codesnippet or something like it or is it a sphere or something more complex and is the data spread between multiple files
2019,ive had issues using masks on open h5py objects when h5py attempts to use fancy indexing with hdf5 hyperslabs you think youre saving time by opening only a subset of the data but in reality it takes gtgt10x as long
2019,very true i think we mostly avoid that in yt but i should double check
2019,when zach and i were talking about this between us my suspicion was that yt was trying to save memory time opening a subset of the data that is fancy indexed to the ray
2019,yes i chatted with user about this on the trident slack and we came to the conclusion its a yt one and i should continue the discussion here i appreciate trying to direct the discussion to the appropriate channel thoughregarding the data format the raw data is a lagrangian cosmological zoomin simulation with data separated into multiple files total file size 8gbthe yt data object is produced by codesnippet after loading with codesnippet
2019,heres a relevant linkhyperlink
2019,im going to start a thread here even though i usually forget to wink i have a few followups before i try to diagnose does this happen regardless of the location you pass the ray through if you send it through the edge of the box does it go considerably faster
2019,and any chance you could run it with cprofile and send me the resultant output
2019,happens regardless of location havent tested with edge of box since thats way outside the zoomin region usually
2019,the notebook above contains the results of cprofile
2019,oh i didnt read the notebook i will check it out i have to handle some teaching responsibilities for a bit but i will return to this im optimistic theres something we can do or at least figure out a bit more aboutone last question whats the depth of the lagrangian zoomin
2019,ie the dynamic range
2019,particle mass resolution 7000 msun for a total gas mass of a few times 1e12 msun ie out to a few times the virial radius of a l galaxy high dynamic range in other words
2019,also i realized i did send a sightline through the edge of the box and it took about as long
2019,ok that may be very useful information and may simply expose something we have not dealt with in the bitmap indexing i will have further diagnostics to request but if you could would you be able to send the codesnippet files
2019,at this point i have to close down slack could you file an issue with some of this on yt and i will assign myself so i do not lose track
2019,will do thanks
2019,ok great maybe file a yt issue then sounds like matt is working with you though
2017,user has joined the channel
2017,hello everyone not entirely sure if this is the right place to ask but i have encountered a field definition in yt that i cannot wrap my head around what does the create_averaged_field method actually do there are no comments in the source and the docs do not tell muchi mean sure it computes weighted means but with respect to what a coordinate axis this method is associated eg with the field gas averaged_density maybe youve heard of it
2017,hi simon i just looked through the source code it looks like it takes a full 3d grid and creates an averaged field that is weighted by cell mass by default using 3x3x3 cubes of cells it does this by throwing away the outer layer of cells so if you have an nx ny nz grid the weighted grid will be nx2 ny2 nz2
2017,the default weighting field is cell_mass but it seems that you can use whatever you want
2017,this line right here is important hyperlink
2017,if you use a validatespatial field validator with a field definition you will be working with 3d structured grid data
2019,hi everyone is there a quick way to add a particle fielddeal with particles on an individual basis in yt im looking to modify the followinghyperlinkso that it calculates the xray emissivity on a perparticle basis in my simulations rather than on the ytmesh because some of my analysis tools rely on the perparticle information thanks
2019,from first glance it seems that i could simply copy everything with gas etc and replace it with for example parttype0 etc but i want to be sure this wont mess anything up
2019,hi user is it gizmo are you using 35 or 40 version im not familiar with this specific field but in general in yt 40 gas and parttype0 are almost the same they are both perparticle
2019,i am using gizmo yes and im using 351 currently so if i counted the number of gas objects and parttype0 i would get the same number out
2019,okay so in 351 they are different you are right gas is the mesh field and you should add field to parttype0 for the perparticle field
2019,here is an example to add a particle field hyperlink
2019,fantastic thank you smile
2019,besides changing ptype note that also to specify codesnippet
2019,thanks so much
2019,is there a way to silence all the logging that comes out of codesnippet i can codesnippet and codesnippet but that seems a bit overbroad because its a global setting
2019,you can do codesnippet
2020,user has joined the channel
2020,hello everyone i want to plot the cell mass at every number density but with decreasing number density ive only been able to do this with profileplot
2020,any help is appreciated
2020,user hi do you want to just reverse x axis
2020,codesnippetimport ytds ytloadenzo_tiny_cosmologydd0046dd0046ad dsall_dataplot ytprofileplotad density temperature velocity_x weight_fieldcell_mass plot_specdictcolorred linestyle relevant part reverse x axisfor p in plotplotsvalues paxesset_xlimpaxesget_xlim1plotsavecodesnippet
2020,something like this should work i think
2020,thank you for the prompt reply
2020,ill try it
2020,there might be some magic option directly in matplotlib which can be passed as codesnippet in codesnippet but im not that familiar with it to know offhand
2020,so i basically edited like thisimport ytfrom ytunits import msunds ytloadscratchsmallnh2dd0002dd0002ad dsall_dataplot ytprofileplotad number_density cell_mass weight_field none accumulation true relevant part reverse x axisfor p in plotplotsvalues paxesset_xlimpaxesget_xlim1plotset_unitscell_massmsunplotsaveand it gave me a weird plot is there something wrong with it also if i want the number density to go from 1e8 to 1e7 how do i write that paxesset_xlimpaxesget_xlim1e81e71
2020,also if i do thisimport ytfrom ytunits import msunds ytloadscratchsmallnh2dd0002dd0002ad dsall_dataplot ytprofileplotad number_density cell_massplotset_unitcell_massmsun relevant part reverse x axisfor p in plotplotsvalues paxesset_xlimpaxesget_xlim1plotset_unitcell_massmsunplotsavethe x axis is increasing again
2020,if you know your limits you can do codesnippet
2020,tried that but didnt work
2020,gave me empty plot
2020,hmm give me a sec ill try to reproduce locally
2020,user try thiscodesnippetimport ytfrom ytunits import msunds ytloadscratchsmallnh2dd0002dd0002ad dsall_dataplot ytprofileplotad number_density cell_mass weight_field none accumulation trueplotset_unitscell_massmsun any yt specific modifications have to happen before this lineplot_setup_plots reverse x axisfor p in plotplotsvalues paxesset_xlimpaxesget_xlim1plotsavecodesnippet
2020,its unfortunately prone to the order of operations
2020,im sorry its so brittle we should definitely fix codesnippet to make it more intuitive and easy
2020,sorry to bother u so much but i got no one else to help this gave same plot as before
2020,is there any way i can specify the limits and make it decrease
2020,ok wait i just realized something when i do set_xlim1e81e7 the axis is actually decreasing but nothing there
2020,without accumulation the graph makes sense
2020,this one with accumulation true which makes no sense
2020,user i think its because the accumulation only goes left to right and your number density here goes high to low
2020,user not sure i understand the axis is decreasing now on all plots
2020,matt what i suggested above should work around it
2020,were literally doing everything and then setting xlim on the axis
2020,user on the first plot looks like you ylim is wrong
2020,its just below the curve
2020,thats why its empty
2020,oh its grams nvm
2020,user oh sorry
2020,but 101 g doesnt look like a lot
2020,user the last 2 plots are ur script
2020,ok why its wrong
2020,user the first empty plot with xlim1e81e7
2020,user without the accumulation its correct but now i need to sum them up the curve should be increasing
2020,the first empty plot has y range between 1 and 10g does those value make sense for your data
2020,i didnt specify the ylim in that plot
2020,u think if i do it would be correct
2020,but a priori i cant know the limits on y
2020,what matt said is making my wonder if i understood you correctly you dont want to just reverse the axis
2020,you also want the accumulation to go from maximum value and increase by adding the decreasing values
2020,you also want the accumulation to go from maximum value and increase by adding the decreasing values edited yes basically start with the mass at the highest density and increase from there
2020,sorry if i was ambiguous
2020,ok i think its gonna be easier to achieve outside of profileplot give me a sec
2020,the idea is simple yet i couldnt formulate it well with the append quantities
2020,im trying to compute the data you want and create a mock profile plot out of it by saving it as a dataset but unfortunately im failing
2020,this is what ive got so far in terms of computing the values you want
2020,codesnippetimport ytfrom ytdata_objectsprofiles import create_profile from ytvisualizationprofile_plotter import profileplotds ytloadenzo_tiny_cosmologydd0046dd0046ad dsall_dataprof create_profile ad number_density n_bins64 fieldscell_mass weight_fieldcell_mass accumulationfalse logsnone do accumulation in reverse manuallydata profgas cell_mass1cumsumaxis01codesnippet
2020,wait thats probably wrong if you have weight
2020,user can you help
2020,user user yes am about to start teaching
2020,thank you so much for ur time any time will be fine thank u again
2020,this is what i ended up with
2020,codesnippetimport numpy as npimport ytfrom ytdata_objectsprofiles import create_profile ds ytloadenzo_tiny_cosmologydd0046dd0046ad dsall_dataprof create_profile ad number_density n_bins64 fieldscell_mass weight_fieldcell_mass accumulationfalse logsnone do accumulation in reverse manuallytemp npflipudproffield_datagas cell_massweight npflipudprofweightdata temp weightcumsumaxis0 weightcumsumaxis0 overwrite profile dataproffield_datagas cell_mass npflipuddata save as temporary datasetprofsave_as_datasetmy_profileh5prof_ds ytloadmy_profileh5 create a plot with modified profileplot ytprofileplotprof_dsdata none noneplotset_unitcell_massmsunplot_setup_plots reverse x axisfor p in plotplotsvalues paxesset_xlimpaxesget_xlim1plotsavecodesnippet
2020,the results are very confusing to me cause even though its an accumulation the curve is actually decreasing but i looked at codesnippet long enough that i think i know why its happening
2020,do you think it can be fixed do i wait for your reply
2019,user assigning the octree to the codesnippet dict worked as needed thanks again
2019,hooray
2019,in yt3x does setting codesnippet not impact the actual saved octree for example the followingcodesnippetimport ytload with no over refiningds ytloadsnapshot_094hdf5over_refine_factor0ad dsall_datasaved dsindexoct_handlersave_octreerefined savedoctreeprintlenrefinednow load with over refiningds ytloadsnapshot_094hdf5over_refine_factor2ad dsall_datasaved dsindexoct_handlersave_octreerefined savedoctreeprintlenrefinedcodesnippetresults incodesnippet179225179225codesnippet
2019,or is there a way to access a codesnippet array that reflects the over_refined cells
2019,related to this tangentiallyin yt 4x is there a way to access the same codesnippet array ie after creating the octree with something likecodesnippet octree dsoctreeleft right n_ref64codesnippetthough here it seems like the codesnippet doesnt have a key at least thats obvious to me for the codesnippet array
2019,hi all im working with some semistructured grid data and trying to make use of codesnippet data objects but the codesnippets dont seem to work properly when passed to the codesnippet argument of either codesnippet or when creating another data object creating the codesnippet works as it should but passing it to codesnippet has no effect im working from my own fork of codesnippet forked at commit codesnippet my changes were just bug fixes to the exodus ii frontend and hexahedral_connectivity
2019,user are you using exodus ii
2019,not anymore i used yt to convert it to hdf5 and now im just loading it in as semistructured following the docs
2019,user ah ok it may be that codesnippet is not working properly with the hexahedral stuff can you see if a cut region with the sample dataset does the same behavior and file a bug
2019,sample dataset as in the one used in the docs
2019,yup or one off the website
2019,hi i recently updated yt to 351 when i try to load my ramses data using just ds ytloadoutput_00001info_00001txt the error is that ramsesdataset object has no attribute bbox can anyone kindly tell me how to set the bbox and load ramses data in yt 351
2019,this sounds like a bug to me
2019,is there any chance you can share a dataset that triggers the issue you can upload files smaller than 5 gb using yt upload some_filetargz
2019,that will print out a url you can share in here
2019,let me try
2019,hi here is the url hyperlink
2019,thank you let me see if i can reproduce your issue
2019,thank you
2019,i can reproduce slightly_smiling_face
2019,let me see whats going on
2019,looks like its a oneline fix going to make a pull request
2019,thank you very much for the report
2019,thank you how can i get the fixed code i used pip to install yt on the cluster
2019,so a really hacky way to apply the fix would be to patch the installed version of yt on the cluster
2019,a better way would be to clone the yt git repository and pull from github to get the fix
2019,and build yt from source
2019,for the first case you can get the path to the installed copy of yt by printing codesnippet
2019,for the latter you can look at hyperlink
2019,do you have a github username
2019,yep its suniverse
2019,hyperlink
2019,thanks for bringing this to our attention slightly_smiling_face
2019,thank you
2019,user you can also do maxfield on a data object
2018,thats great thank you all again
2018,user you can get the image from the codesnippet attribute of the plot like this codesnippet
2018,that will be the image buffer you ant
2018,user what do you mean by plot timeaverage fields
2018,like for a slice or something
2018,if you mean that no there isnt a straightforward way to tell yt to calculate that at the moment although you could iterate over the datasets make a series of fixed resolution buffers then do the averaging yourself
2018,yeah exactly thats what i am currently doing at the moment but i wanted to see if there was some capability that i was missing out on thank you
2018,it would be cool to add more functionality like that
2018,if youd be interested in spitballing a design or even writing a little code this is something we could chat about in cbe6579czdevelopment or on the ytdev mailing list
2018,that sounds like a really neat feature
2018,better support for more advanced time series analysis has definitely come up in the past
2018,i actually would be interested we me and my advisor are potentially looking to do some advanced linear algebra on amr fields writing some code to make time average fields would be an excellent starting point
2018,i will send a shout to cbe6579czdevelopment whenever i get started on that work
2018,awesome looking forward to hearing more
2018,user that sounds so cool
2018,hey all and probably particularly user im trying to use ytree to stitch together the outlists from rockstar everything works fine so long as i stick within the ytree environment but id like to convert the data to another formatmost of this is working fine i can do codesnippet gives me the halos in that tree and i can use codesnippet to get the main branch which is what i need the problem is that i cant figure out how to go from a node to that nodes location in eg codesnippet even the codesnippet doesnt seem to match using the test data on yt hubcodesnippeta0tree uid1gtgt 342342 in auidastypeintgtgtgt falsecodesnippet
2018,is there any property of a given node that gives me a way without searching ideally for that halos location in the root fields
2018,hmm i thought i had this figured out via a derived fieldcodesnippetdef tree_indexfield data import yt return ytunitsyt_arrayytarray nparangedataarborsize dtypefloataadd_derived_fieldtreeindex tree_index unitscodesnippetbut the problem is that its recalculated for each tree so i just get codesnippet if i do codesnippet i also tried using an analysis field but it wouldnt let me directly assign except on a nodebynode basis as far as i can tell which isnt useful for my purposes ie i cant do codesnippet
2019,hi allhope all is well i was hoping you might give some advice on my analysis of some codesnippet simulations with codesnippetmy mesh is a cartesian uniform grid but i want to analyze average quantities vs radius in a yt disk objectcodesnippet ytdiskmy_center dsfind_maxdensity1my_disk dsdiskmy_center 00 00 10 8 r_earth 5 r_earthcodesnippetand then i believe the radius i should choose here is the codesnippetcodeblockbut the bounds of my profile are not from 0 8 but rathercodesnippet range of cylindrical_radiusprofilexin_cgs ytunitsr_earthin_cgscodesnippetcodesnippetytarray1427000956 143696463 1446997873 1457101171 1467275012 147751989 1487836299 1498224741 1508685717 1519219734 1529827303 1540508936 1551265151 1562096468 1573003413 1583986512 1595046298 1606183306 1617398076 162869115 1640063075 1651514402 1663045684 1674657481 1686350354 169812487 1709981598 1721921113 1733943993 1746050819 1758242179 1770518661 1782880861 1795329376 1807864811 1820487771 1833198867 1845998715 1858887936 1871867152 1884936992 1898098088 1911351079 1924696606 1938135314 1951667855 1965294883 1979017059 1992835046 2006749514 2020761136 2034870591 2049078561 2063385735 2077792805 2092300469 2106909429 2121620393 2136434072 2151351184 216637245 2181498599 2196730363 2212068478 dimensionless if instead of cylindrical_radius i use radius then the range of profilexin_cgs ytunitsr_earthin_cgs is not between 0 8 range of radiusprofilexin_cgs ytunitsr_earthin_cgsytarray006382166 006904446 007469467 008080727 008742008 009457405 010231346 011068622 011974416 012954336 014014446 01516131 016402026 017744276 019196368 020767292 02246677 024305325 026294337 028446118 030773989 03329236 03601682 038964235 04215285 045602403 049334248 053371486 05773911 062464155 067575872 073105903 07908848 085560638 092562442 100137233 108331904 11719718 12678794 137163555 148388252 160531516 173668516 187880574 203255668 219888973 237883455 257350504 278410628 301194194 32584224 352507344 38135457 412562492 446324295 482848976 522362631 565109863 611355288 661385181 715509239 774062507 837407447 905936181 dimensionless which makes me think that yt is actually using the spherical radius am i misunderstanding something here thanks so much in advance for anyall help
2019,yes radius is the spherical radius
2019,i dont know offhand if cylindrical_radius respects the center field parameter that might be the issue
2019,thats what my first guess is although i am not sure if this is a bug limitation or user error
2019,see if the values of codesnippet change after you do codesnippet
2019,also instead of going through the profile machinery it might be easier to reason about whats going on if you look at the field values in codesnippet explicitly
2019,finally if you can make a runnable example eg with imports loading a dataset or constructing one in memory one of us could take a look as well
2019,i believe there was at some point a conscious decision i cannot recall much of the context to not feed the center attribute of an object into the field parameters by default
2019,thats not true though
2019,i think
2019,i can confirm that codesnippet does not change codesnippet
2019,i will make a runnable example with a smaller data file than i am presently using and put it here
2019,codesnippetin 7 sp dsspheredsdomain_center 100dsunitskpc 10 kpcin 8 spradiustokpcminout8 unyt_quantity065855503 kpccodesnippet
2019,perhaps it was just for some objects like rectangular prisms or maybe i am completely offbase
2019,although it seems codesnippet works too
2019,codesnippetin 9 spcylindrical_radiustokpcminout9 unyt_quantity053770793 kpccodesnippet
2019,user did you start from a fresh interpreter you might have been getting cached data
2019,but yeah if you can make a runnable example that will make things less ambiguous
2019,
2019,
2019,user i did start from a fresh interpreter
2019,thanks so much for all the help everyone
2019,ah you know what i bet this is because of a periodic correction not doing the right thing
2019,yeah if i set codesnippet in your notebook i get an answer id expect
2019,ah and you know what i think i see where the bug is
2019,yup pr incoming thank you for the report
2019,user do you have a github handle
2019,ah thanks so much for the quick fix
2019,codesnippet is also my github username smile
2019,cool let me see if i can come up with a test using fake data and ill put in a pr
2019,hey user so this is a bit trickier than i thought im going to file an issue because i dont have a real fix for your specific issue you can get a quick fix by setting codesnippet after you load your data
2019,this quick fix is perfectly fine for my purposes
2018,im getting an error with export_sketchfab saying codesnippet even though i have copied the example here hyperlink
2018,further traceback here
2018,codesnippetfile xyzpy line 18 in ltmodulegt color_fieldradius file usrlocallibpython37sitepackagesytdata_objectsconstruction_data_containerspy line 1915 in export_sketchfab sample_type vertex no_ghost no_ghost file usrlocallibpython37sitepackagesytdata_objectsconstruction_data_containerspy line 1762 in export_ply color_field not in selfvertex_datacodesnippet
2018,hi user youre hitting a bug that was fixed back in may hyperlink
2018,im working on getting a new release out
2018,for now if you update to the development version of yt you can get the fix
2018,basically pip uninstall yt clone the repo then do pip install e in the repo more instructions here hyperlink
2018,happy to help out if you run into issues updating
2018,sorry for the trouble hopefully well have a new release out soon
2018,hi user i wasnt completely sure what to do with your message about the cell_mass coming up as zero in the phaseplot should i be able to pull the change 1850 using git somehow so i can make it phaseplot work
2018,i dont know i havent checked yet
2018,im working on fixing the travis tests before i look at that
2018,its possible that applying 1850 to your local copy will fix the issue
2018,i just havent actually checked that yet
2018,okay i will see if i can figure it out and let you know
2020,hi all did anyone use yt to determine the extent of a protostar like in greif 2012
2020,or if i want to overplot the contour of a certain density ie if i just want to see the radius at which the density is 1e10gcm3 only
2020,10e10
2020,hi i am not familiar with the work of greif you may be interested in the overplotting contours functionality hyperlink
2020,hey thanks for the reply i usedcodesnippetpannotate_sphere05 05 05 radius2 kpc circle_argscolorblackcodesnippethow do i set the center to be the maximum densitycentermax did not work
2020,you can first locate the maximum density using eg codesnippet where codesnippet is your data source eg codesnippet or codesnippet
2020,then you can use this as input to the codesnippet callback
2020,theres also dsfind_maxˋ fyi
2020,user has joined the channel
2019,user i totally recommend using the quickstart notebooks like ben kimock said theyre located here hyperlink if you need any help getting them up and running let us knowi also think the cookbook is has a lot of good examples of how to use some of the functionality in yt hyperlinkif you think theres anything confusing or that could be improved in the documentation please let us knowi think that the particular dataset you downloaded isnt used in the cookbook or the quickstart notebooks but there are several other datasets that are however theres a section in the documentation that goes over loading generic particle data here that might be helpful hyperlink
2018,also my dataset wasnt gizmo it was gadget i think we might have a multifile gadget snapshot in the yt data
2018,we could probably reproduce the issue with one of those but unfortunately they are quite large i think
2018,we dont have any in the hdf5 format but maybe it doesnt matter
2018,i suspect it doesnt
2018,but not sure
2018,what about codesnippet
2018,oh youre right
2018,thats also not super big
2018,i can check locally if that has the issue
2018,yes
2018,that reproduced it
2018,issue pls slightly_smiling_face
2018,in my case to reproduce the error i needed to have a new python instance but only tried a couple of times
2018,on it
2018,user hyperlink thanks for the report ill try to take a look soon
2018,and thanks for digging in ash slightly_smiling_face
2020,general question regarding the memory consumption of yt has somewhat to do with issue 2154 or issue 1909 how much memory usage should i expect for a dataset size s analysed on n nodes with n processors per node ie sn on each node would be great but my experience it is more sn but likely i am doing something far from optimal i know there was a discussion using dask at some stage but this is not the current status is it
2020,user has joined the channel
2020,hi ive tried to install my own yt fork in a separate conda environment i can do codesnippet and codesnippet and suchlike from the command line without a problem but whenever i try to import yt from within a python script i get this error codesnippet any idea what i can do to fix it thanks
2020,sounds like your fork was not installed correctly try codesnippet from within your fork env i suspect this will point to your base envs yt installation
2020,that returns codesnippet which is the fork environment
2020,in that case how do you run your python script
2020,ive tried running it from the command line and in a jupyter notebook using anaconda navigator it returns the same error in both cases
2020,when you say command line you mean within ipython im guessing
2020,if so did you make sure to install ipython and jupyter in your fork env
2020,theres an option to open environment in terminal from the anaconda navigator im not really sure beyond that but jupyter is definitely installed
2020,jupyter is based off ipython so i would definetly run codesnippet
2020,and codesnippet to double check
2020,they returned codesnippet and codesnippet
2020,hm and how did you install yt there
2020,i opened the environment in terminal via the anaconda navigator and then i followed the instructions for _building yt from source for condabased installs _hyperlink but cloning my fork rather than the main repository
2020,damn then i have no idea what could have gone wrong i have zero experience with the anaconda navigator so i dont understand ifhow that could be a source of problem
2020,thanks for the help anyway i might just try again with a new environment and see how that goes its the first time ive tried something like this so i could easily have made a mistake
2020,if it still doesnt work maybe open an issue on github documenting how you did it your pythonconda version might also give some clues i for one wouldnt be able to reproduce your setup since i dont have a windows machine but maybe someone else could sorry i couldnt figure it out
2018,user it happens in _setup_plots hyperlink
2018,user should i ask for helpfeedback on adding a yt feature for plotting arbitrary images in the issue or in cbe6579czdevelopment
2018,probably cbe6579czdevelopment
2018,but during the week
2018,ytdev mailing list is there too
2018,im trying to use ahf amigas halo finderthey need data in the gadget binary format which i do not have instead i have some hdf5 snapshots they provide a conversion script but to use it with our data would require some tenuous hackerycan yt help me here is there a way to save a dataset as the gadget binary formatfailing that does anyone know of documentation for that format im having trouble with my googlefu
2018,sorry yt doesnt do that
2018,maybe one day it will but its a seriously hard thing to do in general
2018,user might be able to help i know hes used ahf
2018,user has joined the channel
2018,user hey related to that question i had im adding tests now and realizing i dont know in the tests how to add the default unit objects to a given codesnippet should i be instantiating a codesnippet or maybe accessing an extant one and using that as the base for the tests
2018,sorry i dont quite understand what youre doing
2018,user i want a codesnippet with lots of unit object entries i dont see a test harness that does this
2018,the default codesnippet has stuff but not in unit object format
2018,yeah i dont think that exists yet
2018,ok
2018,you could see how the codesnippet singleton gets set up
2018,i think its just unitregistry
2018,and then you could add stuff to the default one
2018,yeah thats what i was hoping to avoid but ill go for it anyway
2018,ok maybe ill have a better suggestion when i look at your test
2018,it looks like the unitregistry class isnt really tested on its own
2018,hi user i know that people usually write their own conversion script me included i could share my python script with you if that helps one thing is that you do not need to convert all fields to the binary format for ahf to work that might make the conversion easier ive also tried to make a more general gadget format conversion tool but its not stable yet you could try if it works out of the box hyperlink
2018,user followup i would have expected everything that is in the lut to be instantiated and added to codesnippet but seems thats not the case i assume this is by design but i wondered if you could say why
2018,enh nm ill work around it
2018,i think codesnippet is just there as a cache its not necessarily fully populated at any given time the lut should be the source of truth
2018,ah ok
2018,for the last question the documentation is hyperlink section 6 note that theres a small difference between format 1 61 and format 2 62 for ahf both formats are accepted
2018,user is there stuff in codesnippet thats not in the codesnippet
2018,i dont know to be honest
2018,user i managed to get something hooked up to ahf but im running with the openmp configuration and its launched 32 threads but is only running on one any suggestions
2018,yikes
2018,codesnippetin 11 setlistreglutkeys listregunit_objskeys setlistreglutkeysout11 falsecodesnippet
2018,codesnippetin 12 setlistreglutkeys listregunit_objskeys setlistreglutkeysout12c2nm2 jkg na2 cm2 cm3gs2 cms cms2 dynecm2 ergs ergk ergcm2s1k4 ergg ftlbf lbfft2codesnippet
2018,ah i guess that makes sense
2018,these are all compound units
2018,the lut will only have atoms
2018,nm carry on slightly_smiling_face
2018,i havent encountered this issue myself just to clarify does the log file says codesnippet
2018,codesnippet cat test_log grep threadsnumber of threads in use 32codesnippet
2018,except that the other threads arent actually engaged in any work if i codesnippet with the pid of the ahf process all the other threads have 0 cpu time
2018,ah i have never done extra checking but to trust those numbers reported in the log file
2018,sorry i dont have enough knowledge to have useful comments on this probably you could ask it in the google group
2018,smile
2020,user has joined the channel
2020,hey ive been trying to access some files like this onehyperlinkbut the links just time out ive confirmed that its not just me experiencing this
2020,hey cj theres an issue on our end were fixing it now
2020,user its back up
2020,awesome thanks so much
2020,so it turns out that the critical density 3h²8pig is in physical units not comoving that will be a factor 1z³ in overdensity and thus originally the mean densities were only off by a few percent depending on redshift after allsweat_smile
2019,user has joined the channel
2019,hi i am yuxuan recently i dont know how to rescale the simulation snapshot data to another size and density scale this requires me to change the field value by a factor is there some simple codes that could do this
2019,is it possible to get a value range of variable i want to match the value range for several plots i can do this with codesnippet but i have to start with a kind of random guess for min and max
2019,user on a given data object you can call codesnippet and codesnippet when it does one it caches the results for both
2019,user so if i have a slice object codesnippet as codesnippet i can get the dataset by codesnippet but codesnippet causes codesnippet
2019,user from a slice object you can do codesnippet to get the actual slice a data object is distinct from a data set in that the data object is a slice a rectangular prism a sphere etc
2019,codesnippet is my variable name codesnippet returns 1e90 dimensionless whereas the data structure with which the slice object was created has the maximum value of 015 i used codesnippet
2019,user grabbing codesnippet is a good way to get it for the full source i am not really sure why its giving that value for the max on the slice thats quite strange to me but probably specific to the unstructured mesh implementation
2019,user thank you my original mesh is unstructured in 3d but all the elements are triangles the dimensionality of the yt dataset is 2 i checked with a 3d unstructured mesh and the min and max values are reasonable the projection of triangles to slice could be doing something
2019,user i just got max or min values with codesnippet or codesnippet the data on the slice is the same as original 2d data so this just worked
2019,user oh good
2019,user thank you for your help
2019,when i have these two lines for a slice plotcodesnippetslcsaveplot_with_suffix suffixjpgslcsaveplot_with_mpl_kwargs mpl_kwargsformat jpgcodesnippet both generate a png file instead of jpeg file i believe matplotlib supports the jpeg format how could i select the format correctly
2019,so codesnippet is pretty awesome but it only works on units is there any interest in having such a thing for quantities im imagining something that would make it really easy to write a python script that emits latex that i can just paste into a paper
2018,user has joined the channel
2020,i am not having this issue with the fake data
2020,i found that when i use codesnippet this issue arises
2020,also in the test case
2018,user has joined the channel
2018,hi yt friends im wondering if particleprojectionplot is supposed to consider periodic boundary conditions and if theres anything that needs to be configured to achieve that im doing a naive experiment but failed
2018,codesnippetimport ytds ytloadgizmo_64outputsnap_n64l16_093hdf5center dsdomain_width 0618ytparticleprojectionplotds z particle_mass centercentersavecodesnippet
2018,
2018,i dont think it does
2018,i also dont think it would be terribly hard to fix that
2018,user thanks for the information ill submit an enhancement proposal on yt then
2018,the code to look at is the codesnippet class in codesnippet
2018,no need to submit a ytep just open a pr
2018,sure
2018,id like to work on it but maybe two weeks later gotta focus on some other things before that
2018,no worries any time slightly_smiling_face
2018,sorry it didnt work for your use case out of the box confused
2018,hi when i try to load the rasmes data file using ds ytloaddatafieldsmy_field to give the variables correct names yt interpret many variables as dimensionless quantities it there a way for me to manually give then the right dimension while loading the data
2018,no not easily unfortunately this is something that were planning to fix for yt 40 along with a significant reworking of the field system in general
2018,usually what i suggest as a workaround is to define alias fields like this
2018,codesnippetdef density_aliasfield data return datadsarrdataramses on_disk_field gcm3dsadd_fieldgas density_alias functiondensity_alias unitsgcm3 sampling_typecellcodesnippet
2018,you can put those in your plugin file so you dont need to add them to every script
2018,hyperlink
2019,you can attach units to these
2019,ie 15 15 15 kpc but i presume they default to code_length
2019,i think you want gas density not particle_density
2019,is it particle_density in the documentation
2019,ah i think i interpreted the dsload_particle docmuentation poorly i thought it suggests i should put particle_ before each field codeblock
2019,ah i guess those docs need to be updated to have a discussion about sph data
2019,i think bili has an example you can look at in a pr hes working on
2019,hyperlink
2019,i think you need particle_mass particle_position and smoothing_length and yt should be able to generate a density field
2019,bilis pr might be exactly what youre looking for if you dont have smoothing lengths already
2019,anyway sorry this is a little confusing this is what happens when lots of people start using beta level software confused
2019,reports and fixes are greatly appreciated were still not really ready to do an official yt 40 release and beta testing is very useful but only if we get feedback about whats broken
2019,user how do i include units when i try codesnippet i get codesnippet
2019,hm i thought that would work maybe user knows
2019,no worries on the confusion just really appreciate this slack channel exists
2019,i think you need to do this
2019,you can do codesnippet
2019,codesnippetfrom ytunits import kpcleft_edge 0 0 0kpcright_edge 99 99 99kpcag dsarbitrary_gridleft_edge right_edge dims1283codesnippet
2019,not everything needs to be a oneliner slightly_smiling_face
2019,im making a pr to add dsunits too along with a bunch of other goodies
2019,hyperlink
2019,the shape of the density grid is still confusing following users example for generating the arbitrary grid then codesnippet and printing the shapes of eachcodesnippetarbitrary grid shape 128 128 128density grid shape 135 codesnippet
2019,what is the codesnippet
2019,changing the codesnippet from codesnippet to codesnippet made it so yt could calculated the codesnippet
2019,i see what frontend is this
2019,following the bilis example notebook
2019,can you share your code
2019,what do you mean by frontend
2019,theyre using load_particles
2019,if you make a short runnable example one of us could run that would help
2019,that way one of us can run it locally and tell you what exactly is going wrong
2019,you can make rake random data using eg nprandom
2019,i think what matters here is the field names youre using
2019,you need to use a very specific set of field names right now to trigger what you want to happen in yts field system
2019,hyperlink
2019,so this is a really huge example
2019,can you make it more minimal
2019,please dont judge innocent
2019,and only use yt
2019,oh sure give me a bit im a bit slow
2019,let me take a look at your full code and see if i can understand but in general its much better to share what stackoverflow calls an mcve hyperlink
2019,often in the process of generating an mcve you figure out whats going wrong
2019,i think you might be hitting a bug though i dont see anything obviously wrong with your code
2019,if you can make an mcve and file an issue on github one of us can take a look that will also allow us to escape this slack thread
2019,im going to bike into work
2019,looks like its an issue with the cluster not loading the correct version of yt womanfacepalming
2019,ah that behavior would make sense on an old yt version glad to hear it got sorted slightly_smiling_face
2019,for some codes here im looking at a gadget 3 code the unit unitary doesnt seem to be doing what i expect it to do codesnippet are points in r3 which are the start and end of a trident sightlinecodesnippetprint startprint endprint startin_unitskpcprint endin_unitskpcprint startin_unitsunitaryprint endin_unitsunitaryprint startin_unitscode_lengthprint endin_unitscode_length 2995018959 3056563377 tel4719144020147191440201 kpccmh 39661849768 70358215356 462071636703 kpccmh 383224448 391099298 60383302643 kpc 5074889573 9002610205 59123882134 kpc 049916983 050942723 7865240033 unitary 661030829 1172636923 7701193945 unitary 2995018959 3056563377 tel4719144020147191440201 code_length 39661849768 70358215356 462071636703 code_lengthcodesnippetthen when it goes into trident it has a codesnippet which i think basically comes from codesnippet not being in between 0 and 1 as expected is there a way to change that in place while running redefine codesnippet or where can i go to fix it in the source codethanks
2019,unitary gets defined here hyperlink
2019,it should be equivalent to codesnippet
2019,ie 1 in unitary units is the size of the longest edge of the domain
2019,for a dataset where this is happening what is codesnippet
2019,and whats codesnippet
2019,codesnippetprint dsquan1unitarytokpcprint hyperlinkkpc7677235835829029 kpc767723584 767723584 767723584 kpccodesnippet
2019,do you think it has something to do with being comoving
2019,i mean is that the domain width youd expect
2019,i dont know anything about this data
2019,no that seems way too small for this
2019,is this dataset from a really high redshift
2019,this is at z10
2019,ah then i think that makes more sense particularly for a zoomin
2019,where are codesnippet and codesnippet coming from
2019,because it seems like youre using a codesnippet and codesnippet that are outside your domain
2019,which trident is complaining about
2019,that is possible though i feel like the box itself should be big enough to handle it is yt just using the farthest sph particles to determine the boundary of the simulation i assumed it was using the whole box
2019,its coming from the header for gadget cosmology simulations
2019,the boxsize parameter
2019,hyperlink
2019,ok ill look into that and where it defines unitary maybe ill need to keep my sightlines smaller until we get into more galaxy level redshifts thanks nathan
2019,user you could always create your own bounding box for the data when you read it in instead of relying on yt to figure it out that way you could arbitrarily specify a really large bounding box and not run into this issue of having startendpoints for the trident ray outside of the domain
2019,or choose a codesnippet and codesnippet thats always inside your box
2019,eg specify it in comoving coordinates
2019,hyperlink
2019,also if yt is generating a bounding box that doesnt enclose all your data that sounds like a bug to me
2019,on either the yt or gadget side
2019,well it could just be that user is specifying some arbitrary points that are outside of the domain i dunno
2019,yeah i dont think they ever said
2019,i asked a couple times where start and end were coming from
2019,yeah they were just randomly generated it does look like it works if you restrict it sufficiently this is what it looks like i think clearly a trident sightline outside this box would be kind of a waste anyways so ill probably try harder to determine a realistic impact parameter instead of just redefining the box thats a good suggestion though user
2019,what is the goal clayton is this for agora is it just to get a bunch of random sightlines at different impact parameters from the center of the galaxy
2020,user has joined the channel
2020,user has joined the channel
2018,hi i wanted to add a field to yt to calculate a vector cross product but yt does not recognize the vector as an array with shape of 3 instead it reads it as a float value how can i fix it here is the code with a yt test dataset
2018,
2018,
2018,when yt does a projection in say the z direction and the code coordinates go from 0 to 1 does the projection go from 0 in the front to 1 in the back or 1 in the front and 0 in the back
2018,i think it does it in io order so neither
2018,in what context would it matter
2019,user has joined the channel
2019,im having a bit of trouble trying to get the halo catalog to work with my data for some bizarre reason is this the right place to ask about this
2019,sure ask away
2019,great thanks i ran ahf on my data and have been excited to use yts built in containers for halos since i use yt for my gizmo runs i wanted to test everything out so i did exactly what is shown here in the only cell under that heading hyperlinki can successfully print the particle_mass and virial_radius of the halos however when i try to do more complex analysis such as combining the dataset and halos dataset to create a halo catalog such as here hyperlinki get the first problem with a warning when i call halocatalogdata_ds data_ds halos_ds halos_dsyt warning 20190226 093010474 halo dataset testv010snapshot_296hdf5parameter has no field halos particle_identifierthis happens for many of the fields i think all of them however as i said above i can print out halos_adhalos particle_identifier and see it fine where halos_ad halos_dsall_datadoes ahf work with the halocatalog module
2019,i have sample data i could upload it to dropbox if necessary for reproducibility
2019,i should also add that if i call hccreate it throws an exception that those fields do not exist and does not continue
2019,so i dont know much about the halo catalog machinery user may know more but the issue seems to be that the catalog generated by ahf doesnt have ids or yt isnt reading them
2019,its actually all of the fields here is the full warningyt warning 20190226 093010474 halo dataset testv010snapshot_296hdf5parameter has no field halos particle_identifieryt warning 20190226 093010494 halo dataset testv010snapshot_296hdf5parameter has no field halos particle_massyt warning 20190226 093010494 halo dataset testv010snapshot_296hdf5parameter has no field halos particle_position_xyt warning 20190226 093010494 halo dataset testv010snapshot_296hdf5parameter has no field halos particle_position_yyt warning 20190226 093010494 halo dataset testv010snapshot_296hdf5parameter has no field halos particle_position_zyt warning 20190226 093010495 halo dataset testv010snapshot_296hdf5parameter has no field halos virial_radiusbut as i said if i directly access the halos_dsall_data i can output them
2019,also user added the ahf frontend so he might know more as well
2019,maybe you could pastebin the full output of what youre seeing
2019,along with the script youre running
2019,sure i can do that
2019,hyperlinki should note im using python 371 and yt 350 maybe 35 is the issue and i should revert back to 341
2019,i also tried python 371 with yt 351 and the ytastrophysical analysis package 11dev and got the exact same errors as above
2019,can you also pastebin the output of codesnippet
2019,britton and bili are on the west coast so they might not respond for a little while
2019,hyperlink
2019,so indeed it is missing those fields
2019,or i guess it might be in derived_field_list
2019,yes it is in there
2019,yeah i dunno offhand if this is an issue with the frontend or is particular to the dataset youre looking at
2019,it looks like we do have an ahf dataset on hyperlink
2019,does this work for that dataset
2019,hyperlink which was generated using hyperlink
2019,thanks i was wondering about the sim data
2019,ill try it out now
2019,hi user i havent had time to read through this yet and ive got a pretty busy day ahead of me here but ill try to have a look at this at some point soon
2019,thank you very much
2019,the sample data for ahf halosgizmo dataset gives the exact same error
2019,ah great
2019,can you share your script using those datasets
2019,just want to make sure im doing exactly what youre doing
2019,hyperlink
2019,i used the astro_analysis package
2019,but the same thing happens with with the other package that is now deprecated or futuredeprecated
2019,ytanalysis_modules is deprecated yes
2019,thanks for the report im trying to reproduce now
2019,i believe the appropriate portmanteau is fuprecated
2019,ok heres the test script
2019,codesnippetimport ytfrom ytextensionsastro_analysishalo_analysisapi import halocataloghalos_ds ytloadahf_halossnap_n64l16_135parameter hubble_constant07data_ds ytloadgizmo_64outputsnap_n64l16_135hdf5hc halocatalogdata_dsdata_ds halos_dshalos_dshccreatecodesnippet
2019,and i can reproduce
2019,thanks for looking into this
2019,lol
2019,this is an easy fix
2019,pr incoming
2019,is it not looking in derived_field_list
2019,nope
2019,ill add a test too
2019,great
2019,hmm actually no test this is hard to test from the yt_astro_analysis side with real data
2019,hyperlink
2019,easiest way to get that is probably to install yt_astro_analysis from source and make the change yourself
2019,eg clone the git repo and do pip install e inside
2019,you could probably also edit the version of yt_astro_analysis you have installed too but thats way hackier slightly_smiling_face
2019,yeah i was going to do the dirty trick
2019,go right into sitepackages and then forget about it in the future
2019,seems to work great got a halo mass function pretty quickly
2019,i get the following error when running the above code i guess this is another bug reporthyperlink
2019,i think you might have gotten the paths backwards
2019,oops i copied the code incorrectly i used the correct paths in my code flushed
2019,i pasted my paths incorrectly into the example on the documentation but if you swap them you will get the error
2019,ah this is a yt bug for sure
2019,user hyperlink
2019,great thanks ill integrate this into mine slightly_smiling_face
2019,im probably going to go through most of these examples for the next hour and see if everything works is it okay if i keep pushing bug reports in here
2019,sure
2018,user has joined the channel
2018,how do i create a single float with units kpccm
2018,codesnippet
2018,i want to add codesnippet so you can do codesnippet or something like that slightly_smiling_face
2018,hm why does it require that i have a dataset loaded
2018,because it depends on the redshift
2018,theres no constructor for a codesnippet or codesnippet type that takes a redshift that i can callthe requirement for a dataset is all fine and good for what im doing _at the moment_ but im curious
2018,right it all gets set up inside the codesnippet class itself let me point you at the relevant bit of code
2018,hyperlink
2018,this is also how eg codesnippet works
2018,hi all i would like to modify the axis center and the scaling of the axis in the follwing example using an frb hyperlink what are the commands that can do that thanks
2018,also is it possible to add an integrate obtion toproj dsprojdensity 0
2018,sorry can you explain a little bit more what you mean by axis center and scaling of the axis
2018,yes add codesnippet to the call to codesnippet
2018,i think i found the answer to my first question here hyperlink let me try this and i will get back thanks
2018,user i think the integrate method is default no
2018,yup it is
2018,the extent argument does what i want with regards to adjusting the axis limits and adjusting the axis orgin to the right numbers and location without messing with the aspect ratio
2018,so thats good
2018,1
2018,since extend only modifies xmin and xmax ymin and ymax and does some autoscaling what would be the correct way to modify the x and y ticks as well as the x and y labels thnks
2018,something like this hyperlink
2018,or hyperlink
2018,i used a linspace previously to define the ticks it did not work but a list works
2018,arange works also but i have bad experience with arange
2018,do you know why linspace does not work
2018,not offhand no
2018,id need to see an example triggering the issue and poke at it locally probably
2018,ok makes sense understanding this issue is not my highest priority at the moment since this works i need to move on to other things and come back to this later thank you though
2018,hey all im trying to make a proj plot in yt 3x and change the label on the colorbarcodesnippetplot pxplotsdepositparttype0_smoothed_densityplotcaxyaxisset_label_textn_h g cm2pxsaveprojxpngcodesnippetand getcodesnippettraceback most recent call last file projection_octreepy line 20 in ltmodulegt plot pxplotsdepositparttype0_smoothed_densitycodesnippeti looked around the docs and didnt see how to do this but maybe i missed it
2018,do you get more to that error
2018,pxplots is a dict but youre accessing it like a function
2018,is that the problem
2018,the entire traceback iscodesnippetdesikanarayananlogin4 attenuation_laws more projehomedesikanarayananminiconda3envsmypy2envlibpython27sitepackagesh5py__init__py36 futurewarning conversion of the second argument of issubdtype from codesnippet to codesnippet is deprecated in future it will be treated as codesnippet from _conv import register_converters as _register_convertersyt info 20180911 085522342 calculating time from 9756e01 to be 4263e17 secondsyt info 20180911 085522343 assuming length units are in kpch comovingyt info 20180911 085522358 parameters current_time 4263438511011124e17 syt info 20180911 085522358 parameters domain_dimensions 4 4 4yt info 20180911 085522359 parameters domain_left_edge 0 0 0yt info 20180911 085522359 parameters domain_right_edge 50000 50000 50000yt info 20180911 085522359 parameters cosmological_simulation 1yt info 20180911 085522359 parameters current_redshift 002499995903287333yt info 20180911 085522359 parameters omega_lambda 07yt info 20180911 085522359 parameters omega_matter 03yt info 20180911 085522359 parameters hubble_constant 068yt info 20180911 085522362 allocating for 1551e08 particles index particle type allyt info 20180911 085545393 identified 2181e07 octsyt info 20180911 130357411 max value is 520419e20 at 280731499195098876953 222617685794830322266 285307705402374267578yt info 20180911 171435282 projection completedyt info 20180911 171435299 xlim 22181340925 22320740919yt info 20180911 171435299 ylim 28461739948 28601139942yt info 20180911 171435300 xlim 22181340925 22320740919yt info 20180911 171435300 ylim 28461739948 28601139942yt info 20180911 171435307 making a fixed resolution buffer of deposit parttype0_smoothed_density 800 by 800traceback most recent call last file projection_octreepy line 20 in ltmodulegt plot pxplotsdepositparttype0_smoothed_densitytypeerror plotdictionary object is not callablecodesnippet
2018,ah sorry i didnt realize i hadnt pasted the full traceback before posted before i had my coffee
2018,ah so should it becodesnippetpxplotsdepositparttype0_smoothed_densitycodesnippet
2018,removing one set of codeblock
2018,yup
2018,thats what the error message at the bottom says
2018,is there a way to control the minmax of the color scale in a projectionplot i have a series of plots and i want the colors to always correspond to the same values instead of shifting around slightly between plots
2018,the codesnippet callback does the job heres an example hyperlink need to scroll down to the last one in this section
2018,hey im trying to make phase plots using a yt covering grid but it fails with error codesnippet i assume i have to do it by hand
2018,is this with yt40
2018,no thats 35amr dataset
2018,as the error message says thats not implemented why not use a region data object with the same bounds as the covering grid
2018,in principle it could work in a manner analogous to the cut region selector but it would need to be wired up
2018,probably simpler actually because you could just use the selector of the region that covers the same volume
2018,the issue is that i need the velocity divergence which is not implemented for amr
2018,ah i see
2018,it would work if you used codesnippet i think
2018,on the covering grid
2018,and reloaded the data as a dataset
2018,ok
2018,i actually got around the issue using meshonparticle deposition similar to hyperlink
2018,btw i havent forgotten about your pr
2018,ive been focussing on getting 35 out the dor
2018,im trying to save a vr image demesh ytcodesnippetsc ytcreate_sceneds2sccamerazoom2scsavedpi300codesnippetbut the code doesnt like the dpi300 is there an obvious way to increase the resolution
2018,im trying to make an image for a lorentz workshop poster
2018,user that particle filter code you suggested which version of yt are you running it on
2018,user codesnippet
2018,there isnt a concept of a dpi in the volume rendering machinery
2018,ah thanks
2018,fwiw the vr machinery is super nice
2018,hi nathan
2018,can you give me any guidance on how to add change 1850 to my yt
2018,i dont think i have a local copy i just merge from github
2018,user im on the dev version of yt but this _should_ work on 34
2018,user i dont understand what your last message means
2018,how did you install yt from a checkout of the repo
2018,1850 is merged so you just need to pull on the master branch
2018,sure dont worry
2018,in the meantime im using a slower yet working version
2018,user hm okay then i guess i dont understand your comment for issue 2048
2018,hyperlink
2018,what about it
2018,i just ran the test script from the issue on the current master branch and didnt see the behavior kacper reported
2018,so i concluded its fixed
2018,probably by merging 1850
2018,is current master branch yt 35dev0
2018,maybe my problem is that i am not on the stable yt
2018,no its not the stable version
2018,its the development version
2018,the version number we give you 35dev0 on the development version doesnt change so it could be the right version
2018,it might also not be
2018,the only want to check is to go to your clone of the repo
2018,do git checkout master
2018,git pull origin master
2018,then pip install e
2018,that will ensure youre on the latest version
2018,and this should not wreck the clump stuff britton fixed because it is on the master
2018,brittons pr is also merged
2018,i dont need your fix at the moment i did a workaround
2018,ok
2018,when i typed git checkout master i got told
2018,already on master
2018,your branch is ahead of originmaster by 3 commits
2018,should i still go for git pull origin master etc
2018,sorry that was confusing by your fix i meant the clump fix about the info_items i am still having cut_region problems
2018,the ones reported in 2048
2018,ugh sorry have to parent will try and come back to bashing my head against this tonight thanks as always for all your help
2018,user has joined the channel
2018,yes you need to pull and then recompile
2018,user just to followup and make sure i get everything the command
2018,pip install e
2018,will recompile yt
2018,it worked thanks user
2020,user has joined the channel
2020,sorta quick question how is codesnippet defined in yt i think its something like codesnippet but im not sure wherewhen this bulk velocity is defined and how
2018,user has joined the channel
2018,i see theres a note about amiga support in the 34 release notes wheres the documentation for this feature
2018,hyperlink
2018,does yt not have a traditional searchable api reference
2018,i instinctively look for it
2018,it does but that wont help you here
2018,heres yts api reference
2018,hyperlink
2018,because codesnippet has a dynamic return type
2018,yeah although i guess we should probably include the ahfdataset class in the api docs
2018,i guess we missed that when we added the frontend
2018,the things that show up in the api doc search need to be added manually
2018,thats awkward
2018,heres the pr that added the ahf frontend
2018,hyperlink
2018,user do you have a github handle
2018,saethlin
2018,just opened a pr thanks for reporting the issue
2018,ok_hand
2019,is there an nchilada front end to yt
2019,also im not sure if its grammatically correct to say an nchilada or a nchilada
2018,i just issued a pr for this hyperlink i hope it doesnt break anything
2019,user has joined the channel
2020,user has joined the channel
2020,user has joined the channel
2020,user has joined the channel
2018,btw is there something fancy to do to install the yt40 branch im struggling to codesnippet it
2018,yup
2018,hyperlink
2018,courtesy of user
2018,there is also a c046hvb59particles channel which is generally used to discuss yt40 stuff
2018,yeah sorry thats hard right now i really need to do the packaging for cykdtree properly
2018,thats the big pain point atm
2018,or at least make the error nicer
2018,isnt it available on pip
2018,not the version that we need
2018,can you do codesnippet
2018,is that easier to include in the instructions maybe
2018,id prefer people have the repo checked out but yeah that would work too
2018,just on general principle slightly_smiling_face
2018,i like setting people up to be able to hack on code if theyd like
2018,good point
2018,user user how do you manage to switch between different version of yt
2018,right now im doing checkout then reinstall but thats cumbersome when jumping from eg yt 35 and yt 4
2018,i have two repos cloned
2018,same otherwise the build takes ages
2018,yeah theres a lot of differences in c code
2018,i think user has some bash shell helpers that he uses to switch back and forth quickly
2018,i just manually do pip uninstall yt
2018,then pip install e in whichever one i want to activate
2018,i just do python3 setuppy develop in the repo i want to activate
2018,user yeah i have these functions in my zshrc
2018,codesnippetalias apy3source activate homemturkcondapy3alias apy2source activate homemturkcondapy2ppbr pphomeyt1 if d pp ampamp echo pp doesnt exist ampamp return export pythonpathpp echo pythonpathpythonpath export ytpathpp export ytname1 setpromptppbr ytcodesnippet
2018,i like that codesnippet alias im gonna steal that
2018,you should steal the codesnippet stuck_out_tongue
2018,cool thanks
2018,another question then how do you do that on the yt40 branch
2018,this is specifically for sph data
2018,because theres no global octree mesh anymore
2018,if you do codesnippet in the yt40 branch for sph data you get back data at the particle positions
2018,does that work if you do codesnippet
2018,yup
2018,ah yeah not just sph data
2018,all the particle frontends
2018,although codesnippet isnt defined for a pureparticle dataset
2018,im confused
2018,you can load an sph dataset using codesnippet if you pass in a codesnippet field
2018,about what
2018,more details about all this in hyperlink as well
2019,user has joined the channel
2019,user has joined the channel
2020,agreed i am superpsyched too slightly_smiling_face
2018,hi guys is there a current work around for this issue hyperlink
2018,i am getting the same error on an amrex dataset
2018,it also only happens when my datasets are too large
2018,hey so this should be fixed if you pull the latest updates from the yt40 branch let me know if it isnt
2018,user the url at the bottom of the splash paper doesnt work anymore is the original splash code out there somewhere i think i found where the cython code that uses splash is in yt but im just curious if i can read the original
2018,hyperlink
2018,you are looking for splash source code
2018,we dont use splash in yt fwiw
2018,we use some of the algorithms from splash
2018,im interested in learning about how my pretty plots are made so i have this nice splash paper but for my brain its really helpful to see the code that implements these quations and there doesnt seem to be a very clear mapping in the yt codebase ill check out that url
2018,yeah that i didnt take the equations from the splash source code i got them from the paper the splash source code isnt that readable it is on github if you want to look at it or try it out
2018,hyperlink
2018,yeah already got to the repo
2018,fortran
2018,heres the code hyperlink
2018,the yt implementation
2018,codesnippet in that function is an instance of codesnippet which is where most of the complicated bits are isolated to
2018,we use a lookup table to evaluate the projected sph kernel as a function of the impact parameter
2018,so for each pixel that a particle could contribute to by comparing the distance from the particle to the pixel under consideration you loop over the pixels and calculate the projected sph kernel and then add that particles contribution to the pixel
2018,then you loop over all the particles that might contribute to the image
2018,i really should write the paper
2018,this is section 431 in the splash method paper
2018,we use a different definition of the smoothing kernel following gadget in yt than what dan price uses so theres some factors of two that are different in the paper and the yt source
2018,hyperlink
2018,thanks for the directions
2018,i think the yt patch to fix the multiparticle datasets works but yt still isnt cooperating with what im trying to accomplish
2018,if you can share more detail about what problems youre having we might be able to advise
2018,im still triplechecking but heres the code im working with
2018,
2018,the objective is to make a density plot that only includes particles that are part of a particular galaxy
2018,sure i dont see anything obviously wrong with that code but i havent used caesar much
2018,whats going wrong
2018,output looks like this right now
2018,well thats not right slightly_smiling_face
2018,is there any chance you can share those two data files so i can try to reproduce the issue
2018,my extremelynaive projection code produces this
2018,gah
2018,if i had to guess youre hitting a bug in yt that we should fix slightly_smiling_face
2018,actually instead of sharing im going to try to reproduce on my end with the yt gizmo data
2018,its probably something like were not using the correct smoothing lengths
2018,ah yeah that would work too slightly_smiling_face
2018,thanks in advance for the report hyperlink
2018,i have actually had some issues recently with particle filters and some yt40 stuff
2018,my code was actually erroring rather than producing strange output
2018,i suspect theres at least one mistake on my end because ive gotten dubious output from yt34 as well
2018,im not sure it would necessarily give you a sensible output in 34 either
2018,the bookmark i made for the yt data hub thing doesnt work can somebody give me a link
2018,hyperlink
2018,hyperlink is down atm because of a power outage this morning at uiuc
2018,that would explain a lot
2018,but hyperlink is hosted elsewhere
2018,ive got some stuff do just now but i can try and see if i get weird stuff with a dataset i have locally in about 30 mins hopefully we can get this sorted
2018,also out of curiosity does the projection work ok for just a gas density
2018,if i dont attempt any filtering it looks perfect
2018,i bet its using the codesnippet values
2018,just a guess though slightly_smiling_face
2018,i wouldnt be surprised if we are using ds_sph_ptype to grab those
2018,which would be bad
2018,we are
2018,line 136 of off_axis_projectionpy
2018,yeah so right there we need to check if weve been given a sph particle type or a particle filter derived from one
2018,which may need some kind of flag somewhere
2018,i dont remember offhand if we already have a way of figuring that out
2018,im writing up an issue for this
2018,there is a check in that file but clearly that check isnt working
2018,ill try and debug that check in principle once that is fixed and we use the field0 and not ptype that should be good to go
2018,hyperlink
2018,i think i have a fix but will let you know in 5 mins fingers crossed
2018,that would be _awesome_
2018,seems to work locally
2018,ill make a pr
2018,heres a link this is the only change ive made
2018,hyperlink
2018,feel free to try locally
2018,the issue was that the code was essentially hardcoded to grab a bunch of data using codesnippetas the particle type which is parttype0 in this case so it was bypassing the particle filter
2018,it works
2018,woo hoo awesome let us know when you find more bugs
2018,user yup keep the bug reports coming
2018,and if you see yt doing something weird theres a strong possibility its yts fault not yours
2018,awesome thread to follow
2018,im not convinced the precise image values coming out when i do the density projection are correct needs more checking but this may not be totally over
2018,ok fair enough love to hear more slightly_smiling_face
2018,thanks for working with us
2018,opening an issue
2018,hyperlink
2018,smells like a normalization issue to me but im not sure where to hunt
2020,try this codesnippet
2020,hi user sorry i didnt see this until now glad you got it working and thanks for posting an example of what you did i will be doing some runs on stampede2 in the near future
2019,no i meant doing something like thiscodesnippetts ytdatasetseriesdd0030dd0030 dd0040dd0040codesnippetthis will work for frontends for which the codesnippet functionality is not supported which is most of them
2019,user has joined the channel
2019,hii am looking to better understand how profile plots work specifically when i use ytcreate_profile the total sum of all the yvalues varies depending on the number of bins used i was hoping that they would total to the actual total of that quantity is there a way to make that happen or an explanation for why it cantthanks
2019,user im not sure i follow can you explain more how youre comparing and what you expect
2019,ah i see thanks
2019,i havead dsall_data profile ytcreate_profilead n_e fieldsy2 n_binswhere n_e and y2 are derived fields and i vary n_binsthen i takesumprofiley2i was hoping this sum would be equal tosumady2but it is not and varies with the number of binsi was hoping to clarify why this works this way i originally noticed the problem when making two profile plots with different x terms but the same y term and noticed the axis scales were different by a couple orders of magnitudehope that is clearer thank you
2019,user what do you specify the codesnippet to be
2019,i have not been actively specifying it
2019,user so i think that you should try specifying it as codesnippet to make sure its defaulting to summation
2019,thats what i was looking for thanks so much
2017,thank you guys this helps a lot
2017,glad to help
2019,this might be a naive question but in the haloanalysis modules is it possibly to know the stellar mass within the halos it seems that you can use the callback functionality to calculate gas properties but not the stellar properties for example it would be great to calculate the galaxy stellar mass function if anyone knows thanks
2019,hi doug sure you can make a callback to do particle properties as well
2019,something like the following
2019,codesnippetdef stellar_masshalo sphere halodata_object return spherestar particle_masssumadd_quantitystellar_mass stellar_masscodesnippet
2019,this is assuming you had a sphere callback defined earlier in your halo pipeline sou you might have something like thiscodesnippethc halocataloghcadd_callbackspherehcadd_quantitystellar_masscodesnippet
2019,does that make sense
2019,thank you britton it does except for sphere halodata_object
2019,how does it know data_object is the sphere
2019,ah right great question the codesnippet callback creates a sphere data container centered on the halo with the radius set to the virial radius it attaches that sphere object to the halo object as codesnippet
2019,so if you add that codesnippet first in your pipeline that object will be available to you in your stellar_mass function
2019,fantastic thanks so much could i ask one more question what if i wanted other quantities such as those within r500r2500 instead of just the virial radius can i add more sphere callbacks
2019,i suppose they would just have to go into separate halo catalogs
2019,with quantities based on r200r500r2500 etc
2019,yeah totally there is a recipe for calculating properties at different critical density valueshyperlink
2019,you can then use those new values to alter the behavior of the sphere callback
2019,arg looking for documentation we really need to improve these docs thats on me
2019,anyway the virial_quantities recipe will give you new fields like codesnippet that you can then tell the sphere callback to use
2019,fantastic i have a problem though with the stellar mass callback and it may be because im using yt_astro_analysis instead of the yt project haloanalysis module
2019,codesnippetpythontypeerror traceback most recent call lastltipythoninput106b9262d90adcgt in ltmodulegtgt 1 hccreateprojectbbabulrennehananaconda3envspynbodylibpython36sitepackagesyt_astro_analysishalo_analysishalo_catalogpy in createself save_halos save_catalog njobs dynamic 335 336 gt 337 self_runsave_halos save_catalog njobsnjobs dynamicdynamic 338 339 def loadself save_halostrue save_catalogfalse njobs1 dynamicfalseprojectbbabulrennehananaconda3envspynbodylibpython36sitepackagesytutilitiesparallel_toolsparallel_analysis_interfacepy in barrierizeargs kwargs 299 def barrierizeargs kwargs 300 if not parallel_capablegt 301 return funcargs kwargs 302 mylogdebugentering barrier before s func__name__ 303 comm _get_commargsprojectbbabulrennehananaconda3envspynbodylibpython36sitepackagesyt_astro_analysishalo_analysishalo_catalogpy in _runself save_halos save_catalog njobs dynamic 451 selfdata_sourcequantityinti 452 elif callablequantitygt 453 new_haloquantitieskey quantitynew_halo 454 else 455 raise runtimeerrorprojectbbabulrennehananaconda3envspynbodylibpython36sitepackagesyt_astro_analysishalo_analysishalo_quantitiespy in __call__self halo 37 38 def __call__self halogt 39 return selffunctionhalo selfargs selfkwargs 40 41 def center_of_masshalotypeerror stellar_mass takes 1 positional argument but 2 were givencodesnippet
2019,this happens when i runcodesnippet
2019,ah heres the sphere call back doc hyperlink
2019,yt_astro_analysis is definitely the way to go here
2019,can you show me what your script looks like
2019,sure
2019,import ytds ytloadssnapshot_189hdf5 data_dirhalos_ds ytloadssnapshot_189hdf5parameter data_dirfrom yt_astro_analysishalo_analysisapi import hc halocatalogdata_ds ds halos_ds halos_dsdef stellar_masshalo sphere halodata_object return spherestar particle_masssumadd_quantitystellar_mass stellar_masshcadd_callbacksphere factor 20hcadd_quantitystellar_mass stellar_masshccreate
2019,ugh
2019,codesnippetcodesnippetimport ytds ytloadssnapshot_189hdf5 data_dirhalos_ds ytloadssnapshot_189hdf5parameter data_dirfrom yt_astro_analysishalo_analysisapi import hc halocatalogdata_ds ds halos_ds halos_dsdef stellar_masshalo sphere halodata_object return spherestar particle_masssumadd_quantitystellar_mass stellar_masshcadd_callbacksphere factor 20hcadd_quantitystellar_mass stellar_masshccreatecodesnippet
2019,ah this line codesnippetshould be codesnippet
2019,ah thank you
2019,no prob
2019,the first codesnippet call is add it to a registry of known functions
2019,youre saying associate stellar_mass with the function codesnippet i could have made that more illustrative by naming the function with a different name than the string
2019,in codesnippet your picking stellar_mass out of the registry that you added it to previously
2019,do all of the submodules know about the registry or just the halocatalog module
2019,thanks for the explanation i appreciate it the yt code is very abstract so it takes a while to get a grasp on what is going on under the hood
2019,the only thing that knows about the registry is the runtime environment of that script
2019,you could put the callback functions and codesnippet in another file and import that in your halo catalog script and it would then be in there
2019,but this all all just halocatalog specific too
2019,i suppose this is because we imported from the halo_analysisapi maybe thats why i was a bit confused because it looked like a global function but i forgot about that import
2019,ah yeah good point its all coming from that import
2019,specifically codesnippet codesnippet codesnippet those are all in that import
2019,and they know about the registry
2019,great this is very well done since youre here i ran into a problem with the code again but i believe i fixed it im using gizmo and i dont have a star particle_mass field in my derived list i replaced the codesnippet with codesnippet this should work just as fine no
2019,it is definitely creating the catalog haha
2019,yeah that should work the codesnippet particle type is something that may or may not exist but whatever your particle type for stars is thatll do
2019,great this makes my life so much easier i was running into huge problems with pynbody gizmo ahf but yt seems to have it covered i didnt know there was such a rich halo backend
2019,thank you
2019,brilliant glad this is working for you spread the word
2019,also you arent the first person to ask these types of questions about the halocatalog if you can think of ways to improve the docs i would really love that
2019,hmm well ill think about it a bit more i just started with this this week so im going to read through the docs more carefully today ill definitely let you know and ill spread the word slightly_smiling_face
2019,fantastic best of luck with the analysis
2018,can i make a projectionplot for only the particles that correspond to the values in an array of particle ids ive looked through the section on filtering and i might be able to make it work with codesnippet but that seems very roundabout
2018,yes that would be the way to do it
2018,im not sure offhand if that actually works at the moment though in the demeshening
2018,you can create new particle types by creating a particle filter
2018,i just dont know off hand if the filter is recognized as an sph particle type
2018,user im usually using this to filter particle based on idcodesnippetfrom yt import particle_filterfrom numpy import in1ddef add_filter_for_particle_idsds selected_ids new_particle_namefiltered_particle filtered_typeio particle_filternew_particle_name requiresparticle_identity filtered_typefiltered_type def _filterpfilter data ids datapfilterfiltered_type particle_identity astypeint value ret in1dids selected_ids return ret dsadd_particle_filternew_particle_namecodesnippet
2018,interesting
2018,hey can you remind me how one can get transparent backgrounds for yt plots
2018,or in general how to set the background color of the figure im not talking about the matplotlib ax which can be set using codesnippet
2018,i seem to remember that not being straightforward due to details of how matplotlib works
2018,let me see if i can make an example one sec
2018,user has joined the channel
2018,this seems to work
2018,
2018,user i just update the pull request to remove those dead imports it should work now
2018,okay thanks i changed the import call to what you recommended will let you know if it runs
2018,it is no longer failing just not finding the clumps i am expecting either now i need to figure out if the problem is me slightly_smiling_face
2018,anyone know how to find the commit number corresponding to a yt installation from inside the notebook
2018,do git status inside of the repo
2018,if theres no repo we dont encode that information in the installed copy
2018,i see thanks
2018,it would be possible to do that via eg versioneer though
2019,user did you ever get a moment to check this out
2020,in trying to update yt to dev tip im getting some breakages due to sympy not playing well with other packages is this a known issue and is there a known solution or are we just to wipe and start over i saw this recentlymerged pr but wasnt sure it was related hyperlink
2020,rather im trying to update yt to yt40 tip
2020,you might need to update unyt
2020,when i try to codesnippet i get the same error unfortunately
2020,what sympy and unyt versions do you have installed in that environment
2020,and what errors are you seeing
2020,if you can make a script i can run to reproduce it i can debug a little
2020,looks like sympy is 111 and i guess i dont have unyt at all
2020,thats odd i dont think yt should be importable if unyt isnt installed
2020,well i was on trail for the second half of 2019 before unyt was as integrated into yt as it is now i think
2020,in yt40
2020,im just now trying to get up to snuff
2020,yt40 depends on unyt now
2020,did it in july 2019
2020,i dont remember when that got merged
2020,but i thought you said you were trying to update to the latest yt40
2020,yes i am trying to update my yt40 from the state it was in circa july 2019 to the yt40 tip
2020,and i am unable to do so because of this sympy errorcodesnippetinstalling collected packages sympy unyt attempting uninstall sympy found existing installation sympy 111error cannot uninstall sympy it is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstallcodesnippet
2020,what pip version
2020,pip 2002 from userschummelssrcytcondalibpython36sitepackagespip python 36
2020,ah you shouldnt be using pip in a conda environment like that
2020,codesnippet should work
2020,you can get codesnippet from condaforge too
2020,interesting i had thought that the appropriate way to install yt from the repo was tocodesnippetcd yt_srcgit checkout yt40git pull upstream yt40pip install e codesnippet
2020,which is what i did which led to this error
2020,yeah that should work in a conda environment as long as you have all of the depenencies updated first via conda
2020,i didnt realize that a condainstalled sympy would refuse to be updated with pip thats new to me slightly_smiling_face
2020,thanks for the help with this user
2020,im trying your conda upgrade command
2020,actually ive always done that install of codesnippet too though thanks to users trident notebook instructions slightly_smiling_face
2020,afaik that used to work too
2020,ok so using your suggested command it looks like im upgraded to sympy 151 thanks
2020,so for getting unyt should i use conda or pip or just do the codesnippet
2020,codesnippet
2020,got it
2020,i think pip would probably install it if you let it but its best not to mix pipinstalled and condainstalled stuff
2020,i need to run hope you get sorted if you run into new issues introduced in the last six months please let us know
2020,glad youre back from your big pct trip
2020,thanks for the help
2020,i think once yt4 merges iwe may have to modify the install instructions to streamline them a bit so others dont get caught in the pipconda limbo slightly_smiling_face
2018,i want to make a lot of codesnippets but for a small part of a large dataset is there a way to slice the entire dataset
2018,hi ben im not sure if this is what you mean but codesnippet accepts a codesnippet keyword argument allowing you to do the projection on a subset of the full box
2018,where codesnippet is some data container like a sphere or whatnot
2018,sounds like exactly what i want didnt know about spheres and all that before thanks
2018,you bet
2018,i think just about all of the plot functions accept this keyword
2020,hi user the warning youre getting is only about conflicting options for drawing grid ids unique numbers attached to each grid patch it _is_ a somewhat minor issue with how certain default values are colliding but it should not affect your plot
2020,moreover the issue you linked was recently fixed so if it affects you just update your yt clone
2020,you can possibly reproduce a similar plot by making slices of the codesnippet field annotate the grid see comments below
2020,also i just opened a pr to fix that warning so expect it to be fixed too soon
2020,user thank you my current version is 351 i hope this is what you mean when you say yt clone does that need to be updated im currently working on a cluster and so i dont have permissions to update anything myself but will wait till monday incase that is necessary
2020,i was asssuming that you had your own git clone of yt installed from source however the 36 release is in the making and should be available in the coming days or weeks so maybe wait for it before you ask your it department for an update
2018,sorry what do you mean exactly by visualize the grid structure
2018,like you want to make a plot of the amr grids in your simulation and then do a scatter plot on top of that
2018,there isnt a plot type in yt that does that you could probably get a sliceplot to look the way you want with a lot of effort
2018,it might be easier to just make the plot manually
2018,you can get access to the grid metadata for all of the grids in your simulation via codesnippet
2018,thats a python list of grid objects you can get at the left and right edges for each grid like so
2018,codesnippetfor grid in dsindexgrids le gridleftedge re gridrightedgecodesnippet
2018,and then use the left edges and right edges to construct your plot in whatever plotting software youd like to use
2018,user yes this is exactly what i want to do i will give this a try thanks a lot
2018,if i have a storage dictionary doing iterations in parallel is there a simple way to access all the codesnippets in a similar manner to codesnippet to get all the codesnippets
2018,hi mike the codesnippet will be the keys of the codesnippet dictionary
2018,excellent thank you
2018,youre welcome
2018,has anyone run yt in parallel on an hpc system specifically a dod machine i am having trouble getting yt to recognize to use mpi4py or an error occurs when i load the module codesnippet
2018,i havent had this exact error but i have had problems getting mpi4py to run on hpc systems like blue waters
2018,do you know if there is a yt module that has been installed on the system
2018,ie codesnippet
2018,would you mind sharing some of your tricks
2018,if so that is oftentimes a good place to look to see how mpi4py is installed for the module
2018,nope but they do have codesnippet
2018,ok great
2018,so load that and try to track down where it is installed on the system
2018,and look at their cfg file
2018,i installed yt using conda from my home directory
2018,yeah you may have to rely on a different means
2018,a lot of hpc systems dont play nice with isolated conda installs
2018,i gotta run this moment but ill be back in the next hour
2018,i figured not it gets the job done for running serial but obviously some seriously wasted computing power
2018,check out the config file in the codesnippet
2018,will do thanks
2018,and see if you can reinstall mpi4py from source using a similar config
2018,thats the first thing to attempt
2018,ok be back in a bit
2018,did that help at all
2018,i made some head way and am very close to getting it essentially what i did was load modules i needed from my submit script mpi4py etc it gave me an error not being able to find yt so at the top of my python script i gave it codesnippet now it is saying codesnippet which doesnt make sense because if i run python from the terminal i can do codesnippet then codesnippet just fine
2018,hmm
2018,the only thing i can think of is in the codesnippet directory there is both codesnippet and codesnippet when i imported yt in the terminal and wrote codesnippet it outputted codesnippet
2018,as opposed to in codesnippet
2018,but i am not sure why one would have an enable_parallelism feature and the other doesnt
2018,thats odd given your path
2018,did you install yt twice using different methods one from conda or pip and one from src
2018,i just installed from source using codesnippet then codesnippet
2018,maybe i could try just a conda install
2018,when you tried to install mpi4py on your conda python you got a failure right
2018,you just did codesnippet or something
2018,or youre just using the module
2018,i actually didnt install mpi4py i am just using the module
2018,yep
2018,try installing mpi4py with your existing python setup try codesnippet
2018,i did try installing mpi4py a while back but it didnt really work
2018,that would at least have mpi4py running on your specific python setup if the install works
2018,when i did that before it gave mecodesnippetthe application appears to have been direct launched using aprunbut ompi was not built with alps support this usually happenswhen ompi was not configured withalps and we werent ableto discover an alps installation in the usual placesplease configure as appropriate and try again an error occurred in mpi_init_thread on a null communicator mpi_errors_are_fatal processes in this communicator will now abort and potentially your mpi jobnid0161343817 local abort before mpi_init completed completed successfully but am not able to aggregate error messages and not able to guarantee that all other processes were killedcodesnippet
2018,when i installed my own mpi4py
2018,ooof
2018,i think the hpc system really wants you to use their mpi4py
2018,well it likely wants you to use their python too
2018,yeah i also load in their module for that the rest of the modules seem to be taken care of adding codesnippet to the top of my python script but then no enable_parallelism so close
2018,what if you use codesnippet instead
2018,it fails to find the module codesnippet
2018,even if i include both
2018,can you pip install user sympy
2018,let me give that a try
2018,thanks to user help we were successful let me know if anyone else needs help with this task also apologies for cluttering this slack channel
2018,in short the method was to use the system wide install of pythonmpi4py then codesnippet any remaining yt dependencies then codesnippet and codesnippet yt from the git source
2019,hey all i know theres a method for depositing particles into octrees yt 3x using just the gas particles as opposed to all particles but i cant seem to find the relevant source code or documentation does anyone know offhand either the syntax or the docs
2019,oh is it thishyperlink
2019,user that changes how the octree is built but not deposition
2019,deposition is controleld by field name
2019,so something like depositgas_density
2019,sorry i misspoke what i actually meant wsa how the octree is built
2019,thanks its amazing how just saying the question outloud sometimes all of a sudden elucidates the answer
2019,so the issue is that somehow your ramses version dumps invalid binary files the best fix would be to just skip the reading of codesnippet
2019,the easiest i see would be to patch yt could you try using the following patch against yt devcodesnippetfrom 3526ad0f76cccff9825f4ee25b5a8758fa45c48b mon sep 17 000000 2001from corentin cadiou ltcontactcphycmegtdate sun 5 may 2019 190208 0200subject patch quick fix ytfrontendsramsesdata_structurespy 1 ytfrontendsramsesdefinitionspy 3 2 files changed 3 insertions 1 deletiondiff git aytfrontendsramsesdata_structurespy bytfrontendsramsesdata_structurespyindex c5802cbba12979474e 100644 aytfrontendsramsesdata_structurespy bytfrontendsramsesdata_structurespy 1396 1397 class ramsesdomainfileobject for header in ramses_headerhvals hvalsupdatefread_attrsheader fseek484 skip reading of mass_sph for speedup skip reading of headl and taill fskip2 hvalsnumbl fread_vectoridiff git aytfrontendsramsesdefinitionspy bytfrontendsramsesdefinitionspyindex 9cc8278eda3235580a 100644 aytfrontendsramsesdefinitionspy bytfrontendsramsesdefinitionspy 427 428 def ramses_headerhvals stat 3 d cosm 7 d timing 5 d mass_sph 1 d mass_sph 1 d yield next_set field_aliases 2210codesnippet
2019,hey i did comment out mass_sph part to dev version but ending up with another error
2019,hi i am trying to plot exodus 2d data with e extension for which sliceplot worked fine i am trying to plot vectors using annotate_quiver over a sliceplot as shown here hyperlink my vector variable is of lagrange_vec type called nlc my question is how can i access x and y components for plotting i have tried using nlcx nlcy and nlc_x nlc_y but they give the error codesnippethere is my code
2019,
2019,whats codesnippet
2019,if codesnippet is in there then this sounds like a bug in which case please report it on github and include a dataset to trigger the issue with
2018,user has joined the channel
2019,i have been making some nice visualizations with combinations of particleplot when filtered for various interesting cuts i would like to align these plots with a galaxys disk axis but there seems to be no analog to offaxisprojectionplot that operates on particles the deposited particle fields are too crude for my purposes have i missed something is there a good workaround or replacement that will render particles in an offaxis projection
2019,you could reload the particle data using ytload_particles after rotating the particle positions
2019,in principle we could add a offaxisparticleplot or maybe add an option to particleplot that rotates the particles i think theres even fast code for doing the rotations at least on the yt40 branch that would be a great improvement
2019,user sounds vaguely like a bug to me any chance you can make a reproducible example using one of the test datasets on hyperlink that demonstrates the issue also make sure youre using at least the newest stable release
2018,user has joined the channel
2018,user has joined the channel
2018,hi i was trying to create an interactive data visualization with a code very similar to this hyperlink but i keep getting errors like codesnippetanacondalibpython36sitepackagesytunitsyt_arraypy1293 runtimewarning invalid value encountered in log10 out_arr funcnpasarrayinp outout kwargsanacondalibpython36sitepackagesytvisualizationvolume_renderinginteractive_vrpy422 runtimewarning allnan axis encountered selfmin_val minselfmin_val npnanminblockmy_data0minanacondalibpython36sitepackagesytvisualizationvolume_renderinginteractive_vrpy423 runtimewarning allnan axis encountered selfmax_val maxselfmax_val npnanmaxblockmy_data0maxcodesnippet
2018,i loaded a fits file with which i successfully created an idv before but since i updated some of my packages this does not seem to work again
2018,not sure whats the problemany hint is much appreciated
2018,what sort of data is this
2018,a fits file with axes ra dec and velocity
2018,ah so a fits file
2018,im not aware of an issue related to this
2018,if you file an issue with steps to reproduce the problem one of us could try to take a look
2018,i dont think there have been any changes to the idv stuff recently
2018,so i dont know offhand what the issue might be
2018,file an issue on github
2018,yup
2018,if its possible include a link to the data youre working with
2018,thank you doing it right now
2018,you can share data using yt upload pathtodatafits
2018,and then copypaste the link that prints out
2018,user has joined the channel
2018,howdy folks so im currently thinking about a change to the code which if i get working id like to share i have the latest pip install should i uninstall it and pull the git as in on the yt install page or is there a fancy way to fake it
2018,the pull request i mean
2018,hyperlink
2018,i really want quiver to have an annotated scale arrow and ive already done this once by hand for a matplotlib quiver plot i made stuck_out_tongue
2018,id do the pip install e instructions at the bottom there
2018,for the yt development workflow see hyperlink
2018,okay but i should install the git version thats what i figured
2018,yup
2018,okay thanks
2018,you want to be developing from git slightly_smiling_face
2018,that sounds like a great addition btw slightly_smiling_face
2018,cool yeah i see the post in the email forums about it from 2014 and your quiver plot stuff looks almost exactly like mine so i think this will be pretty easy
2018,issue opened
2018,user those lines in codesnippet dont make any sensecodesnippetselfmin_val minselfmin_val npnanminblockmy_data0mincodesnippet
2018,remove that inner min and see if it works for you
2018,same for max
2018,it should becodesnippetselfmin_val minselfmin_val npnanminblockmy_data0selfmax_val maxselfmax_val npnanmaxblockmy_data0codesnippet
2018,where should i remove it
2018,its the line that raises warnings in your bug report
2018,codesnippetanacondalibpython36sitepackagesytvisualizationvolume_renderinginteractive_vrpy422 runtimewarning allnan axis encountered selfmin_val minselfmin_val npnanminblockmy_data0minanacondalibpython36sitepackagesytvisualizationvolume_renderinginteractive_vrpy423 runtimewarning allnan axis encountered selfmax_val maxselfmax_val npnanmaxblockmy_data0maxcodesnippet
2018,we should probably fix that on the yt side i guess
2018,yup
2018,thats in the yt
2018,i cant recall if thats still there in the idv pr
2018,the idv pr seems to show there is no change to these two lines
2018,cool
2018,user sounds like a good material for a pr slightly_smiling_face
2018,emmm what could i do sorry that im not so familiar with github
2018,there are instructions here hyperlink
2018,but if you dont want to do that you dont need to
2018,id comment on the issue what the solution is though
2018,ah i just wish to fix itjoyill look at the website and learn
2018,user i am out sick today but will try tomorrow to get the idv stuff in a place you can use it or if youre around we can try meeting up
2018,i made the two changes as user suggested it worked but produced something really weird
2018,looks like an interstellar cloud to me
2018,kidding
2018,user sorry to hear that you are sick im on campus all the time just email me if youd like to meet
2018,i remember it worked beforejoysomehow i got it messed up
2018,slightly_smiling_face
2018,its probably not your fault the idv has been in need of some loving upgrades
2018,has anyone experienced any errors with pastebin and connection errors recently
2018,i remember having issues a couple of years ago with this but i thought we moved to a different service
2018,i can give a full traceback if it is useful but i think the main thing is that the pastebin site is not accepting socket connections
2018,user has joined the channel
2018,user its been recently migrated by user
2018,but it should still work
2018,user try now
2018,ok
2018,no dice disappointed
2018,it may be dns issue
2018,codesnippetcambotscratchyuguang chummels yt pastebin halopyuserschummelssrcytcondalibpython36sitepackagescmoceantoolspy76 matplotlibdeprecationwarning the is_string_like function was deprecated in version 21 if not mplcbookis_string_likergbin0yt info 20180516 162933037 loading plugins from userschummelsconfigytmy_pluginspytraceback most recent call last file userschummelssrcytcondabinyt line 11 in ltmodulegt load_entry_pointyt console_scripts yt file userschummelssrcytcondasrcytgitytutilitiescommand_linepy line 1413 in run_main argsfuncargs file userschummelssrcytcondasrcytgitytutilitiescommand_linepy line 237 in run selfargs file userschummelssrcytcondasrcytgitytutilitiescommand_linepy line 833 in __call__ privateargsprivate clipboardargsclipboard file userschummelssrcytcondasrcytgitytutilitieslodgeitpy line 315 in main pid create_pastecode language filename mimetype private file userschummelssrcytcondasrcytgitytutilitieslodgeitpy line 211 in create_paste private file userschummelssrcytcondalibpython36xmlrpcclientpy line 1112 in __call__ return self__sendself__name args file userschummelssrcytcondalibpython36xmlrpcclientpy line 1452 in __request verboseself__verbose file userschummelssrcytcondalibpython36xmlrpcclientpy line 1154 in request return selfsingle_requesthost handler request_body verbose file userschummelssrcytcondalibpython36xmlrpcclientpy line 1166 in single_request http_conn selfsend_requesthost handler request_body verbose file userschummelssrcytcondalibpython36xmlrpcclientpy line 1279 in send_request selfsend_contentconnection request_body file userschummelssrcytcondalibpython36xmlrpcclientpy line 1309 in send_content connectionendheadersrequest_body file userschummelssrcytcondalibpython36httpclientpy line 1234 in endheaders self_send_outputmessage_body encode_chunkedencode_chunked file userschummelssrcytcondalibpython36httpclientpy line 1026 in _send_output selfsendmsg file userschummelssrcytcondalibpython36httpclientpy line 964 in send selfconnect file userschummelssrcytcondalibpython36httpclientpy line 936 in connect selfhostselfport selftimeout selfsource_address file userschummelssrcytcondalibpython36socketpy line 724 in create_connection raise err file userschummelssrcytcondalibpython36socketpy line 713 in create_connection sockconnectsaconnectionrefusederror errno 61 connection refusedcodesnippet
2018,i forgot to update it for paste it works for me now
2018,can you try using browser
2018,im not sure how to do that
2018,hyperlink
2018,see if it opens
2018,nope
2018,codesnippetthis site cant be reachedhyperlinks server ip address could not be foundcodesnippet
2018,try again in 30m 60m it may take a while for a dns change to propagate
2018,ok cool
2018,thanks for looking into this
2018,ill try again in an hour and update here my results
2018,codesnippet dig hyperlink ltltgtgt dig 9111p3 ltltgtgt hyperlink global options cmd got answer gtgtheaderltlt opcode query status noerror id 34372 flags qr rd ra query 1 answer 1 authority 0 additional 1 opt pseudosection edns version 0 flags udp 512 question sectionpasteytprojectorg in a answer sectionhyperlink 3563 in a 141142211195 query time 17 msec server 757575755375757575 when wed may 16 183211 cdt 2018 msg size rcvd 65codesnippet
2018,it should return 141142211195
2018,if it returns something different its dns
2018,codesnippet now works
2018,thanks user
2018,we should make that command use gist tbh
2018,yeah that would make it easier to use with nbviewer
2020,thanks for linking this
2020,ive been wondering if theres a canonical way in yt to vizualize noncartesian geometries within their respective native coordinate system for instance given a polar dataset visualising it in a r vs theta frame is often very useful in essence allowing this should be pretty easy because its more or less equivalent to pretending the dataset is cartesian anyone would know about that
2020,i guess you can use phase plots for this
2020,good idea unsettling results
2020,heres what i get
2020,it is probably due to pixellisation issues no
2020,i guess so the only region that appears contiguous has the highest amr level
2020,user has joined the channel
2020,hi ive got some really basic question i got a plot thats very high but thin i am trying to get things readable by increasing fontsize but then ticklabels for x axis the thin one overlap the easiest solution i think would be to change ticks but i found no answer in ytcookbook regarding that and currently doubt thats even possible so is there an easy and straightforward way to edit ticks if no whats the way example picture attached look at the bottom ax
2020,user has joined the channel
2020,im getting the blocky issue with boxlib type data as well yt version 351 and the issue shows up in both python2 and python3 see pictures below same dataset visualized with yt and with visiti only observe the issue when visualizing nodal codesnippet data visualization is fine when the codesnippet are cellbased
2020,in the issue that got opened on this andrew myers said that its fixed on master already
2020,can you try building yt from source
2020,hyperlink
2020,user has joined the channel
2020,user has joined the channel
2020,user i think if you explicitly set the geometry as cartesian when you load the dataset codesnippet itll do what you want havent tried though so dunno if it will actually work the axes names will be xyz if you do that but yt should interpret the data as cartesian
2020,i actually implemented a codesnippet load option in the amrvac frontend for exactly that purpose but it still feels like a hack
2020,user yes see this notebook for an example hyperlink
2020,user what would feel less like a hack to you
2020,theres a big if statement in the pixelization routines that tell yt which pixelizer to pick based on the geometry
2020,presumably thats the code you want to mess with
2020,then i think that what i want would be the option of using the cartesian pixelizer within any geometry
2020,its very low priority but it is on my wish list nonetheless
2020,ok well you can take a look at the geometry handlers
2020,and their codesnippet methods
2020,to see how they work
2020,yeah thanks for pointing that out slightly_smiling_face
2020,for example heres the one for cylindrical geometries hyperlink
2020,thanks nathan if i can manage to spend some time with this i might have follow up questions but ill ask cbe6579czdevelopment then slightly_smiling_face
2020,user has joined the channel
2019,hi all i want to ask does yt amr structure supports both 2d data and in cylindrical coordinates there arent much examples about them most of the examples are working with 3d data in either cartesian or spherical coordinates i am working with a new data from a newly developed hydrodynamic code in hdf5 format but i am having trouble loading it in to yt i am currently looking in the function codesnippet is this the right function to do this
2019,also i try the example code codesnippet in the session generic amr data at codesnippet when i reduce codesnippet to a 2d structure the codesnippet function failed does that mean this function only supports 3d amr structure thanks for answering
2019,it should work passing codesnippet its possible youre hitting a bug though can you give more details about what failed
2019,for these sorts of discussions its most helpful to have a test script that anyone can run eg that includes links to all necessary data files or uses fake random data to trigger the behavior that youre having trouble with
2019,user im gonna need to run in a little bit but if you can create a github issue about this sounds like a bug to me including relevant detail eg if theres a crash please include the traceback and error message and if you have time to put it together a test script that one of us can run to trigger the issue you can file issues at hyperlink
2019,user i recently developed support for _adapta_hop which confusingly is not compatible with hop catalogs
2019,user is hop not finding any halos or just putting them in the wrong places ive seen similar things in the past when some of the fields arent being passed correctly to the halo finder
2019,user well its finding them now but it doesnt come up with the right image unless i make the width of the projection plot really huge on the order of 1000kpc if i put in the center coordinates and make it about 120kpc then the image is just coloured squares but 1000kpc is a high resolution very zoomed out image of the galaxy and im just not really sure whats going on
2019,this is the 1000kpc image
2019,this is the 120kpc image
2019,same center coordinates for both
2019,user judging by the colorscale youre just hitting void can you center your 120kpc wide image on any halo
2019,user by hitting void do you mean that im hitting the low resolution part of the simulation because i dont really understand how thats happening if im using the exact same coordinates for the centre for both of these plots
2019,and no i cant get any 120kpc image they all look like this one but different
2019,not necessarily low resolution just a place where theres no gas
2019,if you do 400kpc wide does it still look reasonable also can you share the code that youre using to make those plots
2019,sure
2019,give me a few mins im gonna try and make them again just to triple check im not doing anything stupid
2019,what object are using for projection the entire domain or ie just a small sphere
2019,the entire domain
2019,soooooo itll take some time
2019,setting codesnippet argument to codesnippet would probably the quickest way of verifying if what i say makes sense
2019,lets make this a thread
2019,im not sure what you mean
2019,codesnippet
2019,it will find the maximum in gas density and center the projection on it
2019,but im trying to find a specific galaxy from the catalogs
2019,ill run that as well
2019,with the width set to 400kpc and well see what comes up
2019,thank you btw
2019,ok i think brittons suggestion that coordinates are somehow wrong is the valid one
2019,yeah i was thinking that might be it but it doesnt explain how i get this massive galaxy right in the middle of my 1000kpc plot of the same center coordinates
2019,really boggled me
2019,hey alladmittedly i know very little about enzo datasets im trying to load an enzo data set cut out a subregion of this and then create a new ds at first i thought maybe creating a codesnippet viacodesnippetimport ytimport numpy as npsnapshot usersdesikanarayanandropboxyt_datasetsenzo_iso_galaxygalaxy0030galaxy0030ds ytloadsnapshotcenter dsarr050505code_lengthlen dsquan025code_lengthregion dsregioncentercenterlencenterlencodesnippetwas the right path but then when i try to access codesnippet i get a weakproxycodesnippetin 30 regiondsout30 ltweakproxy at 0x117f684c8 to enzodataset at 0x119ca9090gtin 31 dsout31 galaxy0030codesnippet
2019,is there a smarter way to accomplish this
2019,the weakproxy is a reference to the dataset
2019,as long as the dataset itself hasnt been garbage collected you can use it just the same as the original dataset
2019,also in the script there you dont use regionds so im a little confused where thats coming from
2019,ah so this is just a selfcontained snippet out of a larger program what im trying to do is create a new ds that is a smaller subregion of the original ds because i want to set up an enzo simulation to do radiative transfer but dont need the entire boxis the appropriate way to do this via a codesnippet keyword and if so any tips on avoiding garbage collection
2019,so the issue youre having is that the weakproxy is no longer valid
2019,you can do this two ways first by reloading using the ytdata frontend just like i presume you do with sph data
2019,or just by using a region and making sure the dataset you created the region from doesnt go out of scope
2019,i can elaborate a bit more if you can share a more full example that triggers whatever problem youre having with the weakproxy
2019,in python an object gets garbage collected when no other objects refer to it
2019,so if youre doing something like iterating over a time series and saving a list of regions to then operate on later youll need to either make sure something has a reference to the original dataset eg by putting it in a list or restructure so you operate on the region right after creating it
2019,so actually the above script if i run it in a python terminal and then just typecodeblocklike before will trigger the weakproxy
2019,why is that a problem
2019,you can use regionds just like ds so long as the dataset hasnt been garbage collected
2019,trigger the weakproxy means just seeing that the object is a weakproxy in the repl
2019,yeah exactly
2019,hyperlink
2019,to learn more about this
2019,the issue is that downstream in the code i call something likecodeblockand it fails because of the weakproxy but i think the answer is to use the regionds soon after i create it im not sure i do to keep it from getting garbage collected
2019,yes that means the dataset is being garbage collected
2019,cool thanks for the advice ill see if i can correct that
2019,you could refactor so the dataset is passed into that function that would force you to make sure the dataset is still in scope somewhere
2019,thats good advice that wouldnt be very hard
2019,another issue with this i think is that because the grids are selected before the parallel iteration begins all the processes end up generating the icoords etc for all grids
2019,yup true the data selection operation happens on all processors i think we also assume that the amr hierarchy can be held in memory on all processors
2019,im a little confused why disabling the caches for those doesnt fix this though
2019,i think its codesnippet
2019,ah so its just the masks
2019,does setting that to false horrendously slaughter performance
2019,not sure need to confirm and test
2019,but i think that in this situation we can special case the selection anyway
2019,probably adding special logic for handling selection on unigrid runs would make a lot of sense
2019,as would eg a config option to disable problematic chaches
2019,disabling that cache does bring the memory down to about what id expect 1
2019,without seeming to hurt the performance too much however i do think its spending a lot of time doing unnecessary selection checks cache or no cache
2019,gonna try to work on that
2020,user has joined the channel
2020,hi i am trying to visualise a codesnippet as followscodesnippetdata initial theta f3d_array radiansbbox nparraynppi nppi nppi nppi nppi nppids ytload_uniform_griddata datainitial theta0shape length_unit2nppi1024 bboxbbox nprocs16 periodicityfalsefalsefalsecodesnippet
2020,but when i do codesnippet i get an error saying codesnippet how should i resolve this
2020,somehow codesnippet does not contain codesnippet whereas codesnippet does is this the reason
2020,this is indeed odd what happens if you change the name from initial theta to something parseable such as initial_theta does that result in any differences
2020,user does not make a difference
2020,can you try changing codesnippet to codesnippet
2020,you got it now its included in codesnippet and there are no errors thrown although the kernel keeps dying for some reason thanks so i cant use radians as units
2020,i am not sure actually let me check into it
2020,it might work if you do a projection that doesnt integrate for instance using a method like mip
2020,i suspect the issue may be that multiplying the units of radians by a length is causing freakouts or maybe radians is the wrong term for it
2020,okay now with radians replaced by dimensionless i consistently get a dying kernel whenever i try to do the projection plot what do you think is probably happening i am new to yt i was trying to replicate this loading generic array data notebook with my own dataset which contains a 3dimensional angular field any suggestions how i could visualise it
2020,nevermind i can do a volumerender thank you grin
2019,hi max
2019,i try to illustrate my task actually i have two distribution functions one is maxwelljuttner mj distribution and powerlaw distribution in momentum space i have to find the intersection point say p_int between these two distributions on each cell now the thing is that mj distribution needs the value of temperature and density field of the cell and powerlaw distribution needs the value of density and mach number field of the same cell to compute the intersection point of the said distribution functions on that cell which i will select based on some criteriahope this will illustrate you what exactly i am looking for
2019,since these functions are scalar function with variable p momentum i need to pass the field values to the functions to compute the intersection point
2019,user has joined the channel
2019,hi when i try to do a sliceprojection plot of the cic field of my particles i got a figure with a lot of artificial filaments the figure is attached below i am wondering if i will be able to make a more smoothlooking cic field
2019,user i think thats an unavoidable artifact from the grid edges where you see the domain subdivided i think a long time ago someone maybe user worked on getting rid of it but its really tricky to do the stuff where youre seeing it in voids and whatnot is probably not real in the sense that its an extremely constrained and not visually wellrepresented colorbar
2019,user i see this plot is the most visible one for the effect i can also see a lot of the filaments if i have a wider range of color bar what is annoying is that it will make the true colors less visible especially for real very low density voids see the plots attached
2019,user yes i see it in this too but i genuinely dont know that theres a lot we can do without changing the notquitesmoothing criteria the cic deposition is inextricably linked to the cell size so there may just not be a lot we can do with it that being said its possible you could add a smoothing field that also calculated the smoothing length but i dont know that it would be worht the additional effort you might try making a particleplot which changes the way the deposition is done to be more general and sometimes results in higherquality images
2019,user i have tried the particleplot there are still a lot of filaments seen there i am wondering if there is any way for me to just export the cic density as the grid data
2019,user yup you can do a codesnippet and query the cic there that would also help you change the resolution you can do this with for instance codesnippet which will give you the full dataset ie codesnippet with 128 steps along each dimension
2019,user thank you i will try that
2018,when i look at the code i did not get it the main code for the sum up should becodesnippeti_i j_i k_i npmgrid03 03 03for i j k in zipi_iravel j_iravel k_iravel sl slicei nx2i slicej ny2j slicek nz2k new_field dataftype basenamesl dataftype weightslcodesnippeti can see it sums up codesnippet times of the sliced dataset how can it be the sum up of entire dataset
2018,sorry i dont follow what do you mean be sum up of the entire dataset
2018,maybe im not understanding what you were originally asking for
2018,the linked function defines a field that computes a local volume average
2018,of the 27 nearest neighbors of every zone
2018,it uses some fancy indexing tricks to do it in a concise way
2018,what i would like to do is to create a derived field which contains the average along one axis over the entire volume
2018,ah ok there isnt a way to do that right now
2018,although thats basically a projection
2018,you could do a projection and weight by the ones field
2018,yes its basically a projection while im thinking whether is possible to incorporate it into derived field since what i finally want to get is the field perturbation relative to the mean field averaged along one axis
2018,i think you could do this in an extremely hacky way with a global variable
2018,im not sure offhand whether a field parameter can be a 2d array
2018,if that works you could use that
2018,unfortunately right now fields cant do global operations like youre wanting them to do
2018,so only hacky solutions will work
2018,i see even with a 2d array as field parameter i need to worry that the date might be a block only not the entire domain so i need some coordinate index matching
2018,in this case maybe its simpler to extract some fix resolution data first
2018,you could pass the 1d flattened projection
2018,although going from the flattened projection to 3d indices wouldnt be straightforward
2018,yeah i can see this could work but will cost more time in coding its nice to confirm that theres no super easy way to do this in derived field thank you
2018,this is something were funded to work on
2018,adding the ability to do things like ray tracing and domain convolutions in a field definition
2018,ill try to remember this as a use case
2018,thanks the perturbation field relative to the mean of entire field is easy to compute while relative to the mean of one axis is useful in planeparallel configuration or in curvilinear geometry to get the nonaxisymmetric component
2018,user i think i did this once to get deviation from a radiallyvarying azimuthally averaged field it was annoying
2019,user has joined the channel
2020,hi user here are some instructions for getting changes from my forks of yt and yt_astro_analysisget my fork of ytgit remote add britton hyperlinkgit fetch britton halopartgit checkout halopartpip install e get my fork of yt_astro_analysisgit remote add britton hyperlinkgit fetch britton particlesgit checkout particlespip install e with both of those you should be able to do the followingds ytloadlthalo_catalog_filegthalo dshalohalos lthalo_idgthalomember_ids
2020,ok thank you so much for your help
2018,user has joined the channel
2018,this should be easy but where are the datasets used in the cookbooksds ytloadisolatedgalaxygalaxy0030galaxy0030
2018,thinking_face
2018,nevermind i found the data page
2019,user has joined the channel
2019,is it possible to ask yt load the simulation data into float32 type arrays i have a very big simulation snapshot which can not be fitted into the server memory if float64 type arrays are used thanks
2019,user unfortunately i am pretty sure this isnt possible there are a lot of places in the code where things are explicitly converted to codesnippet if it isnt that type already
2019,well thanks for the information it is a pity that there will be about half of the memory are wasted because the simulation data is normally codesnippet type how yt by design to handle the very large simulation if the analysis has to be done in a memory limited server can it be paralleled in multiple nodes with mpi
2019,user hyperlink
2020,user has joined the channel
2020,user has joined the channel
2020,user has joined the channel
2019,user has joined the channel
2019,hey im having a little trouble with getting covering_grid working with some eagle data only just started using yt so maybe just missing something obvious
2019,im just getting the following error message whenever i run covering_grid or arbitrary gridattributeerror ytcoveringgrid object has no attribute smooth
2019,all im doing is the followingcodesnippetds ytloadfnamecovering_grid dscovering_grid2 0 16cg_density covering_gridgas densitycodesnippetprojection plots and ray creation and spectrum generating having been generating fine with the data but havent been able to figure out where im going wrong with covering_grid anyone got any suggestions of what im getting wrong
2019,what version of yt is this you can print codesnippet
2019,ah 351 do i need 4
2019,no i think this should work yt3 but im not very knowledgeable of yt3 does changing to gas to parttype0 helpthis may need yt4 actuallyi think codesnippet will work by adding up mass of particles in an oct and dividing by oct volume which is not quite an sph density but it is often good enough for most thingsah im wrong codesnippet just returns the particles densities i think
2019,yeah i think thats what im seeing when i run that currently installing yt4 to have a go with that instead
2019,hopefully things work with yt4 if not please post
2019,also i think yt3 can do a density deposit with codesnippet
2019,but it isnt the _correct_ sph deposition
2019,thanks for the pointers ash think im up and running now it does at least run without errors and outputs a 3d array anway
2019,great
2019,is it the 4x that works or the 3x with codesnippetcodesnippet
2019,thats the way it works in 3 i think it still works in 4 for back compat reasons
2019,rich said it was yt40 which installed and worked
2019,sorry yes the ytcovering_grid code in yt40 seemed to work fine i didnt do a detailed check of the output but did do a quick sanity check by summing along one axis to compare to what id previously got with the same data using ytprojectionplot in yt3 the same density structures were there at least in both projections
2019,cool glad you got things working slightly_smiling_face
2019,yt4 should also be way way faster
2019,user btw would love to see a pr for those octree changes youve been working through with desika
2019,its ok if its not done it just needs to be an improvement over the status quo which i understand is quite broken
2019,yeah me and desika chatted in private and weve got some things planned with a timeline etc
2019,1
2019,happy to review whenever youre ready
2019,yeah i know its a bigger change than we first anticipated but its difficult to do whilst attending a conference this week i know know i need to work faster
2019,lol no worries at all on the wait its a holiday in the us anyway
2019,enjoy the conference
2019,user thanks so much for the work youre doing for this to help enable 4x to be baackwards compatible with the 3x octrees
2019,hi im having a little trouble with projection plots of different particle types im using ramses data and im trying to make a non weighted projection plot of a small part of the simulation of specifically just the gas or just the star particles but im not sure how to specify this in ytprojectionplot
2018,user i was wondering where the issue on the yt github page for this problem hyperlink isi could not find it but i have the same problem when loading a flash file netcdf4 version 141
2018,that error was due to condaforge building a debug version of netcdf4 which had some runtime debug checks that should have been turned off not sure why youre hitting it if your netcdf4 package is up to date is it if youre reading flash data a workaround would be to uninstall netcdf4 completely
2016,user has joined the channel
2018,user has joined the channel
2019,user has joined the channel
2016,user has joined the channel
2020,do you mean an average over a certain volume you can create a region over which you want to calculate the average hyperlinkcodesnippetmeancodesnippetweighted_average see example hyperlink
2020,has anyone done a vr with multiple fields and displayed both transfer functions as legends in the image
2020,i might try to hack this into the code but i was curious if anyone else has already
2020,
2020,actually wasnt too hard to hack
2018,user has joined the channel
2019,user has joined the channel
2018,user has joined the channel
2018,hii am new to yt and having trouble using halo catalogs i am trying to identify and analyze galaxies in a galactic scale simulation and created a halo catalog using hopthe problem is that the halo catalog for some reason changes the coordinates and i have no idea how and whyi thought i could just overlap both coordinate systems the one from the original data and the one from the halo catalog by setting the origin to the center of mass but it either is changed by creating the halo catalog or the accuracy is not good enoughi hope someone can help me with my problem
2018,can you share an example of what youre seeing eg copypaste the script youre running and the output youre seeing what simulation code are you working with
2018,nevermind i just realized my mistake i accidently deleted a line that would do unit conversion which messed everything up see_no_evilsorry for bothering you
2018,yay a thanksgiving miracle
2018,turkey
2019,hey i wanted to use yts defaults to make a matplotlib plot can you remind me how to do this
2019,i remember nathan showing me a matplotlib context just for that
2019,ytfuncsmatplotlib_style_context
2019,thanks
2019,hi i had a question if anyone knows the answer is there a method of slicing in a sphere data object that can only look within a certain radius say i have a sphere already made and then i only want to look within 10 of the radius for gas is this possible without building a new sphere
2019,if you want to make images that might be tough but if you want to just grab data you might be able to do something like codesnippet
2019,or you could make a cut_regioncodesnippetcr dscut_regionsphere objradius lt valuecodesnippet
2019,in that one i think youd have to give the radius value explicitly
2019,hm the first one seems fine thank you there was a problem though it threw an error when i used the syntax you provided
2019,i replaced the condition with a numpy where statement and that worked though
2019,what was the syntax error
2019,its ok glad you got something working though
2019,codesnippetindexerror traceback most recent call lastltipythoninput35f189ebe56afagt in ltmodulegtgt 1 sphparttype1 massessphradius lt 05 sphradiusprojectbbabulrennehananaconda3envspynbodylibpython36sitepackagesytunitsyt_arraypy in __getitem__self item 1056 1057 def __getitem__self itemgt 1058 ret superytarray self__getitem__item 1059 if retshape 1060 return ytquantityret selfunits bypass_validationtrueindexerror boolean index did not match indexed array along dimension 0 dimension is 0 but corresponding boolean dimension is 8codesnippet
2019,i know there are no particles within the radius it gives the same error if there are
2019,ah it might have to be codesnippet
2019,in fact its likely to be incorrect with the codesnippet without that
2019,because codesnippet will be for all particles so that array and the codesnippet array will not be the same size
2019,i see i see
2019,but i dont think there is a parttype1 radius field
2019,i believe there should be as long as you can get positions for codesnippet there should be a radius field
2019,strange then i get ytfieldnotfound when i just tried
2019,oh maybe its codesnippet
2019,always forget particle field naming conventions
2019,yes you are correct
2019,excellent
2019,thanks so much
2019,no problem
2020,jumping on this a couple of days latecurrently were using the standard sph viz stuff for slices and projections of arepo data itd be really nice to eventually use the voronoi mesh for those also
2020,sadly this is something i am not an expert on
2020,and then every time i mention this to arepo people they just shrug and say even outside of yt they always do sphtype stuff anyway
2020,slices would be easier than projections although still hard
2020,wed need a representation of the 3d voronoi mesh couldnt do it in the image plane
2020,projections would require a voronoi volume renderer
2020,which again would need a 3d representation of the voronoi mesh
2020,for slices we wouldnt need the mesh right wed just need to iterate over all possible contributing particles which should be constrained and track a second distance field which we minimize
2020,ie a distance plane and codesnippet we set the value
2020,i dont see how youd be able to regenerate a slice of the mesh that way but im bad at visualizing this sort of thing
2020,i guess what im saying is that the voronoi mesh is an emergent property that comes from computing the nearest particle and since wed be doing that at fixed sample points we would be able to compute it ourselves
2018,user has joined the channel
2018,hello my regrets for the rookie question i want to use the codesnippet function with a 3d vector field i followed the streamlines tutorial hyperlink but i cannot figure out how to use this with my own datain my implementation of the tutorial i can see that the codesnippet object has fields codesnippet codesnippet and codesnippet which i assume provide velocity values on a regularlyspaced mesh however from which field does the function get the mesh coordinates for each vectorto put this another way suppose i start with numpy arrays corresponding to xyz coordinates and vx vy vz coordinates what is the simplest possible structure i can put this into which would allow me to use streamlines im not working with astrophysical data just simulation output thank you very much
2020,user has joined the channel
2018,user has joined the channel
2018,i am trying to use plugins in a jupyter notebook i am following along with the yt the plugin file and am not able to call functions in my ipynbthe call ytsay_hello doesnt work i defined def say_hello in my py file
2018,thats not how the plugins file works the functions you define in there wont show up in the yt namespace
2018,where did you get that impression
2018,oh huh it says in the docs that should work
2018,tries
2018,hmm so i guess it used to do that a while ago but then when we changed how the plugin file works we didnt make it inject functions into the yt namespace
2018,and youre the first person to notice
2018,or at least to report it
2018,user hyperlink
2020,hi could i have a question about this code please why is codesnippetempty the part of code before codesnippetis for generating magnetic field and the rest is part with mistake in yt thank you very muchcodesnippetcodesnippetcodesnippetcodesnippet codesnippet codesnippetimport mathimport codeimport ytfrom yt import ytarray arrays in yt modulefrom ytvisualizationapi import streamlines force lines constantsq 16e19 electron chargem 91e31 electron massv_par 2000 parallel volocity v_per 2000 perpendicular velocityx0npzeros6 vector 6 dim give zeros into it 3 components positions 3 components velocity cartesian coordinatesxmin 015xmax 015ymin 01ymax 01zmin 01zmax 01sampling 100x_ nplinspacexmin xmax samplingy_ nplinspaceymin ymax samplingz_ nplinspacezmin zmax samplingx y z npmeshgridx_ y_ z_ indexingijassert npallx00 x_assert npally00 y_assert npallz00 z_ cylindric coordinates r theta z transformation r_coor theta_coor z_coor for i in rangesampling1 r npsqrty_i2 z_i2 theta mathatan2y_i z_i z x_i r_coorappendr theta_coorappendtheta z_coorappendz computation of magnetic field according to the equations in cylindrical coordinatesdef mag_fieldgrid b_theta npzerossampling1 sampling1 sampling1 dtypenpfloat if grid2any lt 0 b_z grid0 b_r 0 elif grid2any lt nppi b_z 025 grid0 npcosgrid2 075 grid0 b_r 0253 grid0 grid0 npsingrid2 else b_z 05 grid0 b_r 0 return b_r b_theta b_zb_r b_theta b_z mag_fieldgridnpmeshgridr_coor theta_coor z_coorbx b_r npcosb_thetaby b_r npsinb_thetabz b_z choose point in field where force line will be integratedx_point 0025y_point 0z_point 0 dictionary of numpy arrays magnetic field datadata dictb1bx b2by b3bz bx datab1by datab1bz datab1 3d array bbox nparray0 25 11 11 borderds ytload_uniform_griddata b_rshape length_unitmpc bboxbbox nprocs100 data dimenze define c the center of the box chosen pointc dsarrx_point y_point z_point code_length c1 dsdomain_center n is number of streamlinesn 1 scale is the spatial scale of the streamlines relative to the boxsizescale dsdomain_width0 pos c create streamlines and integrationstreamlines streamlinesds pos b1 b2 b3 lengthnone streamlinesintegrate_through_volumefor stream in streamlinesstreamlines stream streamnpallstream 00 axis1 data of force linex_streamline stream0y_streamline stream1z_streamline stream2printx_streamline
2020,hi
2020,i tried your script out and it looks to me that your filtering condition in the final for loop is too strict so nothing comes out of it
2020,this is not strictly related to yt though its plain numpy array manipulation
2020,thank you so this is wrong codesnippet how to write the filtering better please
2020,i follow this example hyperlink could you explain me the condition please what is the aim of that line
2020,sorry im not familiar with that part of the api i actually have no idea why this filtering is there but there must be a good reason
2020,thank you for finding where the mistake is
2020,not even sure that its there actually i havent been able to reproduce the recipe itself
2020,it is solved
2020,great how did you solve it
2020,withcodesnippet codesnippet
2018,is there a blessed way to hash an entire dataset im looking at a codebase that uses codesnippet but that just ends up hashing the first file if you think youre pointing it at a multifile snapshot
2018,user hmm its supposed to hash all the files im surprised it doesnt
2018,im on 40 dunno if that matters
2018,hmm if you report an issue i can come back to that i think the original implementer may not be around the community anymore but i am not sure
2018,curious just from looking at the source i dont see anything that suggests it would find all the files involved in the snapshot
2018,hyperlink
2018,there is a thing that does this in the demeshening
2018,for sph data specifically
2018,one sec
2018,codesnippetin 1 ds_file_hashattributeerror traceback most recent call lastdocumentsytgitytmodspy in ltmodulegtgt 1 ds_file_hashattributeerror gadgethdf5dataset object has no attribute _file_hashin 2in 2 dsindexout2 ltytfrontendssphdata_structuressphparticleindex at 0x10e576c88gtin 3 ds_file_hashout3 249704968950119223codesnippet
2018,user set the channel topic general help with yt please mute if you feel its too noisy
2018,hyperlink
2018,its a method of codesnippet so that should work for any particle dataset not just sph
2018,we could do that for grid datasets too but someone would need to wire it up
2020,scipy has a good implementation of a kdtree that can do this relatively quickly hyperlink
2020,if you want only immediate neighbour you can probably do it with yt otherwise if you want to access nonlocal data as in at an arbitrary distance zachs suggestion is probably the best
2019,is there a way to use codesnippet so it is more like a 2d histogram or is the easier thing to do jsut do a 2d histogram
2019,is the codesnippet keyword what you are looking for
2019,i seem to recall that there is a function to sample a given field at an arbitrary location in a dataset but i forget the name and i forget if it works for particlebased datasets
2019,someone is asking me if there is a way to arbitrarily specify an xyz location and get out a densityweighted metallicity value for that location
2019,any ideas
2019,dspoint
2019,not sure what it means to do a weighted average with a single data point though
2019,unless youre talking about sph data
2019,i think dspoint works for sph in the demeshening
2019,yeah this is for sph data
2019,yeah i remember dspoint i just thought there was something like query_field_at_location
2019,but i guess that is dspoint
2019,there might be a lowlevel routine that ash would have written
2019,ok cool thanks
2019,interesting
2019,so codesnippet just grabs all of the particles within a smoothing length of the point you specify
2019,yeah that sounds right
2019,i guess this makes sense as its just like the other geometric data objects
2019,i guess shed have to write something more detailed to appropriately apply the smoothing kernel to each of those points to get the interpolated field value at that location
2019,yup it wouldnt be crazy to have a utility function in yt for that
2019,yeah seems like it could be useful
2019,also would work with gather smoothing too
2019,im wondering how much would piggy back on what was done in the projection stuff
2019,all the lowlevel machinery is there just needs to be wired up
2019,like this is the function you want for gather hyperlink
2019,and i guess in principle you could use this function to do scatter on a one zone grid
2019,hyperlink
2019,or refactor it or whatever so that function calls another function that does scatter smoothing at a single point
2019,user has joined the channel
2019,im actually not entirely clear about this function so one would provide a kdtree with the locations densities masses smoothing lengths and then the field you wanted to query and it would give you the interpolated value of the field at that location using the gather method not sure what the tree_positions are
2019,welcome user
2019,you could look at the place its being used inside yt hyperlink
2019,its called tree_positions because its used to interpolate onto an octree but it could be an array of arbitrary positions
2019,ok this is useful thank you
2019,also user might be interested in this discussion which perhaps might be best to continue in cbe6579czdevelopment or c046hvb59particles
2019,thanks user for starting the convo and user for some initial thoughts
2019,slightly_smiling_face
2019,yeah i think all this code exists but could maybe written in a slightly nicer way to make it easy to generalise for a single point
2019,definitely i may be able to try this down the road but am swamped right now thanks for all the pointing in the right direction user
2019,and the coding user
2019,user if youre interested i think this would be a fun first contribution to yt slightly_smiling_face
2019,we have codesnippet which i guess we could make use this
2019,that is the function i was thinking of
2019,but couldnt find it
2019,presumably it only works for grid datasets
2019,i think it uses codesnippet
2019,i have no idea what it does with sph datasets offhand
2019,looking at it now
2019,its all grid
2019,i think it would just barf on particle data
2019,since its using thisleftedge and such
2019,yeah
2019,doing this would finally justify its existence given that codesnippet exists now wink
2019,slightly_smiling_face
2019,user thanks for the encouragement im down to take on the challenge slightly_smiling_face can you think of a good shortyetsweet example function i could use as a template i see the yt style guide etc but always work better from examples and havent worked with yt before
2019,maybe as a start you could try refactoring codesnippet and codesnippet so that each if them call another function youd write that does gather and scatter interpolation at a single point id also check that there arent any performance implications of doing that by doing some timing tests with dsoctree and dsarbitrary_grid with sph data both of those functions are written in cython in hyperlink on the yt40 branch
2019,cython is sort of a combination of python and c but since this is a refactor i think you might be able to do it by example
2019,cython has pretty good docs too hyperlink
2019,youd need to set up a development build of yt by cloning the yt git repository checking out the yt40 branch and doing codesnippet in a fresh virtualenv or however you manage your python environments
2019,there are guides to how to make pull requests and work with git in the developer guide
2019,hyperlink
2019,since this initial thing would just be a refactor you wouldnt need to touch tests proabably but if you wanted to finish this and add the utility function youd need to add new tests and docs which is also explained in the developer guide
2019,happy to help out with any of these steps this is all pretty standard stuff so once you get up and running with yt development setting yourself up to contribute to pretty much any open source project on github will be way easier slightly_smiling_face
2019,see the cbe6579czdevelopment channel too slightly_smiling_face
2020,user has joined the channel
2020,hello hello i was just looking at the pytest infrastructure pr hyperlink and trying to figure out why the build is failing it seems for python 27 at least the coverage command isnt found also for the other builds it seems like my blacklist file for the pytest answer tests didnt do its job and im not sure why any thoughtshelp would be greatly appreciated thanks
2020,i think you need to add coverage to codesnippet probably also codesnippet and codesnippet
2020,it looks like nose has a ignorefiles commandline option
2020,another way to do it would be to make those functions not have names that begin with codesnippet
2020,even under pytest those arent really tests right just utility functions that might be used by tests
2020,thanks it seems both coverage and codecov are already in test_requirementstxt and test_minimal_requirementstxt but not appveyor unless im missing something here is the travis output hyperlink
2020,so if you look inside travisyml its setting up a virtualenv and then isntalling a bunch of stuff into that virtualenv and then running the tests inside it
2020,but the posttest step is using the python outside of the virtualenv
2020,so i think you just need to install coverage into the global python environment
2020,oh hmm actually nm
2020,thats wrong
2020,its dying trying to run the tests
2020,ah
2020,the real problem is that the pip install step fails
2020,because youre trying to install pytest 522 on python 27
2020,you need to expand the setup environment step in the travis output
2020,user
2020,ohh gotcha thanks
2020,probably would be better if our travisyml errored out completely if a pip install fails
2020,hyperlink
2020,ah no thats not quite what we want we probably need to check the return code from pip install and execplitly kill the script if it returns an error
2020,i added pytest46 python_version lt 30 and pytest52 python_version gt 30 to the test_requirementstxt and test_minimal_requirementstxt files i also removed the _test suffix as you suggested hopefully all is well now
2020,i think you want those to be single equal signs
2020,pytest46 is 460
2020,and you probably want the bugfix releases
2020,pytest46 resolves to 469 atm
2020,the newest 46 release
2020,hi yes thats exactly right the gadget fofsubfind catalogs refer to those made by gadgets inline halo finder there may be a standalone version of that but im unaware of itunfortunately the yt halo finders dont write out the particle information for each halo right now i recently made this work in a fork so i can push that after that there still is the matter of properly accessing that information in yt and that machinery doesnt yet exist this may be something i try to do in the near future if youre interested in helping out please let me know
2020,thanks for your help and looking forward to your work
2018,user has joined the channel
2018,user has joined the channel
2019,user has joined the channel
2019,in yt 2x there was some fields called totalmass and dark_matter_mass is there any equivalent one in yt 35 i am familiar with the fields cell_mass and particle_mass by adding cell_mass and particle_mass one can calculate total mass but i need to calculate star particle mass dose any one know how to get star particle massc2c9d1rv5enzo
2019,you need to make a particle filter for the star particle type
2019,and then calculate the total particle mass for that particle filter
2019,thanks user slightly_smiling_face
2019,this example will likely be helpful hyperlink
2019,hello again
2019,im trying to do the tutorial from jupyter notebook and when i tried to download the datasets it came up with this when i ran the program
2019,
2019,im not sure how to fix this as this was exactly what was written in the instructions for the tutorial
2019,ah thats a bug in the notebook
2019,there should be an exclamation mark before the tar command
2019,like the other ones
2019,ah perfect
2019,ok ive run it but nothing is printing
2019,its probably downloading the data
2019,ok cool thank you
2019,so i tried it on a random jupyter notebook that isnt linked to yt and it completed running really fast why is it that on this one its slower or am i doing something wrong probably
2019,the notebook that youre running downloads about 10 gb of data
2019,on a slow network connection that might take a long time
2019,so its ok that its still running
2019,oh i just got your second message ok ok my internet is clearly vvvvvv slow
2020,iirc with gadget noncosmological sims you need to set the bounding box at load time we fixed this on the yt40 branch which you might want to try out
2020,if you look in the docs on loading gadget data theres an example of how to set the bounding box manually
2020,user checkout box 2 herehyperlink
2020,well i know how to set the bounding box but i dont know why only one snapshot file has this error all the snapshot files are come from the same one cosmological simulation i think they have the same boxsize for another snapshot files theres no error when i laod them even i dont set the bounding box so why for this one snapshot the particle bound exceed the default bounding box which i think is the boxsize
2020,strange any chance you can share the data file
2020,well i update yt and its dependencies then problem solved thanks for your help user user
2020,what is the simplest way to get access raw data of a field in the entire domain
2020,is this what youre looking for codesnippetad dsall_datafield_data adltfield_keygt codesnippet
2020,thank you it is what i was looking for
2020,user has joined the channel
2018,hello everyone and thank you for accepting me in your forum or whatever i should call this workspace since this space is for asking questions i will dive straight into it i am currently working on a structure formation project and im analyzing data from the dark sky simulations project this is a cosmological simulation having only dark matter particles so what i want to do is to use the rockstar halo finder in order to identify and analyze subhalos that constitute the bigger halos given to me by the halo catalog produced from the aforementioned project now when i run the rockstar algorithm it returns a dataset like object having some fields like particle_position_x particle_velocity_x etc so regarding these fields i was wandering how were they produced for example the position is given as the position of the center of mass of the particles in this particular subhalos and the velocity is it mass weighted or not thank you in advance for your reply
2018,user welcome i believe the coordinates that rockstar has a pretty complicated algorithm for determining the centroid of halos i believe that it will be massweighted for both spatial and velocity coordinates but this isnt really a yt question i would read over the rockstar documentation method paper to see exactly how these values are calculated
2018,thank you very much for your reply well you are right as it stands the question is not very much related to yt but yt gets involved in the next step that is when i invoke the halo finder to find the subhalos i then use the halocatalog object of yt to analyze the results in particular i feed the halocatalog with the rockstar output and the original data set of the whole halo and apply some filters for example i ask for halos with mass gt 1013 solar masses here is where my real problem starts i compare the particle identifier field of the rockstar_ds and the catalog_ds and find that indeed every id in the catalog_ds already exists in the rockstar_ds as it should but when i do this for the particle position field or the particle velocity fields i find a discrepancy for example only half of the values in the catalog_ds match the ones in rockstar_ds so i guess that when i used the halocatalog object it changed some of the values in position and velocity i could just proceed and analyze the output of the halo catalog but i want to be sure that it has not changed something under my nose i hope i am not confusing you sorry for the long question but i really dont now how to phrase it better
2019,user thanks for the suggestion i found that a python visualization package codesnippet will make this easy i would like to visualize unstructured mesh data so i think it will be possible to export slice images in gray with colorbar range matching using codesnippet and align those images in 3d space with codesnippet
2019,user that sounds cool can you show me once you have a working version
2019,user definitely i will
2018,interesting im not sure the answer to your question but user will likely know since he implemented most of the halo functionality in yt
2018,user has joined the channel
2018,hi i am new to using yt and am running into some troublequestions i am currently trying to extract isosurfaces using the function codesnippet from a 3d mesh with data tagged on each cell and i am running into some trouble i am starting with a pyne mesh with tagged data i can successfully load in the data using codesnippet from there it appears to be type codesnippet i can also then do codesnippet and it appears to then convert codesnippet to type moabhex8mesh i am running into an issue then when i try to use codesnippet i get an error codesnippet so my question is is there a way to go from the dataset i do have to some dataset that can be used with codesnippet or is there a better way to get isosurface data from my mesh thanks
2018,for reference i was trying to follow this example hyperlink
2018,hi kalin
2018,unfortunately right now theres no support in yt for extracting isocontours from pyne meshes
2018,im not sure offhand how hard it would be to add support for it
2018,sorry to not have more helpful advice confused
2018,that was my suspicion do you know offhand if there is any support for converting a pyne mesh into a different type of mesh that is supported
2018,one thing you could do is interpolate your data to a 3d uniform resolution grid
2018,using eg dsarbitrary_grid
2018,and then reload that data using load_uniform_grid
2018,i dont know what your data looks like but if it has lots of fine detail but also lots of empty regions then that might be expensive
2018,hmm i will try that thanks
2020,hi all i am a firstyear grad student at the university of michigan doing some work with yt im trying to create a 1d profileplot with the yaxis as a derived field that returns the result codesnippet where each element of codesnippet is a yt field converted to an ndarray and codesnippet is a previously defined python function and the xaxis as just temperature however yt gives me the error codesnippet ive been able to make sliceplots with the values of the derived field so i know the field is giving numerical values with units does anyone know what can be done about that type of error
2019,hi can i ask if volume rendering is available for the ramses grid data now i still got the error amrkdtree does not support particle or octreebased data
2019,user i think right now the answer is sadly still no
2019,this is one that we made a lot of progress on but then had to stop due to lack of resources disappointed
2019,anyway it is good to know that
2019,thanks
2018,hi any suggestions about how to set up a python environment to switch between python 2 and 3 and to test yt
2018,yes codesnippetconda create name mypy2env python27codesnippetthen to turn oncodesnippetsource activate mypy2envcodesnippetand to turn offcodesnippetsource deactivate mypy2envcodesnippetht to user for showing me this a few weeks ago
2018,thanks i suppose i need to install yt for different pythons separately
2018,im no expert and there might be some cool way of linking installationsbut yeah i just reinstalled everything in a py2 environment as well
2018,got it ill give it a try thanks
2018,you can just have both installed simultaneously its ok to do that just call the executables python3 and python
2018,since i want to built yt from source using python setuppy develop should i simply create two yt root directories and compile them separately
2018,ah i see what youre saying yes that should work if you want to quickly switch but make sure youre using the right codesnippet in the setuppy call
2018,i think matt has some shell shortcuts to switch which one is activated
2018,i just have both simultaneously installed
2018,ill try it thanks
2018,as an update i was able to spoof a background color by drawing a set of three thousand opaque lines and positioning them appropriately in the image although this was very difficult as orienting them without being able to view the axes of the 3d volume was confusing specifically the default view cube is degenerate in the typical illusion sense about which side is front or back up or down also i had to modify the line object opacities as opaque lines would block the view of the density in the interior of the cube even if they were positioned behind the density is that expected behavior not your typical yt image i imagine but i have attached it for reference a komolgorov power spectrum
2018,yeah its physically motivated ray tracing so if the opacity reaches unity anywhere along the line of sight youll wash out that pixel
2018,cool
2018,glad to hear you figured out a workaround
2018,that bodes well for us actually be able to fix it once and for all
2018,if you comment on the issue with a script demonstrating your fix that might help us figure out a real solution
2018,apologies for the broken behavior i realize thats an important issue for publication quality graphics
2018,we just have lots of other fires that need putting out confused
2018,also for the volume rendering infrastructure in particular it was written by someone who left the field
2018,so none of us know the code very well especially the low level parts
2018,so its a tough issue to fix in that context
2018,not to just make a bunch of excuses of course but just to give you some context about why its hard to fix
2018,that is good to know thank you ill share the script in the github thread maybe someone will find it useful though i doubt it will lead to a real solution as it was very much hacked together i appreciate you sharing the context for why things behave the way they do its totally understandable just know that this is still the best 3d rendering library ive found to integrate with python though it may be worthwhile to at least add a comment on the page with the cookbook saying that this behavior is broken at the moment
2018,hi is there a way to do a particle union of filtered particles
2018,does that not work
2018,it should i think
2018,i mean defining the particle union just as youd define any other particle union assuming the filter has already been defined
2018,this line hyperlink prevents it
2018,i guess try replacing that with codesnippet instead of codesnippet i dont know offhand what would break
2018,but codesnippet has only keys for raw particles right
2018,like i said i dont know offhand what would break
2018,i guess the answer to your question is that no one has tried to implement it yet
2018,i dont see any particular reason why this shouldnt work but it looks like the current implementation was written without this use case in mind
2018,ok fair enough slightly_smiling_face
2018,i think i managed to find where the missing part is but im a bit lost
2018,if i force yt to also accept derived fields there is an issue in codesnippet because the code tries to read derived fields as if they were raw fields
2018,and hence fails
2018,whats the traceback
2018,probably that needs to be explicitly handled at a higher level somewhere
2018,i opened an issue
2018,hyperlink
2018,so codesnippet and codesnippet are particle filters defined by the ramses frontend
2018,yes
2018,its going to probably be somewhere in codesnippet theres like an assumption somewhere in there that all the fields that make up a particle union are ondisk fields which youre breaking
2018,in particular the fact that its going into codesnippet indicates that
2018,id try to see what happens in that function when you pass it a particle filter field it should be going down the same code path when you pass it a particle union
2018,at least for the parts of the union that are fields associated with a particle filter
2018,the issue is around here i guess hyperlink
2018,in the case of a union made with raw particles ptf contains a raw particle field
2018,id be a little surprised if the issue was there actually
2018,at that point we should only be dealing with fields that we actually need to read from disk
2018,but i might be wrong
2018,the lines i sent are finding all the fields that are making up the union and readthem expecting them to be on disk
2018,hyperlink
2018,so i guess we also need to add logic to codesnippet that handles the case where particle unions might be made up of particle filters as well as ondisk fields
2018,i think
2018,again id look at how io for particle filter fields work in that function
2018,i dont know offhand how that works id need to test and poke at that function with a debugger
2018,ive set up a minimal version that doesnt crash anymore
2018,it does so by reading from disk only raw particles types
2018,now i have to figure out how to get codesnippet to append the relevant data
2018,is there a reason why codesnippet
2018,should it not be i dont know enough about the ramses frontend or how those fields are set up
2018,well codesnippet is the particle union
2018,so id expect not to be codesnippet
2018,ah ok getting closer
2018,i added a test in codesnippet to filter out derived fields
2018,its because codesnippet assumes its always setting up an ondisk field
2018,that function gets called by codesnippet
2018,to be precise what is exactly an ondisk field
2018,a field that we can read directly from disk
2018,without doing any processing on it
2018,so it should in principle exclude fields that are unions of derived fields
2018,of particle filters yes
2018,hi is it possible to load two cubes fits file matching size into the same scene while doing the volume rendering the idea is to compare the two cubes
2018,sure you need to create two volumesource instances one for each dataset
2018,like this example hyperlink
2018,note that ive never tried to do what youre doing there might be issues im not aware of
2018,the volume rendering multiple fields example
2018,yup the one i linked to
2018,that example shows how to do what you want with two fields from the same dataset
2018,but it should work with two fields from different datasets assuming the units are the same
2018,i do have to match the units before that ill follow that example and give it a try
2018,thank you so much
2018,hey all i have a simple question about halo finding i want to load a codesnippet ds and find halos of gas particles only
2018,i try something like
2018,codesnippetn 2 ds ytloadsnapshot_100hdf5yt info 20180815 200328448 calculating time from 4444e01 to be 1585e17 secondsyt info 20180815 200328449 assuming length units are in kpch comovingyt info 20180815 200328467 parameters current_time 15852279102079226e17 syt info 20180815 200328467 parameters domain_dimensions 1 1 1yt info 20180815 200328467 parameters domain_left_edge 0 0 0yt info 20180815 200328467 parameters domain_right_edge 50000 50000 50000yt info 20180815 200328468 parameters cosmological_simulation 1yt info 20180815 200328468 parameters current_redshift 12500002398009817yt info 20180815 200328468 parameters omega_lambda 07yt info 20180815 200328468 parameters omega_matter 03yt info 20180815 200328468 parameters hubble_constant 068in 3 from ytanalysis_moduleshalo_analysisapi import halocatalog in 4 hc halocatalogdata_ds dsfinder_methodfoffinder_kwargsptypegas hccreatecodesnippet
2018,but then it barfs withcodesnippetin 5 hccreateyt warning 20180815 200458628 dm_only is deprecated use ptype to specify a particle type insteadruntimeerror traceback most recent call lastltipythoninput56b9262d90adcgt in ltmodulegtgt 1 hccreateytytanalysis_moduleshalo_analysishalo_catalogpy in createself save_halos save_catalog njobs dynamic 335 336 gt 337 self_runsave_halos save_catalog njobsnjobs dynamicdynamic 338 339 def loadself save_halostrue save_catalogfalse njobs1 dynamicfalseytytutilitiesparallel_toolsparallel_analysis_interfacepy in barrierizeargs kwargs 299 def barrierizeargs kwargs 300 if not parallel_capablegt 301 return funcargs kwargs 302 mylogdebugentering barrier before s func__name__ 303 comm _get_commargsytytanalysis_moduleshalo_analysishalo_catalogpy in _runself save_halos save_catalog njobs dynamic 404 if selfhalos_ds is none 405 find the halos and make a dataset of themgt 406 selfhalos_ds selffinder_methodselfdata_ds 407 if selfhalos_ds is none 408 mylogwarningno halos were found for 0formatytytanalysis_moduleshalo_analysishalo_finding_methodspy in __call__self ds 42 43 def __call__self dsgt 44 return selffunctionds selfargs selfkwargs 45 46 def _hop_methodds finder_kwargsytytanalysis_moduleshalo_analysishalo_finding_methodspy in _fof_methodds finder_kwargs 59 60gt 61 halo_list fofhalofinderds finder_kwargs 62 halos_ds _parse_old_halo_listds halo_list 63 return halos_dsytytanalysis_moduleshalo_findinghalo_objectspy in __init__self ds subvolume link dm_only ptype padding 1605 raise runtimeerror 1606 if dm_only is true ptype must be none gt 1607 dm_only must be false if ptype is set 1608 1609 if ptype is noneruntimeerror if dm_only is true ptype must be none dm_only must be false if ptype is setcodesnippet
2018,so i see that codesnippet as a keyword is deprecated i set codesnippet as gas its possible i need to set it as codesnippet or something but i cant quite figure out what that setting ought to be
2018,user codesnippet works when i tried
2018,ah i think i tried the codesnippet part as a keyword and not a codesnippet thanks user
2019,does codesnippet work for codesnippet im trying to do something likecodesnippet p ytparticleplot ds particle_position_x particle_position_y particle_mass pannotate_contour density codesnippetbut get the error codesnippet
2019,im trying to add velocity quivers on a projection plot which i have done before but naturally cant find a working example of tried mimicking hyperlink but im clearly missing something suggestions the projection is made doing codesnippet with centers and things specified
2019,user i dont think so right now no
2019,user any chance you can make a runnable example that triggers that error using one of the data files from hyperlink
2019,wait
2019,sobsoverlackofemojihere
2019,user thanks for the quick response i guess i can create a similar image using the codesnippet field or do you have any other suggestion even if it requires some hard coding
2019,it works well i get fugly overdrawn lines upside_down_face for the isolated galaxy version
2019,are the scripts identical
2019,if theres some difference that might be causing the error one possibility was you called annotate_quiver incorrectly earlier in your notebook
2019,and youre seeing the error for that incorrect call
2019,effing notebooks
2019,its a little confusing because the plot callbacks dont actually get called until the plot is drawn
2019,ok let me it from scratch then
2019,part of the whole doing this in a notebook thing was because the making the projection takes nearly a minute and then i forget im doing it
2019,big simulation fun times
2019,also hey molly wave
2019,wave
2019,yes ok so remaking the projection plot worked is there a way to now remove the quivers i have edit them so i can make modifications without regenerating the entire thing again and again
2019,codesnippet
2019,ooooh
2019,codesnippet
2019,codesnippet
2019,copied from the cookbook
2019,i dont think theres any reason why it couldnt use the contour callback it just hasnt been wired up it might be as simple as just removing callback from the blacklist one sec to point at the place in the code
2019,seems like it should work to me are you maybe using a yt version older than 2018
2019,hyperlink
2019,ugh
2019,yes
2019,let me give it a try
2019,341
2019,updated it on one computer but not all
2019,ok thanks slightly_smiling_face
2019,dear ytusersi need to pass the value of the availablederived field corresponds to the index selected based on some criterion using numpywhere to a scalar function it should list out the indexes wheres the condition satisfies it happens when this has been done outside the field but instead of getting 3d indexes it gives 1d yt_array indexes i thinkbut i need to pass this value of field corresponds to the selected index to scalar function inside the field which may give some problem please find the attachment to see what exactly i am trying to dothe attached script can run on the enzo test data set enzo_tiny_cosmologymany thanks and regards
2019,here the script
2019,got the following errorcodesnippettraceback most recent call last file plot__particlepy line 68 in ltmodulegt psave prefix_out_dsbasenamepng mpl_kwargsdpidpi file work1fishsoftwareytytpy2ytvisualizationplot_containerpy line 92 in newfunc args0_setup_plots file work1fishsoftwareytytpy2ytvisualizationplot_windowpy line 1070 in _setup_plots selfrun_callbacks file work1fishsoftwareytytpy2ytvisualizationplot_windowpy line 1127 in run_callbacks sysexc_info2 file work1fishsoftwareytytpy2ytvisualizationplot_windowpy line 1121 in run_callbacks callbackcbw file work1fishsoftwareytytpy2ytvisualizationplot_modificationspy line 75 in _check_geometry return funcself plot file work1fishsoftwareytytpy2ytvisualizationplot_modificationspy line 620 in __call__ if selftake_log zinplog10ziytutilitiesexceptionsytplotcallbackerror annotate_contour callback failed with the following error local variable zi referenced before assignmentcodesnippet
2019,ill play with it a bit further
2019,well i guess thats why it was on the blacklist slightly_smiling_face
2019,most of the entries on the blacklist could be fixed someone just needs to do the work
2019,no problem i can give it a try thanks again for the help slightly_smiling_face
2019,ill file an issue first if thats ok
2019,sure
2019,1
2019,another way around this blocker for you would be to get the image from the frb attribute and then make the plot manually in matplotlib
2019,i think codesnippet uses the frb interface anyway
2019,codesnippet
2019,good suggestion thanks
2019,hi prateek not sure what you are exactly trying to achievedo you want to have a field which will take certain values given another field then maybe you can direclty add the field and not take the detour via the indices
2019,does anyone else have a problem when setting codesnippet explicitly in codesnippet if i runcodesnippetfor i in ytparallel_objectsrange10 njobs x printicodesnippetfor codesnippet everything works fine but for codesnippet and codesnippet where codesnippet is the processors i run the script on every thread will printi ie i am getting several zeros etc
2019,sounds like a bug to me
2019,i am wondering if it is just my mpi or everybody has this issue
2019,i dunno let me try
2019,it seems to be working for me
2019,codesnippet cat testpyimport ytytenable_parallelismfor i in ytparallel_objectsrange10 njobs 2 printi mpirun n 4 python testpyyt info 20191031 142000857 global parallel computation enabled 2 4yt info 20191031 142000857 global parallel computation enabled 3 4yt info 20191031 142000857 global parallel computation enabled 0 4yt info 20191031 142000857 global parallel computation enabled 1 413570135979022464688codesnippet
2019,there are two parallel for loops with 4 mpi processes
2019,and the output is as expected i think
2019,as expected you get multiple times every number
2019,thats the same output i get but i thought that one will get every number just once as you obtain if you set codesnippet
2019,you get two of them
2019,one for each of codesnippet
2019,maybe im wrong about how codesnippet should work
2019,i dont really remember its been several years since ive used it
2019,ok maybe i just completely misunderstood the example here hyperlink i thought the sentence if the inner parallel_objects call were removed from the loop the twoprocessor work group would work together to project each of the density and temperature fields this is because the projection functionality itself is parallelized internally means that then codesnippet is called only once
2019,you might very well be right i dont think codesnippet is commonly used without codesnippet you might want to look at the source code and see if you can understand how it works
2019,i think everything is working properly since you have codesnippetyou have two processors working on each loop and double outputting if you have codesnippet then 4 outputs for every number assuming you are running it with 4 processors setting codesnippet doesnt really seem that effective though from some of the things i have been doing maybe even slowing because of communication overhead unless the problem is massive that i am doing on each step like extracting a bunch of uniform volumes
2018,user has joined the channel
2018,thanks for your feedback to kiran on issue 1921 hes an ug student working with me
2018,user has joined the channel
2019,trying to build some intuition of the current state codesnippet has the functionality of evaluating a field at an arbitrary point in a simulation but currently only works with grid codes not sph we can get that functionality with sph data if i refactor 1 codesnippet and 2 codesnippet the documentation for codesnippet saysgt this function takes in arbitrary positions field_positions at which to perform a nearest neighbor search and perform sph interpolationthat sounds like what i want but youre suggesting it cant do it at an arbitrary positionthe documentation for codesnippet saysgt this function takes in the bounds and number of cells in a grid well actually we implicity calculate this from the size of buff then we can perform nearest neighbor search and sph interpolation at the centre of each cell in the gridim struggling to see the differences in their functionality thinking_face user can you say a bit more about what gather and scatter interpolation is
2019,also should i move this conversation to cbe6579czdevelopment
2019,for gather scatter see hyperlink
2019,thanks user for the reference
2019,i have a gizmo snapshot of a zoomed galaxy and want to rotate and translate into the frame of the high res galaxy i have the coordinates rotation matrix and code to do the rotationtranslation but how do i access the coordinates to change them specifically in such a way that i can then do visualization stuff
2019,to my knowledge we dont have a mechanism for changing the inmemory coordinate system from one to the other however it would be relatively straightforward to write a function in python that could just do the trig to convert from one to the other i think
2019,i guess you could make derived fields for the new coordinate system but not change the existing coordinates on disk
2019,to access the original coordinates just treat them like any other spatial fieldcodesnippetad dsall_dataadgas xcodesnippet
2019,you can set the field parameters associated with a specific data object in this case codesnippet returns a codesnippet data object so you could set the center of your galaxy bycodesnippetad dsall_dataadset_field_parametercenter x_center y_center z_centercodesnippet
2019,you can also set the normal vector for a data object this way using the codesnippet function
2019,its straightforward to get a rotation matrix in yt hyperlink
2019,as for visualization you can use the codesnippet and codesnippet to do projections from an arbitrary normal vector to an arbitrary center location
2019,i hope this helps others may be able to chime in and offer other suggestions i have missed
2019,awesome thanks user
2019,slightly_smiling_face
2020,hi user codesnippet is something i wrote so im happy to help you with this unfortunately im in an all day review meeting today but i will get back to you tomorrow
2020,also please ping me here if you havent heard back after tomorrow i forget things quite easily
2020,thanks for your reply i think i know what happens here in treefarm halo catalogs must be in the form created by the gadget fof halo finder or subfind substructure finder but my halo catalogs were created in yts halocatalog i thought they are the same but actually notand do you know how to get gadget fofsubfind halo catalogs can i get them in yt or is there another code or somthing i cant find it online
2020,attached is a poloidal slice through a 3d disk simulation i am studying the xaxis of the codesnippet gives radius from the parent object the yaxis gives elevation in the disk the simulation data is on a 3d cartesian mesh does codesnippet have an infrastructure to perform an azimuthal codesnippet average of this plot codesnippet can use the codesnippet keyword to average along the x y or z dimension codesnippet can perform azimuthal averages of data objects after supplying codesnippet and codesnippet field parameters to produce 1d profiles but neither of these are exactly what i am after as always thanks in advance for all the support
2020,user i believe it can i think a phase plot could do this where the binning fields were z and cylindrical theta
2020,oohlet me try
2020,thx user
2020,thanks again user looks great if anyone else is interestedcodesnippet define cylindermy_cylinder dsdiskmy_center_of_mass 001 5 r_earth 52 r_earth create profileprofile ytcreate_profile data_sourcemy_cylinder bin_fieldscylindrical_radius cylindrical_z fieldsspecific_energy n_bins140140 unitsdictcylindrical_radiusr_earth cylindrical_zr_earth logsdictcylindrical_radiusfalse cylindrical_zfalse weight_fieldcell_volume extremadictcylindrical_radius05 cylindrical_z52 52 phase plotplot ytphaseplotfrom_profileprofileplotset_logspecific_energy falseplotset_zlimspecific_energy 08e11 15e11plotset_cmapspecific_energy rdbu save figureplotsaveyt_answerpngcodesnippet
2020,user awesome
2019,i have some gizmostyle datasets and im trying to do some rather custom plotting this is an sph dataset when i run this codecodesnippet image yton_axis_projection dsboxcenter width2 center width2 center normal_vector10 00 00 width dsarrwidth3 resolution256 256 itemparttype4 masses north_vector00 00 10 codesnippeti get the confusing exceptioncodesnippetruntimeerror can only perform offaxis projections for sph fields received parttype4 massescodesnippetis this a yt internal terminology thing i dont understand otherwise this smells buglike
2019,user thats really strange but i cant say just now if its any deeper than what youre seeing that it thinks you cant do it because it assumes itll only be asked to project sph not nbody particles
2019,ahhhhh duh parttype 4 doesnt have a smoothing length so its not sph
2019,yay
2019,hi i have a problem in compiling yt from source on a cluster the compile is successful while when i codesnippet the error shows codesnippet
2019,btw i can install yt after switching from codesnippet to codesnippet
2019,i bet whatever compiler you build with yt must be accessible whenever youre trying to use it if you compile with intel you probably need to have the intel module loaded whenever you import
2019,thanks ben i guess so therefore i decided to switch to gcc whenever i use yt
2019,user thank you for your advice i just got volume rendering images out of my image stack
2019,user also i made a small mistake in the patch it should readcodesnippetfrom 3526ad0f76cccff9825f4ee25b5a8758fa45c48b mon sep 17 000000 2001from corentin cadiou ltcontactcphycmegtdate sun 5 may 2019 190208 0200subject patch quick fix ytfrontendsramsesdata_structurespy 1 ytfrontendsramsesdefinitionspy 3 2 files changed 3 insertions 1 deletiondiff git aytfrontendsramsesdata_structurespy bytfrontendsramsesdata_structurespyindex c5802cbba12979474e 100644 aytfrontendsramsesdata_structurespy bytfrontendsramsesdata_structurespy 1396 1397 class ramsesdomainfileobject for header in ramses_headerhvals hvalsupdatefread_attrsheader fseek484 1 skip reading of mass_sph for speedup skip reading of headl and taill fskip2 hvalsnumbl fread_vectoridiff git aytfrontendsramsesdefinitionspy bytfrontendsramsesdefinitionspyindex 9cc8278eda3235580a 100644 aytfrontendsramsesdefinitionspy bytfrontendsramsesdefinitionspy 427 428 def ramses_headerhvals stat 3 d cosm 7 d timing 5 d mass_sph 1 d mass_sph 1 d yield next_set field_aliases 2210codesnippet
2019,i tested the code on one of my dataset and it reads thumbsupskintone3
2019,hi user thanks for your patience ive been playing around with neater ways to do this but havent done much yet theres no way to do codesnippet but a shorthand that should at least make things more concise would be to do something likecodesnippetm200c aarrhm200c for h in haloscodesnippetthat will at least give you a ytarray with proper units that you can then do stuff with
2019,sorry to make you wait so long for such an anticlimactic answer but hopefully that helps a bit let me know if you have any more questions and thanks for using ytree
2019,thank you this does seem to be better than what i was doing
2019,user has joined the channel
2020,user has joined the channel
2020,is there a way to create radial bins in profiles for particle fields without depositing the derived fields eg particle_velocity_cylindrical_theta into deposit
2020,and then just creating the profile against index radius
2020,you probably want the particle_radius field
2020,you cant mix grid and particle fields so if you want to profile particle fields you need to use particle fields for both axes
2020,hello everyoneim trying to make a multiplot using the example code given under multiplot and slice projections hyperlink
2020,heres my code
2020,codesnippetdef _nhifielddata return dataparttype0density dataparttype0hydrogen dataparttype0aphimhpath afsmpatempmrmgehlmaurorasnapshot_052ds ytloadpathsnap_0520hdf5dsadd_fieldh_p0_number_densitysampling_typeparticlefunction_nhiunits1cm3force_overridetruetridentadd_ion_fieldsdsions o ic iisi iife iisampling_typeparticleorient horizontalfig axes colorbars get_multi_plot32colorbarorientbw6center dsdomain_centerleft_corner dsdomain_left_edgeright_corner dsdomain_right_edgedepth dsquan10code_lengthleft_corner2 center2 05 depthright_corner2 center2 05 depthregion dsboxleft_corner right_cornerres 12001200width 625code_lengthwidth1 07code_lengthvvcc dsfind_maxh_p0_number_densityleft cc right cc depth1 dsquan075code_lengthleft left depth1right right depth1reg dsboxleftrightslc ytprojectionplotds z fieldsh_p0_number_densityo_p0_number_densityc_p1_number_density weight_fieldnonedata_sourceregionproj ytprojectionplotds z fieldsh_p0_number_densityo_p0_number_densityc_p1_number_density weight_fieldnonedata_sourceregslc_frb slcdata_sourceto_frbwidthresproj_frb projdata_sourceto_frbwidth1resdens_axes axes00 axes10temp_axes axes01 axes11vels_axes axes02 axes12slc_dens nparrayslc_frbh_p0_number_densityproj_dens nparrayproj_frbh_p0_number_densityslc_temp nparrayslc_frbo_p0_number_densityproj_temp nparrayproj_frbo_p0_number_densityslc_vel nparrayslc_frbc_p1_number_densityproj_vel nparrayproj_frbc_p1_number_densityplots dens_axes0imshowslc_dens originlower normlognorm dens_axes1imshowproj_dens originlower normlognorm temp_axes0imshowslc_temp originlower temp_axes1imshowproj_temp originlower vels_axes0imshowslc_vel originlower normlognorm vels_axes1imshowproj_vel originlower normlognormcodesnippet
2020,i get the following error
2020,codesnippetp009 yt info 20200219 182258212 making a fixed resolution buffer of h_p0_number_density 1200 by 1200 file trident_projectionpy line 69 in ltmodulegt slc_dens nparrayslc_frbh_p0_number_density file afsmpatempmrmgehlmytyt40ytvisualizationfixed_resolutionpy line 136 in __getitem__ units selfdata_sourceitemunits file afsmpatempmrmgehlmytyt40ytdata_objectsdata_containerspy line 266 in __getitem__ rv selfdsarrselffield_datakey fiunitsp014 yt error 20200219 182313608 keyerror h_p0_number_densityp014 yt error 20200219 182313608 error occured on rank 14application called mpi_abortmpi_comm_world 1 process 14codesnippet
2020,even if i try to run the exact script from the cookbook i get the same error except codesnippet on the 3rd last line
2020,im using codesnippet
2020,i cant seem to figure out whats wrong any ideas whats going on here
2020,thanks
2020,if you make it use codesnippet instead of the string codesnippet
2020,does it work
2020,even if that does work this seems like a bug to me though if you can open an issue on yts github with details that would be very much appreciated
2020,opening an issue on github helps us not lose track of bug reports
2020,let me check if it works with codesnippet if not ill open an issue on github
2020,thanks
2020,even if it does work an issue report would be appreciated
2020,passing a string should work
2020,alright cool ill report it regardless
2020,another question i had is when i try to add the ion fields to the dataset i get codesnippet is there a way i can force override this
2020,with trident sounds like a trident issue
2020,trident has its own slack channel iirc
2020,alright thanks ill check it out there
2020,ive opened the issue
2018,user has joined the channel
2018,user has joined the channel
2018,how do you change the name of a plugin file using pluginfilename hyperlink
2018,have an entry in your config file that looks like thiscodesnippetytpluginfilename my_filenamepycodesnippet
2018,so i have a file called my_pluginspy located in configyt
2018,inside that file all i have is
2018,pluginfilenameplugpy
2018,plugpy is also stored in configyt and contains a simple print statement
2018,when i call ytenable_plugins in my jupyter notebook i want to see my print statement as an output however all i see is yt info 20180627 101259839 loading plugins from homemnielanconfigytmy_pluginspy
2018,what am i doing wrong
2018,the config file should be located at codesnippet
2018,the contents of that file should becodesnippetytpluginfilename plugpycodesnippet
2018,and you should delete the codesnippet file you have in codesnippet
2018,thank you
2019,hi everyone i am having this strange issue in extracting codesnippet from my data when i use codesnippet on a single 2d slice codesnippet seems to work fine i get varying integer values of values between 0 and the finest however when i do this with a volume using codesnippet the data is all at a single level i specify from the codesnippet argument or using codesnippet i get all my values being 99 which is not correct any idea about what would be causing this issue or how to solve it
2019,i should add i did the exact same procedure with codesnippet and my extracted data was correct
2020,regardless wed have to compute it ourselves since its not stored in the snapshot files
2019,im gonna have a discussion with nelle varoquaux about this soon
2019,updated yt bug persists
2019,what yt and matplotlib versions
2019,codesnippet and codesnippet
2019,user has joined the channel
2019,codesnippetgtgtgt import ytgtgtgt yt__version__40dev0gtgtgt import matplotlibgtgtgt matplotlib__version__302codesnippet
2019,ah we probably need to merge the 40 branch with master to get the fix
2019,one sec let me port the specific fix you need
2019,the pr with the fix is hyperlink
2019,hmm i think i need to update some tests with this pr so i shouldnt just push directly but ill open a pull request and user can pull that pull request in locally until its merged sorry again for the trouble disappointed
2019,user do you have a github handle
2019,saethlin
2019,im in meetings for a bit but ill do the thing youre describing when im done no worries
2019,to get the fix do
2019,codesnippetgit checkout b ngoldbaumyt40 yt40git pull hyperlink yt40codesnippet
2019,and youll have the fix in a new branch named codesnippet
2020,hi im having a little bit of trouble with codesnippet its returning a ytquantity in units of code_temperature when im after kelvin is there a way to set the units of a ytquantity i cant figure it out
2020,try thiscodesnippettmax coords dsfind_maxtemperaturetmax hyperlinkkcodesnippet
2020,perfect thank you
2020,this is awesome was planning to do something similar mind sharing your cookbook recipe
2019,user has joined the channel
2019,hi so i refound this problem with chaining cut_regions i looked on github and nathan had opened an issue for me but then closed it i think it may have gone unfixed though so can i reopen it or do i just do a new issue
2019,hyperlink
2019,i have made a cleaner example script of the problem using isolatedgalaxy
2019,hi stephanie i think it would be clearest to go ahead and make a new issue you can refer to the old issue by saying 1093 somewhere in your issue description github will automatically link things
2019,ok cool will do thanks
2019,since codesnippets unit support offloads conversions to sympy you can pass any expression with valid dimensions to codesnippetis this intentional i found a use for it and i like it just curious
2019,user can you give a short example of what youre talking about
2019,codesnippet
2019,oh yes units can have constant multipliers
2019,i havent tried anything more diabolical
2019,im considering trying it now but this is something i _wanted_ to work so i was amazed then went back to what i was doing stuck_out_tongue
2019,yeah thats intentional slightly_smiling_face
2019,thanks slightly_smiling_face
2018,hey everyone may i know if it is possible to overplot a line on a phaseplot
2018,you can but its a bit buried
2018,once you have your codesnippet object or similarly for projections and slices you can access the internal matplotlib ax _via_ codesnippet which you can use as a regular matplotlib axis
2018,user thanks for your reply i may have done something stupid but following your instructions i got keyerror gas temperature may i know why
2018,you should look up what are the keys of codesnippet
2018,i think they are indexed by codesnippet and codesnippet in your case
2018,so that would be codesnippet
2018,is it possible to force a dataset to regenerate its index and clear its cache of the loaded data
2018,another way of formulating it is where are the data cahced once generatedread from disk
2018,i figures out i could delete codesnippet to force the index to be rebuilt but i would like to flush any cached data
2018,thanks for your quick reply i checked and corrected it to ppplotsgas cell_volume it now runs without error but the line is not appearing on the phaseplot
2018,user if you have any more suggestions i would greatly appreciate it
2018,to be honest thats beyond my knowledge you should check out hyperlink
2018,ive been using the clump finding infrastructure in yt which is great but pretty slow on some big datasets ive got when i try to run it with codesnippet i get a segfault i guess its not enabled to use mpi within the codebase
2018,user thanks for your help i have tried everything i know but still cant get the line to appear hope i can get more help from more experts on this
2018,user yeah that sounds right i think it might have been once it will be slow on big datasets lots of room for improvement try running cprofile on it to see if we can find highlevel slow areas
2018,user here let me make an example
2018,user not really i guess you could do codesnippet and reload the dataset
2018,user hyperlink
2018,user a couple caveats you need to do your customizations after calling codesnippet
2018,otherwise they wont show up
2018,im guessing that you were applying your customizations on an axes that was getting clobbered after you did the customizations id like to make the api for this nicer
2018,user those ci failiures look spooky should your branch be good for my limited use anyway
2018,sorry what ci failures
2018,oh on my pr
2018,i didnt look thanks for reminding me
2018,ah looks like i didnt handle a corner case will fix
2018,1
2018,just pushed again this should hopefully pass more tests slightly_smiling_face
2018,argh still two failing tests closer though
2018,might have to fix these tomorrow
2018,user has joined the channel
2019,thanks
2019,oh unfortunately it is really slow for octree datasets
2020,374
2020,indeed i didnt think to mention i was attempting to build on python 38thanks a lot for your reply for now i believe i should be able to do what i want with 36 or 37
2020,report i was able to complete installation on python 37 but not on python 36 question
2020,user i think osx equivalent of codesnippet is called codesnippet
2020,it can attach to a running process so in one terminal run codesnippet and in the other do codesnippet
2020,theres also codesnippet on osx not sure whats the difference
2019,user has joined the channel
2018,i ran the exact same script with the isolatedgalaxy sample data on codesnippet to export to skectfab but i got codesnippet
2018,any ideas on why or should i open an issue on githubflushed
2018,can you pastebin the full traceback
2018,although looking at the code i think i see the issue
2018,yeah i see the issue
2018,gonna make a pr
2018,codesnippetattributeerror traceback most recent call lastltipythoninput3ad08c11cbb2cgt in ltmodulegt 16 color_logtrue 17 boundsboundsgt 18 api_key9e2d061cee1c4c58916f0eda98e8e19a 19 anacondalibpython36sitepackagesytdata_objectsconstruction_data_containerspy in export_sketchfabself title description api_key color_field color_map color_log bounds no_ghost 1913 ply_file temporaryfile 1914 selfexport_plyply_file bounds color_field color_map color_loggt 1915 sample_type vertex no_ghost no_ghost 1916 ply_fileseek0 1917 greater than ten million vertices and we throw an error but dumpanacondalibpython36sitepackagesytdata_objectsconstruction_data_containerspy in export_plyself filename bounds color_field color_map color_log sample_type no_ghost 1760 selfcolor_field 1761 elif sample_type vertex and gt 1762 color_field not in selfvertex_data 1763 selfget_datacolor_field sample_type no_ghostno_ghost 1764 self_export_plyfilename bounds color_field color_map color_logattributeerror ytsurface object has no attribute vertex_datacodesnippet
2018,thank you
2018,hyperlink
2018,user has joined the channel
2018,i got the same error but a different traceback after applying the changes
2018,codesnippetattributeerror traceback most recent call lastltipythoninput15ad08c11cbb2cgt in ltmodulegt 16 color_logtrue 17 boundsboundsgt 18 api_key9e2d061cee1c4c58916f0eda98e8e19a 19 anacondalibpython36sitepackagesytdata_objectsconstruction_data_containerspy in export_sketchfabself title description api_key color_field color_map color_log bounds no_ghostanacondalibpython36sitepackagesytdata_objectsconstruction_data_containerspy in export_plyself filename bounds color_field color_map color_log sample_type no_ghostattributeerror ytsurface object has no attribute vertex_datacodesnippet
2018,user did you reimport yt after applying the patch codesnippet that nathans pr updates is the only occurrence i see in the code
2018,if i make any changes to source files while using ipython i usually exit and restart to make sure the imports are fresh
2018,sorrydisappointed_relieved i should have reimported yt but i somehow forgot
2018,no worries slightly_smiling_face
2018,thats an easy mistake to make
2018,when using codesnippet the color is supposed to be represented as an array of 3 floats can we add a fourth float representing the transparency i tried to run it with an array of 4 floats it was not raising errors but the final result when using this colormap and exported to skechfab was not showing transparency either
2018,user has joined the channel
2018,hi i am wondering if it is possible to retrieve the dark matter particles associated with each halo from a rockstar halo catalog
2018,i have the rockstar binary output which should contain this information but its not clear to me whether i can access it through yt
2018,if i load the halo andor particle data with ytload it seems i can only access the halo data
2018,do you have the original dataset the halo finder was run on
2018,yes
2018,ok let me see if i can make a quick example for you to look at
2018,i have loaded them together and there is a particle_identifier but it seems to refer to the halo
2018,that would be amazing thanks
2018,just a pointer to the right part of the docs would be plenty help though i just cant seem to find the right place to look for how to do this
2018,yeah i dont think theres a worked example exactly like this right now
2018,heres what i just pieced together
2018,based sort of on this example but i also had to look at the source code a bit hyperlink
2018,yes thats the example i was trying too
2018,codesnippetimport ytfrom ytanalysis_moduleshalo_analysisapi import halocataloghalos_ds ytloadrockstar_haloshalos_00bindata_ds ytloadenzo_64dd0043data0043hc halocatalogdata_dsdata_ds halos_dshalos_dshccreatesave_halostrue grab the 0th halohalo hchalo_list0 print data about this haloprinthaloquantities print the particle id of all particles in this halohalodata_objectparticle_indexcodesnippet
2018,i dont think we read in the particle ids from the rockstar output
2018,i guess it would be useful to add that ability i dont know enough about rockstars data format to be helpful with adding that though
2018,what im doing in this example is creating a sphere data object in the data_ds centered at the halos location
2018,and then getting all the particles in the data_ds that are inside that sphere
2018,not quite the same as the particles that are in the halo identified by rockstar
2018,i might be missing something though im not a cosmology person really
2018,there is some c code shipped with rockstar that provides functions to do this but i was hoping for a less cumbersome way with yt
2018,user might know more although hes not around right now
2018,functions to read the binary with particle ids
2018,i suppose some of the particles inside the sphere of the yt catalogue may not be gravitationally bound particles then but perhaps this will be enough for my needs
2018,thanks a lot for the help
2018,np
2018,if the data really do exist in the binary outputs we could probably add a way to get at those
2018,it just requires writing the code to do it slightly_smiling_face
2018,im gonna head home for the night
2018,have a good evening and welcome to the yt slack and community slightly_smiling_face
2018,yeah if i manage to retrieve them with the proper method i could let you know how i did it
2018,rockstar mentions the possibility here
2018,hyperlink
2018,have a good night and thanks again
2018,ah perhaps this is a new feature in rockstargalaxies
2018,the rockstar frontend was written before that was a thing
2018,so i have created the halo catalog using the code snippet above and if i grab a halo from the halo_list it doesnt have a data_object attribute
2018,perhaps it is the particle data format i am using the eagle simulation data which was generated with a modified gadget code
2018,maybe yt does not know how to read this though it didnt throw any errors when i made the original halocatalog object
2018,we have an eagle example dataset on hyperlink
2018,you could try running your example using that dataset
2018,and then one of us would be able to reproduce the issue and see whats going on
2018,the relevant code is here
2018,hyperlink
2018,thats the main loop for creating the halo catalog
2018,if codesnippet is true then codesnippet gets populated
2018,my halo_list has been populated
2018,ah but the codesnippet doesnt have a codesnippet hmm
2018,but the only quantities in the halo items are particle_identifier _mass _position and virial_radius
2018,and these seem to refer to the halo
2018,so perhaps the particle data wasnt read in properly
2018,i can try with the example dataset and see how it goes
2018,ah sorry
2018,i forgot a step
2018,codesnippet
2018,you need to tell the halo catalog to create the data object
2018,codesnippet sets the radius of the sphere to twice the virial radius
2018,aha got you
2018,ill give it another shot so
2018,sorry about that i should have double checked that the code i pasted in here was working correctly
2018,i had it working in an interactive ipython session and i messed up copypasting
2018,there are a bunch of other callbacks that are predefined
2018,fyi you can also use codesnippet
2018,where the url has to be the good one though
2018,oh i didnt know about codesnippet is that recent does it just wrap codesnippet
2018,hyperlink
2018,it uses requests it looks like
2020,hi user ive issued some pull requests that will add support for loading particles from hop and fof catalogs made with yt youll need to pull changes from my fork of yt_astro_analysis and my fork of yt but it should all work if youre still interested in this let me know and ill send detailed instructions
2020,yeah im still working on halo merger tree it will be really helpful if you can send detailed instructions and thank you very much
2018,user has joined the channel
2018,hi everyone is there a way to change the default mass definition of rockstar to change the output in the documentation of rockstar hyperlink there is mention of changing the mass definition so as to modify the outputs i am wondering where do i change this mass_definition as i am interested in the radius at 500c thanks in advance
2019,user has joined the channel
2019,does anyone have any experience using the hop catalogs in ramses
2019,im trying to use them to locate galaxies in the simulation but for some reason its not correctly locating them
2019,user i think user might have
2019,user has joined the channel
2019,is there an easy way to create a derived field out of the curl of an existing vector field ie the current density from magnetic field
2019,wait i see that the gradients of the magnetic field are already available to compute the curl
2019,im surprised the curl itself isnt available
2018,user has joined the channel
2020,user has joined the channel
2020,just a quick note to say that ytree either stable or dev version cannot be imported when using the yt40 dev version i followed all conda python3 install instructions at hyperlink importing ytree results in modulenotfounderror no module named ytexternsix this is not urgent for me because ytree works perfectly in python2 with yt341 but if anyone has an easyobvious solution please let me know user
2020,ytree could probably either bundle its own copy of six or depend on six eg by adding it to codesnippet in codesnippets codesnippet
2020,you should probably file an issue about this on github
2020,or fix it like i suggested and make a pr slightly_smiling_face
2020,thanks user
2020,does anyone know an easy way to scale a volume rendering
2020,say if one of the directions is much longer than the others
2020,i think you might need to hack the camera andor lens
2020,i was afraid of that
2020,i think you can do this by setting codesnippet in the implementation of codesnippet for a new lens
2020,i think thats the start position of the rays
2020,i see ill play around with that thanks
2020,user has joined the channel
2020,hi im gen chiaki a postdoc in georgia techi removed the codesnippet directory by mistake and try to install codesnippet again through the install scripti could install all files but when i type codesnippet it fails with a messagecodesnippet file homegenchiakiytcondalibpython37sitepackagesmpmathlibmplibelefunpy line 76 in ltmodulegt cache_prec_steps min2klog_taylor_prec20 2k1memoryerrorcodesnippeti used codesnippet and codesnippet my os is codesnippet im afraid some conflict with the latest version occursthank you
2020,looks like youre running out of ram
2020,thank you for prompt response yes the memory usage becomes almost 100 but my machine has 64 gb
2020,thats very strange importing yt shouldnt use that much ram
2020,yt 340 is very old for what its worth
2020,although your traceback is from mpmath which is a dependency of sympy does importing just sympy run out of ram
2020,i guess someone on stackoverflow had the exact same issue hyperlink
2020,i doubt this is a yt issue per se
2020,ah yeah this is hyperlink
2020,user looks like you just hapenned to install yt at a time when there was a bug affecting not just you but lots of condaforge users ive filed some issues and pinged one of the condaforge maintainers hopefully thisll get fixed soon
2020,oh thank you so much i should be a lucky guy
2020,for now you can probably install mpmath with pip instead of conda
2020,just a guess on my phone
2020,maybe install mpmath from the default conda channel
2020,good luck sorry for the brokenness
2020,thanks ill try to install mpmath with pip for now
2020,thanks for your answer unfortunatly neither of these works maybe its a frontendlevel issue im using the amrvac one
2020,user i suspect there may be a conditional that should be fixed in the gradient field code that assumes 3d
2020,but not for any particularly substantive reason
2020,i just checked codesnippet cant find such a conditional upon quick reading im now trying to get a better grasp of it
2020,ah well theres may indeed be something fishy hereim seeing that eg at this line hyperlinkim getting codesnippet such that codesnippet which looks odd for 2d data
2020,after toying with the equivalent problem for 3d dataset comparing amrvac data vs fake ds it seems pretty clear this is a frontend problem actually switching this conversation to github
2020,user i also would be very interested in using gradient fields for 2d data sets see the chain of messages here from middecember if you find a workaround id be ecstatic to hear it
2020,user user i found the issue it was my mistake apparently codesnippet in my code is _not_ computed using centered differences it is actually a state variable that is solved for explicitly in the code there is a separate variable codesnippet that is computed directly from the velocity fields just as done as with yt and they came out to be identical except for the boundary conditions but that is something i can handle thank you for the inputs slightly_smiling_face
2019,howdy folks im looking to do a 3d linear interpolation of the gas potential in my data onto the lagrangian particle positions so i can calculate the pe of the gas on the stars i see there is an arbitrary grid object that might save me from looping over npinterp is this the correct place in the code to be looking to do this
2019,i see this object is really made to be used in the reverse sense of what i want to do but im curious about this voxelize the grid statement in docanalyzingobjectshtmlarbitrarygrid
2019,my fallback plan is to use dspoint to get the cell the particle is in then index all the neighbors manually to get the data then do 3 1d linear interpolations and average them
2019,careful neighbors might be on different amr level assuming youre dealing with an amr code
2019,we dont expose the precise functionality youre looking for i dont think
2019,if youre fine with using interpolated data for neighbors on different amr levels one way to do this would be to create a covering_grid or arbitrary_grid centered on the location of the particle that is 3x3x3 zones at the amr level of the cell the particle is in
2019,this will probably not be terribly efficient because youd have to loop over particles
2019,if you dont care about the linear interpolation you could use codesnippet to do this in a somewhat more efficient manner
2019,that just returns the value of the cell that the particle is in
2019,maybe ill start there and expand if needed but yes i was just looking at creating a covering grid then passing that to scipyinterpolateregulargridinterpolator to get at it
2019,yup we make the assumption that data are piecewise constant in a zone
2019,ah yeah if you can just make a single big covering grid that would also work
2019,or smoothed_covering_grid
2019,which will do cascading linear interpolation in regions where data are at a lower resolution than the grid
2019,hrrrm sounds like possibly a chance to contribute some useful code to the project only question is do i do the simple thing for now thesis defense is looming in the next few months so simple is rather appealing at the moment
2019,heh yes good luck btw
2019,i think we have all the machinery necessary to get what you want in a nice way its just a matter of wiring it up and giving it a user interface
2019,sorry to not have an easy oh yeah you just do this answer
2019,oh no its okay i was anticipating doing some wiring although you made me ask an important question which is whether the piecewise constant method of dsget_field_at_point is good enough for my purposes you might have saved me some time anyway
2019,user has joined the channel
2018,im having trouble getting codesnippet to work im in a notebook and im just doing codesnippet works and shows up fine and then codesnippet to which i get this same thing if i do say codesnippet etc
2018,update it works in python3 but not 27
2018,can you file an issue pls
2018,fyi it works for me both on python3 and 27
2018,not with the same dataset though
2018,with steps to reproduce evidently
2018,is there a way with the dusk colormap to set a codesnippet
2018,can you elaborate a bit more what youre trying to do
2018,is the bad value inside or outside the colorbar range
2018,i have a plot with some points filled with nans
2018,ah ok
2018,does codesnippet work
2018,and id like it to be filled with the first value of the cmap
2018,yes but how do i get the color
2018,i think it chooses that color by default
2018,hyperlink
2018,oh thats right
2018,hello folks quick q im trying to get an annotated contour all one color white with labels heres the test data my initial mc im trying to plot hyperlink and heres the code i used hyperlink im always getting the plot colormap stuck into the contour annotation colors disappointed
2018,i want some cool contours of the ionization fraction overlaid with the mag field and density or temperature as i may sorry that flash plt_file is kinda large but its what i have laying around that i was working on this morning
2018,am i doing this wrong or did i find a new feature
2018,slightly_smiling_face
2018,tries to reproduce
2018,user you want codesnippet
2018,you have codesnippet
2018,aha
2018,thanks slightly_smiling_face
2018,thinks matplotlib should emit a warning there but what does he know
2018,is this code snippet going to produce a model with two surfaces when uploaded to sketchfab the embed on the website seems to be broken
2018,
2018,what url is that
2018,i see the sketchfab widget at hyperlink
2018,oh the url is hyperlink
2018,ah https
2018,i bet itll work with http
2018,its probably mixed content errors
2018,do you see the first widget above that one
2018,yes
2018,yeah i have a fix
2018,for not just use hyperlink and youll see the widget
2018,were linking to the second widget with an http url which web browsers these days object to from an https page
2018,thats probably a minor issue but the sketchfab result seems a little bit weird i though that sample code was supposed to give a model of two surfaces with different transparency
2018,i tried the code and it gives the same result as the widget on the website as it should
2018,it does but one model is inside the other
2018,since the transparencies are different shouldnt we still be able to see two surfaces
2018,i guess not
2018,i dont know offhand why thats not working
2018,it looks like the transparency is being written to the mtl file
2018,perhaps sketchfab doesnt support that
2018,isnt sure
2018,i tried setting different colormaps for each of the surfaces yet after uploading the model it still looks just white
2018,the sketchfab website says it supports mtl file
2018,its also possible were not writing the data to the mtl file correctly
2018,im just speculating
2018,sorry i cant be more helpful
2018,but when uploading it did tell me that theres something wrong with the mtl file
2018,tries to run that example
2018,hmm meshlab doesnt seem to do anything with the transparency either
2018,the colors work fine though
2018,
2018,i think thats a known thing with meshlab
2018,user do you remember how you got transparencies
2018,did you have to use blender
2018,user has joined the channel
2018,the example code does not give any kwarg about colormap so the color of the surface it set by default
2018,it looks like codesnippet has a codesnippet keyword argument
2018,yes but the example did not specify a colormap
2018,thats true i guess it picks a default one if one isnt specified
2018,yup hyperlink
2018,looks like the model should at least look purplejoy
2018,one thing that might be worth trying to is encode the transparency as an alpha value in the material specification
2018,and not using the d parameter as were doing now
2018,the transparency is getting written to the file and according to the mtl file spec it should be working
2018,but it appears both meshlab and sketchfab ignore it as were writing it now
2018,im not sure why
2018,ah got it
2018,in sketchfab go to 3d settings and under opacity set it to dithered and then choose a value close to 50 on the slider bar
2018,hyperlink
2018,ah cutei guess we could also set the color in the 3d settings
2018,ill try play around with it though this is not the optimal solution
2018,we should look at supporting hyperlink it seems to be a better specified format than objmtl
2018,i like it much more
2018,i remember reading through the spec once
2019,hi mihir sorry for the delay getting back to you lots of teaching and events happening right now the vector fields that exist right now are mainly for combining xyz component fields into a 3 n shaped fieldat the moment im not sure how much work it would take add analysis fields with various array shapes but ill look into it in the next few days and get back to you as soon as i can
2019,user has joined the channel
2019,
2019,
2019,
2018,oh sorry about that the scripts are supposed to run first make_the_catalog and then examplepy now that i think about though you probably wont be able to download the data with what i sent you and i wouldnt have you download everything needed to make the load it would be too much trouble with no reason and anyway i think that i wasnt very specific thus far and i should apologize about that so being specific question when i run a command such as this one halocatalogdata_dsds finder_methodrockstar finder_kwargsdm_onlytrue and then applying a filter as this one add_filterquantity_value particle_mass gt 1e12 msun i get 2 outputs a directory named rockstar_halos and dir halo_catalogs hence i can load from these two a rockstar_ds and a catalog_ds should i expect fields like particle_position or particle_velocity to be different between the 2 when refering to the common particles between the two of course
2020,hello i was wondering if it was possibly to make a plot of the amr grid of any region within the simulation im currently using ramses code
2020,something like this
2020,user you should be able to do this with codesnippet or codesnippet on a slice or projection plot
2020,hi user i tried to do this for the following projection plot
2020,proj ytprojectionplotds z gas density center0450478 0523349 0541032 width40 kpc weight_fielddensity
2020,where ds is given byds ytloadoutput_00448info_00448txt extra_particle_fieldsparticle_birth_time d particle_metallicity d
2020,yet i got this response
2020,yt warning 20200411 050351379 supplied id_loc but draw_ids is false not drawing grid ids
2020,when i tried to save the plot
2020,i checked if this was an issue that had cropped up before and located thishyperlinkhowever using projzoom did not change the response and i did not manage to get any annotations regardless of what i tried also the person who sent in the issue in the link above was using flash data whereas i am using ramses and i didnt really understand why using zoom would change anything about whether or not it annotated grids
2020,any ideas
2019,im not able to install codesnippet on my mac from source it appears to run into an error of not finding a file called ios if i codesnippet instead it installs fine i dont think its a codesnippet bug otherwise the same process wouldnt be able to install codesnippet right has anyone else ran into thiscodesnippetinstalling collected packages yt found existing installation yt 40dev0 uninstalling yt40dev0 successfully uninstalled yt40dev0 running setuppy develop for yt complete output from command usersclaytonstrawnanaconda2envsmyenvbinpython c import setuptools tokenize__file__usersclaytonstrawnytsetuppyfgetattrtokenize open open__file__codefreadreplacern nfcloseexeccompilecode __file__ exec develop nodeps unable to compile openmp test program so cython extensions will be compiled without parallel support usersclaytonstrawnanaconda2envsmyenvlibpython27distutilsextensionpy133 userwarning unknown extension options extra_compile_arg warningswarnmsg writing ytegginfopkginfo writing toplevel names to ytegginfotop_leveltxt writing dependency_links to ytegginfodependency_linkstxt writing entry points to ytegginfoentry_pointstxt reading manifest file ytegginfosourcestxt reading manifest template hyperlink warning no previouslyincluded files found matching scriptspr_backportpy warning no files found matching svgz under directory doc warning no files found matching pdf under directory doc no previouslyincluded directories found matching docsourcereferenceapigenerated no previouslyincluded directories found matching docbuild writing manifest file ytegginfosourcestxt running build_ext building ytgeometryparticle_oct_container extension gcc fnostrictaliasing iusersclaytonstrawnanaconda2envsmyenvinclude arch x86_64 dndebug g fwrapv o3 wall wstrictprototypes iytutilitieslib iytutilitieslibewahboolarray iusersclaytonstrawnanaconda2envsmyenvincludepython27 iusersclaytonstrawnanaconda2envsmyenvlibpython27sitepackagesnumpycoreinclude c ytgeometryparticle_oct_containercpp o buildtempmacosx106x86_6427ytgeometryparticle_oct_containero warning include path for stdlibc headers not found pass stdliblibc on the command line to use the libc standard library instead wstdlibcxxnotfound in file included from ytgeometryparticle_oct_containercpp632 in file included from usersclaytonstrawnanaconda2envsmyenvlibpython27sitepackagesnumpycoreincludenumpyarrayobjecth4 in file included from usersclaytonstrawnanaconda2envsmyenvlibpython27sitepackagesnumpycoreincludenumpyndarrayobjecth12 in file included from usersclaytonstrawnanaconda2envsmyenvlibpython27sitepackagesnumpycoreincludenumpyndarraytypesh1822 usersclaytonstrawnanaconda2envsmyenvlibpython27sitepackagesnumpycoreincludenumpynpy_1_7_deprecated_apih172 warning using deprecated numpy api disable it with define npy_no_deprecated_api npy_1_7_api_version wwarnings warning using deprecated numpy api disable it with ytgeometryparticle_oct_containercpp64010 fatal error ios file not found include ios 2 warnings and 1 error generated error command gcc failed with exit status 1 rolling back uninstall of ytcommand usersclaytonstrawnanaconda2envsmyenvbinpython c import setuptools tokenize__file__usersclaytonstrawnytsetuppyfgetattrtokenize open open__file__codefreadreplacern nfcloseexeccompilecode __file__ exec develop nodeps failed with error code 1 in usersclaytonstrawnytcodesnippet
2019,i dont have a solution and i dont have a mac i could even test on i just have suggestions this is a file generated by cython is it possible this is a cython bug and if you update cython youll get a fixed version
2019,codesnippet is a c standard library header it ought to be enclosed with codesnippet not codesnippet i also see this is being built with codesnippet not codesnippet which seems odd for a c file but that appears to be just what cython does
2019,you might be able to follow the instruction in that warning message codesnippet by stuffing that flag into the environment variable codesnippet
2019,shrug maybe something here will help while we wait for the people who actually know yt to wake up
2019,user hyperlink
2019,hi can yt load plot3d format
2019,also is it possible to use yt to extract data along a contoured 3d boundary and plot the extracted data in an xy plot
2019,no yt doesnt yet have a loader for plot3d and no thats not possible although we do have a way of getting field data at the vertices of the countoured data
2019,this one hyperlink
2019,yup this one
2019,ok well the only way to get it in python is i guess to write my own loader then how much work would this be
2019,what sort of data is it
2019,like grids particles
2019,amr
2019,block structured ijk data no amr
2019,if you can keep it in memory you can load it using ytload_uniform_grid
2019,once you have that working you could add a frontend we have docs on that here hyperlink
2019,its not trivial but its not a crazy amount of work especially for a unigrid data format
2019,depends on how comfortable you are with python
2019,if you are interested were happy to work with you eg in the cbe6579czdevelopment channel here or via email on our mailing list
2019,hyperlink
2019,well i will have to say that my priority is to postprocess the data that i have and not to develop a frontend for yt not sure if i am understanding your offer correctly meaning that as soon as i have the data in python i would move on to postprocess it and get the meat out of it
2019,yes lots of doc around i have not read yet
2019,ok
2019,you said you were interested in writing a reader but its ok if youre not interested in contributing
2019,once you can represent your data as 3d numpy arrays you should be able to load it into yt using load_uniform_grid
2019,good luck
2019,you said we do have a way of getting field data at the vertices of the countoured data just making sure that i will have a way to actually do the postprocessing that i want once i have it in pythonyt
2019,thats right take a look at this hyperlink
2019,you can get eg surfacesome_field after creating the isosurface
2019,that will return the field values at each triangle
2019,there should also be surfacevertices if im remembering correctly which will store the coordinates of all the vertices
2019,ok great thank you
2018,user has joined the channel
2020,this is maybe a bit basic but how do you specify the field type when creating a profile for instance i was trying to make a profile of the gas cylindrical_velocity_theta against radius and initially tried doing thiscodeblockbut it came up with the errorcodeblockand then when i tried to specifycodeblock
2020,or
2020,codeblockit came up with the same error as before where it couldnt find all gas cylindrical_velocity_theta in the info file
2020,and also later it couldnt find the cell mass either
2020,make a list of tuples
2020,this seems like a bug though
2020,if you open an issue on github with a script someone can run to reproduce this issue that will help
2020,if i had to guess codesnippet would work
2020,assuming that field exists
2020,not being able to find the cell mass later also sounds like a different bug
2020,i dont think cylindrical_velocity_theta exists
2020,weirdly this worked out when just wrote outcodeblock
2020,ie just not specifying what each argument was
2020,interesting glad you found a workaround
2020,i have a pretty basic coding question as well trying to add a field vcirc sqrtgmr however i need to include something that tells it not to worry when r 0 but the following attempt isnt working didnt expect it to but this was my attempt anyway
2020,sorry about using a screenshot
2020,maybe you want npwhere
2020,if you havent looked at hyperlink that might also be worth doing
2020,ok checking it out
2020,i often do something like wh radius 0nwh radius 0my_arraywh some_function_ofradiuswhmy_arraynwh some_default_value
2020,where my_array and radius have the same shape
2020,oh also in your field definition
2020,its not the mass enclosed
2020,its the local mass at that position
2020,oh true thank you
2020,its unfortunately not straightforward in yt to make a field that depends on the enclosed mass
2020,you need to do that outside the field system
2020,how do you mean
2020,like on a 3d ndarray centered on your halo
2020,or whatever object youre looking at
2020,i guess if you have an outside estimate of the radial density profile you could use that to estimate the enclosed mass for a field definition
2020,never tried that though
2020,it would need to be a perhalo thing though
2020,alas
2020,this sounds really hard
2020,like you would need to make sure youre only considering amr zones that are associated with whatever halo or object or whatever youre calculating the circular velocity for
2020,yeah
2020,yeah so youd need to identify all the halos or objects you want to consider
2020,for each one calculate the enclosed mass at a given radius
2020,and then use that for your field definition
2020,using a 1d table
2020,and interpolating between values
2020,if you only have one object its often easier to reason about things if you dont work with the native amr data and instead work with an interpolated uniform resolution grid
2020,thats what i did for my thesis
2020,anyway good luck have a nice weekend
2020,thank you
2020,you too
2019,quick question ive been wondering for a while now does yt have a functionality for converting amr data to a good ol regularspaced numpy array be it at the coarsest or the finest amr level be it incredibly slow or inefficient
2019,hi user i would start herehyperlinkalso have a look at covering_grids and abritrary_grids should be on the same page if thats not what you meant please let me know
2019,thanks for your answer it _looks_ like what i am looking for although im having problems checking for it as yt seems undecided
2019,
2019,it looks like a severe bug affecting non 3d datasets but as im working with an experimental and yet unmerged frontend it might be specific to it user any clue
2019,taking a look at the source its not as much of a bug as a missing feature its never been implemented for datasets with lower dimensionality codesnippetif lenitem selfdsdimensionality not the right specification and we dont want to do anything implicitly note that this happens after the implicit expansion of a single slice raise ytdimensionalityerrorlenitem selfdsdimensionalityif selfdsdimensionality 3 well pass on this for the time being raise ytdimensionalityerrorselfdsdimensionality 3codesnippet
2019,try creating an codesnippet directly im pretty sure that works for 2d data
2019,thank you user i can confirm this actually works
2019,codesnippetobj dsarbitrary_griddsdomain_left_edge dsdomain_right_edge dims128 128 1d objrhosqueezeto_ndarraycodesnippetdid the trick although it raises the question as to why we are dealing with 3d edges array while the dataset is actually 2d i remember forcing this in the frontend but i dont know why that felt necessary
2019,because logically all data are 3d from yts perspective
2019,alright thanks
2020,user has joined the channel
2020,hi could i have a question about this code i got an error on the line before the last line runtimeerror i do not know what it means thank youcodesnippetcodesnippetcodesnippetcodesnippetcodesnippetcodesnippetcodesnippetcodesnippetfrom yt import ytarray arrays in yt modulefrom ytvisualizationapi import streamlines force linesimport matplotlibpylab as pl constantsq 16e19 electron chargem 91e31 electron massv_par 2000 parallel volocity v_per 2000 perpendicular velocityx0npzeros6 vector 6 dim give zeros into it 3 components positions 3 components velocity cartesian coordinatesxmin 2xmax 2ymin 2ymax 2zmin 3zmax 5sampling 10x_ nplinspacexmin xmax samplingy_ nplinspaceymin ymax samplingz_ nplinspacezmin zmax samplingx y z npmeshgridx_ y_ z_ indexingxyrnpsqrtx2y2thetanparctan2yx je treba overit je skutecne poradi yx byva ale obcas je to obraceneb_rnpzeros_likexb_thetanpzeros_likexb_znpzeros_likexwnpwherezlt0b_zwrwb_rw0wnpwherezgtmathpib_zw05rwb_rw0wnpwhere zgt0 amp zltmathpib_zw 025rwnpcoszw 075rwb_rw 0253rw2npsinzw transformation of magnetic field from cylindrical coordinates into cartesian coordinatesbx b_r npcosthetaby b_r npsinthetabz b_z choose point in field where force line will be integratedx_point 0025y_point 0z_point 0 dictionary of numpy arrays magnetic field datadata dictb1bx b2by b3bz bx datab1by datab2bz datab3 3d array bbox nparray22 22 35 borderds ytload_uniform_griddata b_rshape length_unitmpc bboxbbox nprocs100 data dimenze define c the center of the box chosen pointc dsarrx_point y_point z_point code_length c1 dsdomain_center n is number of streamlinesn 1 scale is the spatial scale of the streamlines relative to the boxsizescale dsdomain_width0 pos c create streamlines and integrationstreamlines streamlinesds pos b1 b2 b3 lengthnone this line gives errorstreamlinesintegrate_through_volume
2020,hi user could you paste the full error also you can format nicely code using triple back ticks on slack 3 times before and after the code you want formatted
2020,however when copypasting your code it seems to work perfectly fine if you remove the codesnippet from your codesnippet call this would definitely be a bug if you confirm this solves your issue could you fill an issue on the projects github
2020,thank you so much it solved my issue you mean i should add this question to github hyperlink
2020,yes that would be great
2020,you can fill in the template that will show up to report the bug so that it can be fixed in the future
2020,ok many thanks again
2018,hi ive been searching the yt documentation to see if you can extract field values over a 2d surface eg at a certain radius without it being an isocontour but i cant find anything am i missing something
2018,hi how is your 2d surface defined if it is a simple geometrical object cube sphere disk you can probably use a geometrical selection hyperlink
2018,if the region is more complicated to define you can use a cut region hyperlink where the cut would only leave cells within your region of interest
2018,both will return a data container lets call it codesnippet that you can use like a dictionary codesnippet
2018,thank you for your help as far as i can tell that first option lets you define a sphere but then you can only view data as slices through it not as eg interpolated values on the 2d surface of the sphere flux through this surface etc
2018,the only way i can think of doing it would be to output radius as a field and then use that to define an isosurface
2018,but it would be a lot more convenient if i could do it using my existing data
2018,yes thats how you can do it right now
2018,generate a marching cubes isocontour on the radius field
2018,for a long time ive wanted to add the ability to generate interpolated 2d data like that on the surface of various geometric objects cylinders and spheres mostly
2018,there are some tricks we can use to speed that up substantially over the marching cubes based approach
2018,but that doesnt exist yet
2018,ok great thanks for getting back to me
2020,is there a way to locate a fields extrema in a region object codesnippet doesnt take a data_source argument while data containers dont have a codesnippet method
2020,theres the extrema derived quantity that you can use codesnippet
2020,or even simpler codesnippet codesnippet
2020,i have the coordinates of the centers of galaxies stored in arrays x y z when i used them to define a sphere such as sp dsspherex0 y0 z0 50 kpc i can successfully call max_tempspsumtemperature however when i try to call max_emissivity spsumluminosity_field a derived field that i created i get the error valueerror operands could not be broadcast together with shapes 6713 0 with 6713 being the length of the arrays x y z however when i define sphere with hard coded values such as sp dssphere05 05 05 50 kpc i can successfully call its luminosity using the field i derived any ideas on why this might be happening thanks
2019,user has joined the channel
2020,user has joined the channel
2020,hi everyone im currently trying to track a position within my simulation based on a set of criteria naturally this can be done using the npwhere function but i was wondering if there was an equivalent within yt such that i dont have to read in the whole dataset
2020,not that im aware of if you feel like your position could drift into the entirety of the simulation volume what is the nature of your tracking criteria
2020,im essentially looking for the minimum value of a ratio between xy magnetic field vector and z field vector essentially looking for where the magnetic field is the most into the plane as possible and then tracking that in time currently i have it implemented ascodesnippet codesnippet codesnippet codesnippet codesnippet codesnippet
2020,in its current implementation its hardly a slow computation but i just wondered if there was a more elegant way of doing it
2020,hi jack you could try something likecodeblock
2020,beautiful just beautiful thank you so much d
2020,you bet
2020,okay now assuming that i would like to do the same but for a subset of the data is there an equivalent for adcut_region i noticed that dssphere doesnt contain a find_min function
2020,yeah you can docodeblockthe return value is similar to codesnippet but returns a list of 4 items youll have to make items 24 into an array yourself have a look at codesnippet to see all the ones that are therealso just in case youre interested all of these as well as things like codesnippet are parallel safe so you can run that code in parallel and under the hood the work will be divided up
2019,quick question about the units of parttype0_smoothed_temperature with ytprojectionplot how come my temperature units for the colorbar are k cm and how do i just do kelvin the colorbar values are on the order of 1029 kcm which makes no sense to me this is for plotting cosmological simulation data from gizmo the fire simulations
2019,youre doing an unweighted projection
2019,so youre looking at the column temperature
2019,eg the line inegral of the temperature field along one of the axes of your simulation
2019,if you want something with units of temperature at the end specify a weight field
2019,eg mass
2019,you can also specify ones as the weight field if you really do want an unweighted projection
2019,perfect user thanks that workedone more quick question is there a reason why doing a projectionplot of depositparttype0_smoothed_temperature takes so much longer than eg depositparttype0_ciccurrently im reading in the whole particle dataset gizmo hdf5 file for a single snapshot and not filtering the yt dataset object to eg only keep particles within 3rvir of the halo im interested in do you think doing this would help and is there an option in ytload that can easily accomplish this eg maybe bounding_box
2019,the latter is doing an sph projection
2019,err the former
2019,esp in yt 3x that is very very slow
2019,esp for large datasets
2019,you probably want to be running on the yt40 branch things will be much faster there
2019,see eg hyperlink for details
2020,user has joined the channel
2020,hello yti am a developer of warpx a 3d particleincell code for laserplasma interaction relying on amrex for mesh refinement for output files we are using the amrex plotfiles that yt can read and give great rendering thank you i am currently working on a volume rendering of a 3d simulation with yt see image and i observe a behavior that i cannot explain the image uses a number of derived fields one for a laser pulse red one for plasma fields blueyellow and one for an external lens green and the image below looks correct
2020,wow cool looking
2020,heres the same script used some iterations later the green blob should be in the gap roughly in the middle of the image but it is not and i do not understand whynote 1 when i tried to change the order of the fields i think the last derived field for which i call codesnippet is only shown on the right of the box and disappears on the left partnote 2 i am using parallel rendering with mpi and openmp parallelizationnote 3 when plotting with lower resolution i did not observe the same behaviorhas anyone observed this type of issuesthanks
2020,so each derived field is its own source
2020,sounds like a bug to me but its going to be hard to track down without a reproducible example
2020,yes the script looks likecodesnippetsc ytcreate_sceneds fieldwake lens_typeperspectivesource_laser ytvisualizationvolume_renderingapivolumesourceds fieldlaserscadd_sourcesource_laser etc for other sourcescodesnippet
2020,if you do the green source on its own does it show up
2020,maybe its there but it has very different opacity from the other fields
2020,thanks useri can share the script and some data but the rendering takes a lot of time right now i am trying to do serial rendering to see if the bug disappears
2020,yeah it would also help to have a reproduction script that doesnt need a lot of computation time
2020,i have not tried the green source on its ownand the field disappears very quickly does not really look like opacity also it is present in all iterations when rendering with low resolution 512 512
2020,ill try and prepare something
2020,ok sorry to not be immediately helpful
2020,its just that a lot of things could be breaking and its hard to tell which just by your example
2020,no problem thanks for your help in a few minutes ill be able to tell if serial rendering gives the right result at least
2020,turning off openmp threading and mpi parallelization for each iteration still using codesnippet give the right resulti can do some more tests but this serial rendering too 130 h confused
2020,well that at least narrows down where the bug might be
2020,wonders if the openmp code cython generates is triggering ub
2020,iirc cython is perfectly happy to generate incorrect openmp code in some circumstances
2020,eg hyperlink
2020,thats just a guess though
2020,ok i can try pure mpi or pure openmp rendering that should at least tell us if its openmp threading
2020,user update pure openmp threading in this case codesnippet made the rendering 3x faster and gave the correct result
2020,heh so i guess its mpi
2020,i wonder what mpi parallelism over a single dataset is even doing in your example
2020,i am using it pretty much as a black box i have to admit
2020,if ive got a gizmodataset and i want to load multiple fields of the same particle type from the same region it seems like there should be a way to have yt only do the whole selector walk once is there the naive thing which doesnt work iscodeblock
2020,playing with codesnippet always gives the right answer so yeah it seems to be mpi
2020,user each twoelement tuple is a single field what you passed isnt a valid field name tuple
2020,instead pass a list of two twoelement tuples
2020,i think thatll only do the selection once
2020,user has joined the channel
2020,user do you mean like thiscodeblockthis doesnt work either as a tuple of two 2tuples or as a list of two 2tuples
2020,huh it should
2020,youre on yt40 right
2020,yes
2020,and sorry what does doesnt work mean exactly in this context
2020,codesnippetin 5 regparttype0 masses parttype0 neutralhydrogenfractiontypeerror traceback most recent call lastpython38libpython38sitepackagesytmodspy in ltmodulegtgt 1 regparttype0 masses parttype0 neutralhydrogenfractionpython38libpython38sitepackagesytdata_objectsdata_containerspy in __getitem__self key 249 f key 250 elsegt 251 f self_determine_fieldskey0 252 if f not in selffield_data and key not in selffield_data 253 if f in self_container_fieldspython38libpython38sitepackagesytdata_objectsdata_containerspy in _determine_fieldsself fields 1189 else 1190 fname fieldgt 1191 finfo selfds_get_field_infounknown fname 1192 if finfosampling_type particle 1193 ftype self_current_particle_typepython38libpython38sitepackagesytdata_objectsstatic_outputpy in _get_field_infoself ftype fname 788 if field not in selffield_infofield_aliasesvalues 789 return self_last_finfogt 790 if field in selffield_info 791 self_last_freq field 792 self_last_finfo selffield_infoftype fnamepython38libpython38sitepackagesytfieldsfield_info_containerpy in __contains__self key 330 331 def __contains__self keygt 332 if dict__contains__self key return true 333 if selffallback is none return false 334 return key in selffallbacktypeerror unhashable type listcodesnippet
2020,oh oh wait you want to batch the field accesses
2020,i see
2020,and the problem is that doing the two fields separately are spending a lot of time not doing io
2020,its actually not io but yeah
2020,how do you know its spending time doing index calculations did you profile
2020,yes
2020,if this is going to turn into we need to patch yt to get this behavior i should be much more systematic about it ive just been looking at what symbols show up in codesnippet
2020,ok sorry just trying to understand exactly what youre doing and what the trouble is
2020,doesnt help that i got some sedation at the doctor earlier
2020,i want to read two or more attributes for a single particle typethe codesnippet calls to a yt region dominate quite a few data analysis scripts i haveif i do this in two codesnippet calls im pretty sure from reading the yt code for this operation that it will look up which particles im trying to pick out twiceit would be pretty cool if i had a way to not have yt do the redundant work of figuring out which particles im trying to read data for
2020,i think you may just be seeing yt doing io twice
2020,doing codesnippet does all the spatial indexing
2020,let me put together a test script so we can be sure were talking about the same thing
2020,it always helps for these discussions to have a test script we can both run
2020,codesnippet is a subregion of the simulation box right not codesnippet
2020,correct it is a subregion
2020,usercodesnippetin 2 time dsindexyt info 20200203 163404784 allocating for 1191e07 particlesinitializing coarse index 100 1919 0001lt0000 994itsinitializing refined index 100 1919 0011lt0000 171itscpu times user 152 s sys 209 ms total 154 swall time 155 sout2 ltytfrontendssphdata_structuressphparticleindex at 0x7f6d724c2128gtin 3 time dsfind_maxgas densityyt info 20200203 163437845 max value is 415344e21 at 319956347656250000000 314736640625000000000 289698867187500000000cpu times user 378 ms sys 841 ms total 462 mswall time 459 msout3unyt_quantity415344071e21 gcm3 unyt_array3199563476562 tel314736640625314736640625 2896988671875 code_lengthin 4 v c dsfind_maxgas densityyt info 20200203 163451248 max value is 415344e21 at 319956347656250000000 314736640625000000000 289698867187500000000in 5 reg dsboxc10kpc c10kpcin 6 time regparttype0 massescpu times user 347 ms sys 679 ms total 415 mswall time 411 msout6unyt_array000036683 000047384 000034478 000031614 000034297 000032042 code_massin 7 time regparttype0 densitycpu times user 340 ms sys 399 ms total 380 mswall time 378 mscodesnippeti loaded the data like thiscodesnippetimport ytfrom ytunits import kpcfname gadgetdiskgalaxysnapshot_200hdf5unit_base unitlength_in_cm 308568e21 unitmass_in_g 1989e43 unitvelocity_in_cm_per_s 100000bbox_lim 1e5 kpcbbox bbox_limbbox_lim bbox_limbbox_lim bbox_limbbox_limds ytloadfnameunit_baseunit_basebounding_boxbboxcodesnippet
2020,when i profile accessing a field in a region all the time is spent in io routines
2020,codesnippet 17023 function calls 16785 primitive calls in 0380 seconds ordered by internal time ncalls tottime percall cumtime percall filenamelinenofunction 1 0083 0083 0204 0204 iopy19_count_particles_chunks 18 0081 0005 0174 0010 iopy99_read_particle_fields 85 0056 0001 0077 0001 datasetpy476__getitem__ 51 0038 0001 0038 0001 method astype of numpyndarray objects 204 0016 0000 0026 0000 grouppy253__getitem__ 34 0015 0000 0070 0002 iopy80_get_smoothing_length 72 0010 0000 0011 0000 filespy150make_fid 72 0010 0000 0013 0000 filespy403close 102 0010 0000 0010 0000 method reduce of numpyufunc objects 119 0007 0000 0008 0000 datasetpy395__init__ 357 0006 0000 0006 0000 datasetpy283shape 72 0005 0000 0005 0000 filespy95make_fapl 34 0003 0000 0005 0000 attrspy56__getitem__ 18 0003 0000 0121 0007 iopy35_read_particle_coordscodesnippet
2020,when you do similar stuff for your workflow do you see differences
2020,how do you know that its not just doing io that takes time when you query those fields
2020,the timings here might depend on the geometry and size of your data of course not saying that what youre seeing is impossible just that i need more info to be able to understand and maybe help
2020,heres a strippeddown example of what im doing which i believe is substantially the same as what youre doing im selecting a generous box around the central galaxy in a zoomcodesnippetimport ytimport caesarobj caesarquick_loadufrcnarayanankimockbfire2h113_hr_sn1dy300ro100ssgroupscaesar_0172_z2000hdf5center objgalaxies0posds ytloadufrcnarayanankimockbfire2h113_hr_sn1dy300ro100sssnapshot_1720hdf5region dsboxcenter dsquan75 kpc center dsquan75 kpcregionparttype0 massesregionparttype0 neutralhydrogenabundancecodesnippet
2020,codesnippet 7551150 function calls 6910456 primitive calls in 27731 seconds ordered by internal time ncalls tottime percall cumtime percall filenamelinenofunction 2882 6290 0002 6925 0002 homekimockbpython38libpython38sitepackagesh5py_hldatasetpy476__getitem__ 2820 1940 0001 1940 0001 method astype of numpyndarray objects 194 1805 0009 6070 0031 homekimockbpython38libpython38sitepackagesytfrontendsgadgetiopy100_read_particle_fields 2 1271 0636 8841 4421 homekimockbpython38libpython38sitepackagesytfrontendssphiopy19_count_particles_chunks 2163 1115 0001 1125 0001 homekimockbpython38libpython38sitepackagesh5py_hlfilespy150make_fid478306129 0938 0000 2447 0019 homekimockbpython38libpython38copypy128deepcopy 1307 0647 0000 0647 0000 builtin method ioopen_code 2158 0545 0000 0623 0000 homekimockbpython38libpython38sitepackagesh5py_hlfilespy403close 6856 0503 0000 0503 0000 builtin method posixstat 7752 0474 0000 0822 0000 homekimockbpython38libpython38sitepackagesh5py_hlgrouppy253__getitem__255158511 0383 0000 1066 0000 homekimockbpython38libpython38sitepackagessympyprintingprinterpy251_print 896 0355 0000 1786 0002 homekimockbpython38libpython38sitepackagesytfrontendsgadgetiopy81_get_smoothing_lengthcodesnippet
2020,yup its spending almost all the time doing io
2020,the codesnippet method for h5pys dataset class
2020,not according to codesnippetcodesnippetreal0m28432suser0m23244ssys0m6028scodesnippet
2020,oh ok so theres more frames to that profile
2020,can you run your script with pyspy pls
2020,and share a flame graph with me
2020,hyperlink
2020,you need to install it with pip
2020,i see they too have mastered the rust manylinux packaging dance
2020,heres an invocation
2020,codeblock
2020,you want codesnippet so itll profile cython code too
2020,pyspy is great if youve never used it best python profiler right now imo
2020,codesnippet pyspy record n o profilesvg python benchpyerror failed to merge native and python frames have 64 native and 32 pythoncodesnippet
2020,fun
2020,i think you might need sudo on a mac if youre on a mac
2020,maybe run it without codesnippet
2020,im not on a mac
2020,seems to work without codesnippet i own the python interpreter but im doing this on an hpc nodenot really keen on moving these massive snaps off the cluster but i could do that
2020,yeah no worries
2020,without codesnippet is fine
2020,
2020,would be even cooler if this didnt profile the imports
2020,yeah ok if you read the profile
2020,first bit is imports
2020,second bit is codesnippet
2020,yup
2020,third and fourth bits are the two io bits which are identical
2020,and are looks to me just basically doing io
2020,this profile looks 100 expected to me
2020,i have a sanity check to do
2020,i guess codesnippet could be amortized over both calls
2020,which i think user has an open pr for
2020,hyperlink
2020,so i guess another option would be to run a patched version of yt with matts pull request applied
2020,it occurs to me another lowerlevel thing you could do would be to call codesnippet directly
2020,something like thiscodeblock
2020,and then the field data will be available in the codesnippet dict
2020,note i havent actually tried this no idea if itll be faster
2020,codesnippetimport ytimport caesarimport h5pyimport timeobj caesarquick_loadufrcnarayanankimockbfire2h113_hr_sn1dy300ro100ssgroupscaesar_0172_z2000hdf5center objgalaxies0posds ytloadufrcnarayanankimockbfire2h113_hr_sn1dy300ro100sssnapshot_1720hdf5region dsboxcenter dsquan75 kpc center dsquan75 kpcstart timetimeregionparttype0 massesregionparttype0 neutralhydrogenabundanceprinttimetime startstart timetimefor i in range4 with h5pyfilefufrcnarayanankimockbfire2h113_hr_sn1dy300ro100sssnapshot_172ihdf5 r as f fparttype0masses fparttype0neutralhydrogenabundanceprinttimetime startcodesnippet
2020,that code at the bottom with h5py is doing _just_ the io
2020,the times for the two sections in seconds arecodesnippet18276262521743774033153271675109863codesnippet
2020,looks like this is a bit fastercodesnippetin 10 time regget_datafieldsparttype0 density parttype0 massescpu times user 313 ms sys 723 ms total 386 mswall time 383 mscodesnippet
2020,this is why im _really_ incredulous when you say thats io
2020,yeah youre hitting the thing matts pr fixes
2020,right now yt does an io pass to figure out how big the arrays we need to load data into should be
2020,so its really doing multiple io passes
2020,also thats not necessarily a completely fair comparison
2020,youd need to compare with codesnippet
2020,since youre using a subregion yt needs to do multiple io operations at disjoint points in each file
2020,not saying that yt will necessarily be as fast as doing the io completely manually with h5py either
2020,matts pr will get things closer though
2020,also you can use codesnippet which answers your initial question about batching io for multiple fields
2020,hope thats all helpful sorry were not quite at the level of performance youre expecting
2020,if youre up for it applying matts pr and giving it a test would be very helpful especially if things are broken if you do please leave a comment with your results
2020,ill check it out later the script that was the cause of this conversation just finished running so its back to dissertation for me
2020,lol
2020,user in return for helping you out earlier pretty please can you share the movie youre making it looks really cool
2020,user sure its 13 mb should i send it to you by email actually user helped me for the yt rendering
2020,you can put it in here if thats ok
2020,email works too though if youd prefer it stay private mailtonathan12343gmailcomnathan12343gmailcom
2018,i know i should know thisbut how do i turn off the color bar in a simple projection plot not the demeshed codesnippet if that makes any difference
2018,p ytprojectionblah codesnippet
2018,thanks
2018,relatedly if i want to change the label axes on a proj plot i can do something like from the email archives in a 2014 email from usercodesnippetimport ytds ytloadfilenameprj ytprojectionplotds 0 densityprjset_colorbar_labeldensity arbitrary labelcodesnippet
2018,will that automagically change the scale too like if i go from gcm2 to msunpc2 or something
2018,it will if you use codesnippet to customize the unit of the colorbar
2018,like codeblock or something
2018,codesnippet
2018,awesome thanks for the correction
2018,i believe this is all covered explicitly in the plotting docs
2018,eg hyperlink
2018,oh thank you i cop to not even having thought to look much appreciated
2018,has anyone had luck in plotting particles from amrexs tutorial cases such as codesnippet i am mostly having difficulties loading the data effectively across the multiple levels
2018,user
2018,first ive heard of this tutorial but i bet andrew can help its pretty late though
2018,this specific tutorial was recently released i would have suggested another tutorial but most of them seem broken sounds good there is always tomorrow thank you
2019,user has joined the channel
2019,hello all im using yt to create sliceplots of boxlibtype data from an amrexbased code and am getting some weird boxes in the slices that look like this ive been using the dsr method to interrogate the fields and thats showing some artificially low values as well however ive talked to others whove said that theyve seen the same thing with yt but not with visit before i try and do a comparison with visit which im not familiar with have any of you come across something like this or have any idea what would cause yt to plot a field with these boxes
2019,user the blank boxes look like spots where yt isnt finding any data there are a couple possible reasons the main one is if your slice maybe is right on a grid edge it can sometime result in that can you shift the slice by 1e9 or so and see if a similar thing happens if so we should try to fix it in the slice selector in yt alternately there might be different issue but if you can clear up the first possibility we can proceed from there
2019,hi how can i set the x and y limits on a sliceplot hyperlink
2019,they are controlled by the codesnippet and codesnippet parameters there are some examples on the page you linked you could either set them when creating the plot as codesnippet or customizing them later as shown here hyperlink
2019,there are several different ways to customize but the most direct ones are codesnippet and codesnippet
2019,thanks
2019,user well ill be moving the center minutely seems to have fixed the white boxes thanks so much this slice is directly through the center of the domain but it almost certainly lines up with the edges of some of the amr grids ill use the offset trick from now on although it sounds like there may be a deeper issue here in how yt does slices in such an instance that might be worth addressing
2019,i agree its definitely something we need to fix and now i think i can get a test case
2020,hi could you please provide a script that produces this error if possible please reduce it to a minimal form
2020,hi ill try to do that but it will take a little bit of time to make it reproducible because the derived field im using calls an f2py function that has to live in another file ill try getting a minimal version
2020,thanks for recommending this i now see that codesnippet is not the problem it probably has something to do with the f2py function im calling in the derived field
2020,its okay if even the minimal script has dependencies slightly_smiling_faceyou could maybe try replacing the f2py function altogether with a pure python function it does not have to reprodruce the exact behaviour of the real one whats important is that it returns results of the types youre expecting from it this is not necessarily applicable here but if it is it could help identifying the source of your problem
2020,also if the problem is still not obvious a good practice is to try and reproduce your error with a fake dataset try codesnippet or codesnippet for instance in order to make sure its easy for others to reproduce it with no access to your data
2020,thanks again for this advice when i replace the f2py function with a much simpler python function but still with the codesnippet call the code worked fine
2020,great then its very likely that the f2py function is at fault i never worked with this package so i wont be of much more help but it seems to me you should inspect the output of this function before the point of your script that raises the error
2020,just a small update without the fixes from the pullrequest i managed to get the mean to within a percent from cosmic mean by taking the smoothing length as codesnippet but decreasing the number of nearest neighbors as much as possible i went down to 4 with only 2 the code slows down too much for both illustris and illustristng i guess this is because these simulations are moving mesh not sph so the density is actually the density of each voronoi cell particle and not one calculated based on a number of nearest neighbors like in the sph case with for example eaglewith eagle things seem to work fine now with the provided smoothing lengths and 58 nearest neighbors although it will take a while to finish the entire box since they dont have a low resolution version
2018,user has joined the channel
2018,hey britton thanks for adding the yt frontend that does make most of my code much faster but unfortunately it bogs down elsewhere now and actually ends up much much slower though its possible thats at least partially due to how im doing the search i think i can solve this via a derived field but im kinda hitting a wall on how to do thatso heres the deal with this new interface its trivial for me to do 90 of what i want to do which is rearrange the data arrays and copy them to new structures however the remaining 10 indexing the progenitors is taking far far longer because theres no progenitor finder in the yt frontend only a descendant pointer so before i was able to do something likecodesnippetfor halt_index node in enumeratesorted_nodes list of nodes sorted by uid ancestors nodeancestors handle ancestors basically loop over the list and assign the most massive as the main progenitor of node and all others as coprogenitors of the next most massive progenitorcodesnippetthat codesnippet operation wasnt cheap but it wasnt too bad once the trees were loaded now however i unfortunately have to do something likecodesnippetfor halt_index uid in enumeratehaltuid ancestors haltdesc_uid uid handle ancestors in a similar way nowcodesnippetsince codesnippet contains all the halos over all the trees this search takes a fair bit of time when its repeated over the entire treei _think_ that i ought to be able to use derived fields to get around this particularly if i can save those derived fields and then have them loaded by yt but im not sure how to access that information in the derived field methodology basically im trying to do something likecodesnippetdef mmp_uidfield data ancestors dataancestors this line doesnt work define the uid of the ancestor via vmax or something like that return ancestorsnpargmaxnvmax for n in ancestorsuidcodesnippetis there a relatively easy way that i can get this or something similar working otherwise it may actually turn out to best for me to continue working with the ytree interface which i do have working at a reasonable clip now
2018,thanks
2018,hi shea unfortunately the last code example wont work as the codesnippet argument coming into the field function isnt the node itself but the dictlike object containing its field you could accomplish that in the following waycodesnippetaadd_analysis_fieldmmp_uidfor node in list_of_nodes nodemmp_uid nodeancestorscodesnippetyou could also similarly create a field that stores the uid of the root node codesnippet which would allow you to select all the nodes from a given tree in yt by the common root_uidhowever it looks like youre setting the progenitor of a given node as the ancestor with the greatest vmax if thats true you could also accomplish this by doingcodesnippeta ytreeloadaset_selectormax_field_value vmaxcodesnippetthen a given nodes progenitor line would becodesnippetnode a0progenitors nodeprogcodesnippettheres more information on that here hyperlinkthat might still be too slow for you since nodeprog will return the full line of most massive progenitors back to the first snapshot and maybe you only want a given nodes immediate progenitor if thats the case i can probably accommodate that with a small amount of developmentof course let me know if ive completely missed the boat on what youre trying to do ill be back in the us next week and we can have a lower latency conversation
2018,user has joined the channel
2019,user has joined the channel
2016,user has joined the channel
2016,hi guys i want to use the sz package in yt to produce some mock images my simulation gas is sph particles i used the load_particles to read in the gas particle information but i am not quite sure if it is ok does this sz package require gas information in field instead of particle
2016,if so how can i load the basic gas particle information and let yt generate these required field information of gas
2020,hi everyone im using codesnippet to compute mergertrees for all halos created by the gadget fof halo finder halo catalogs were created in ytcodesnippetdata_ds ytloadsnapshot_000hc halocatalogdata_dsdata_ds finder_methodfofoutput_dirgroups_000hccreatecodesnippet
2020,but when i make merger tree in the next codecodesnippetimport ytfrom treefarm import treefarmts ytdatasetseriesgroups_0h5my_tree treefarmtsmy_treetrace_descendentsgroupfilenameall_haloscodesnippet
2020,i got this errorcodesnippettypeerror traceback most recent call lastltipythoninput179fa3a89e6df6gt in ltmodulegt 4 ts ytdatasetserieshomegroups_0h5 5 my_tree treefarmtsgt 6 my_treetrace_descendentsgroupfilenameall_halosmyfilelibtreefarmtreefarmtreefarmpy in trace_descendentsself halo_type fields filename 367 368 if ds1 is nonegt 369 ds1 self_load_dsfn1 index_ptypehalo_type 370 ds2 self_load_dsfn2 index_ptypehalo_type 371 myfilelibtreefarmtreefarmtreefarmpy in _load_dsself filename kwargs 186 load a catalog as a yt dataset and call setup function 187 gt 188 ds yt_loadfilename kwargs 189 if selfsetup_function is not none 190 selfsetup_functiondsmyfilelibtreefarmtreefarmutilitiesiopy in yt_loadfilename kwargs 13 if level gt 10 and level lt 40 14 ytloggersetlevel40gt 15 ds _yt_loadfilename kwargs 16 ytloggersetlevellevel 17 return dsanaconda3libpython37sitepackagesytconveniencepy in loadargs kwargs 84 candidates find_lowest_subclassescandidates 85 if lencandidates 1gt 86 return candidates0args kwargs 87 if lencandidates 0 88 if ytcfggetyt enzo_db typeerror __init__ got an unexpected keyword argument index_ptypecodesnippet
2020,its seems like there is no group type in the catalogs does anyone knows whats wrong with this
2019,hi user im happy to help out with this im at a workshop now but ill send you a message when i have time to look at this
2019,hi user is it that youd like to save a 2d array of density vs temperature profile for each halo i dont think thats supported yet but one solution may be to save the profiles with yts codesnippet command and then have the analysis field be the path for that file if its saving the full profile in the tree file youre keen on then we can chat about how to possibly implement that
2019,yes i want to save densityradius and temperatureradius profiles for halos right now i am saving these profiles in a dictionary with treenodes as keys but it would be simpler if they are saved in the same file as the arbori noticed that the derived fields can be added in xyz vector forms similarly if analytic vector fields with predefined size can be implemented that would be great if its not going to be too complicated to do that i am interested in doing that
2020,user has joined the channel
2019,user has joined the channel
2019,can we have 2d plots in volume rendering i want to visualize the several orthogonal crosssections of 3d data
2019,user you have to manually composite it but it has been done i think your best bet wouldbe to save the pngs and then composite in something like graphics magick or with pilpillow
2018,sorry for being persistent here but ive noticed another thing by inspecting only the fields of the rockstar_ds again the halo_catalog object played a role in its creation i find again something that looks like a discrepancy for example the number of subhalos in a spesific halo found by the rockstar is 1785 then if i compare the fields particle_velocity and particle_bulkvel i find something strange that is 1486 items seem to match in these fields while in the rest i find differences v v_bulk even at the order of 10 these differences make it hard for me to rely on the outputs because i dont fully understand them i hope that im not annoying you and that there is a meaning to my questions i you believe that they are not relevant to this thread please tell and i will stop
2018,hi there were glad to help out would you be able to post the script youre using somewhere so i could take a look the easiest would probably be to do codesnippet and then post the link here
2018,user has joined the channel
2018,hi all i recently did a system update on my imac and as a consequence i am now receiving an error when attempting to create a sliceplot of an enzo output ive already completely reinstalled anaconda yt h5py python the works and i have tried multiple versions as well here is the error hyperlink
2018,i am however able to load the same data file on a different computer with the same version and build of anaconda yt and h5py
2018,interesting
2018,the exact same dataset
2018,can you only reproduce it on that one system
2018,it might be an issue with the filesystem on the computer where its crashing
2018,ive never seen something like this error before
2018,interestingly this is in the traceback anaconda3libpython37sitepackagesytfrontendsenzoiopy in _read_obj_fieldself obj field fid_data 159 return datat 160 raisegt 161 dgreadh5pyh5sall h5pyh5sall data 162 i dont know why but on some installations of h5py this works but 163 on others nope doesnt seem to be a version thing
2018,that comment refers to a commented out line below the line thats failing for you
2018,any chance you can share the dataset thats dying for you
2018,also what yt and h5py versions are you using
2018,errno14 happens when you try to fopen a file outside of your usable address space
2018,possibly also it might actually be the dataset itself since the computer on which i thought i had fixed the issue just threw this error im running yt 341 and h5py 280
2018,codesnippet is also pretty suspicious slightly_smiling_face
2018,thats a lot of bytes wink
2018,you can share datasets using the codesnippet command line helper
2018,codesnippet
2018,yes im very confused by the error message the datafiles are not gigantic on the order of a few tens of mb however i am accessing them over via sshfs
2018,thatll print out a url once its finished uploading you can share
2018,its getting pretty late ill poke at this tomorrow if you can share the file
2018,might be an enzo issue especially if you produced this file with a modified version of enzo
2018,might be a yt issue and youve hit some corner case in the enzo io routines
2018,might just be a corrupt file
2018,might be a filesystem issue
2018,hard to say slightly_smiling_face
2018,good night
2018,ah yes 18446744073709551615 is 264 1 slightly_smiling_face
2018,i should try to memorize that one
2018,ok i think i may have discovered the issue i found a previous commit in which things were plotting nicely which existed only on the branch for my laptop go figure so yt does not play well with writeghostzones 1 parameter in enzo which was floating around some of my parameter files pastrebecca likely thought about inspecting the ghost zones and then promptly forgot about it my apologies for spamming the help channel
2018,ah yes in principle that should at least fail with a much less crappy error message though
2018,i think we even have support for that although its definitely not tested so im not surprised its broken
2018,if you can make a bug report about this we can at least make the error message less crappy or maybe even add support for reading in the data
2018,user has joined the channel
2018,when i try to get the divergence of a field in my nonperiodic dataset that i load via load_uniform_grid i get an out of bounds regardless of what sort of region i try and specify is this just because the streamdataset will always have to use the whole gridthere isnt any chunking
2018,example script and error hyperlink hyperlink
2018,just set codesnippet
2018,as a hack
2018,whats happening is that your field is selecting data outside the domain to fill in ghost zones
2018,cool that works
2018,i guess im surprised that was happening even with a smaller region though does it compute the quantity for the whole domain even if im just asking for part
2018,no it should work with a sufficiently small region
2018,it seems like any size of region will break in my script except one that doesnt contain any data
2018,but this doesnt really matter i can just change the periodicity i suppose it doesnt effect anything else
2018,that sounds vaguely like a bug i can try to take a look i guess
2018,oh i think i know whats happening
2018,you only have one grid
2018,so its getting the data for the entire grid
2018,it doesnt matter if you only select a subset of that grid yt still treats it as a single chunk
2018,okay cool thats what i figured
2018,hi i have an enzo data that outputs some extra field f which is supposed to be a kind of density field however yt reads f as a dimensionless field is there a simple way to add unit to my field f thanks
2018,not for the field f itself thats something we want to make easier in yt 40 though
2018,what you can do now is define an alias field that attaches the correct units
2018,for example heres an alias of density that we force to have units of codesnippet even though thats wrong its just for illustration
2018,codesnippetdef my_density_aliasfield data dens datagas density strip units without copying dens densviewnpndarray return datadsarrdens ergdsadd_fieldgas density_alias functionmy_density_alias unitserg sampling_typecellcodesnippet
2018,for your field you could skip the stripping units part since its already getting returned as dimensionless
2018,it works thank you user
2020,in yt4x are there any methods for plotting the voronoi mesh over eg a projection plot of arepo data something likehyperlink
2020,no weve talked about that for slices where it makes more sense i think but i dont think it really makes sense to do that for projections
2020,but we dont do it for slices either
2020,i think john has thought about it a little
2020,oh yeah a slice would make more sense youre right
2020,it works in projections of amr data because theres symmetries along the coordinate axes not so much for voronoi meshes
2019,other quick question is there a way to mute yt avoiding the nonerror messages like codesnippet or codesnippet
2019,you can set that using codesnippet the various amounts of logging can be found here hyperlink
2019,perfect thank you very much
2019,hi all is it possible to use the volume rendering functionality if i interpolated particle data onto a grid and then loaded it into yt or has volume rendering been implemented for particle data yet
2020,user has joined the channel
2020,this message was deleted
2020,user projections and slices are fundamentally different operations so its not inconceivable that they give very different views the projection samples data all along the line of sight so for example youll get a full view of that angled disk the slice is sampling data at a single distance along the line of sight so in the example above much of that disk is in the foreground or background and wont be seen this is also why adding the data_source doesnt change much in the slice example the same grids are being sampled because your sphere intersects the plane of the sliceone thing worth trying is to make slices and projections that are perfectly face on with the disk you can do this by computing the angular momentum vector for the sphere then using that to make offaxis slices and projections have a look here for more infohyperlinkhyperlink
2020,the necessary bits of the codesnippet package were pulled into the yt source at some point from a conda environment you should just be able to docodesnippetconda install numpy cythoncd ytpip install e codesnippet
2020,thanks so much ive done this already but the issue is that particle plots cant be done off axis so im trying to keep it consistent between projections of the amr grid the gas distribution and the stars and this off axis slice thing was becoming issue with the amr grid picture as a projection makes no sense and neither did the slice
2020,is it not possible to turn on minor colorbar ticks for off axis slice plots
2020,doesnt this produce the expected result codesnippet
2020,
2020,noop
2020,ok this is a bug
2020,which version of yt are you running
2020,351
2020,any reason not to upgrade to 36
2020,im running on a shared cluster so i would need to ask the guy who runs it wasnt aware there was an update available as well
2020,will ask him now and let you know tomorrow if this is still a bug
2020,ill check to see if the bug is still there in 36 right now
2020,checked
2020,well in 360 colorbar minorticks are actually _broken_ the class method is here for offaxissliceplot but its actually impossible to have colorbar minorticksthis is a bug i recently fixed on the master branch however not in time for the 360 release
2020,since you dont have the possibility to use the master branch youre in a position where no release has this feature in a stable state sorry about that id recommend updating to 36 nonetheless because a lot of _other_ bugs were fixed in the mean time but its up to you
2020,no problem thank you so much anyway
2020,thanks
2018,
2018,ive reproduced my heisenbug
2018,this throws a notimplementederror on my end can anyone confirm
2018,yup i can hit that too
2018,i bet i know whats happening
2018,thanks for the report ill try to take a look this afternoon
2018,hyperlink
2018,hyperlink
2018,fixed i think
2018,have some more cleanups to do though
2018,thanks again for the report
2018,oo nice
2020,user has joined the channel
2020,if you need to sample the field at the location of many or all particles you can instead use the mesh sampling method see hyperlink that should be available in yt 36
2020,thank you all
2020,user has joined the channel
2020,hey thanks a lot for your response i figured out the sources of the errors codesnippet folder was empty could be a git clone error im not sure why these files were missing but i copied the files from an older version of yt40 from february i had downloaded and it installed properlyare there any concerns about simply copying the build files from an older version 4 months old
2020,well i can think of one itll be virtually impossible to reproduce your environment if you ever need assistance with a bugerror that we cant reproduce straighforwardly seems like a very unlikely situation though that being said the actual codesnippet release is on its way so the days of installing from source will soon be over i would recommend you stay tuned for when that happens slightly_smiling_face
2020,congratz for figuring it out btw
2018,user has joined the channel
2018,user has joined the channel
2019,
2019,codesnippetplot phaseplotds density temperature mass weight_fieldnoneplotset_logdensity trueplotset_logtemperature trueplotsavephasepdf mpl_kwargsbbox_inchestightcodesnippet
2019,this seems like a plain phaseplot almost straight from the example in the docs but somethings going wrong with the colorbar and some other labels on the right any ideas
2019,user ahhh recent matplotlib had a strange change
2019,and user fixed it in a recent yt
2019,ill update thatll probably do it
2019,i get the impression that recent matplotlib had a strange change but user fixed it in a recent yt is a significant fraction of yt development
2019,i like to think folks are also doing some fun things with data handling indexing and whatnot like the sph overhaul but point taken slightly_smiling_face
2019,wow youre not kidding seriously is
2019,sorry did not check in earlierdid you solve your problem sounds like you have a function codesnippet which gives you the intersection point i would just add this function as a new field
2019,user has joined the channel
2020,quick question how does one change the unit displayed for a given fields colormap eg in a sliceplot frm codesnippet to codesnippet for instance
2020,codesnippetp ytsliceplotpset_unitltfieldgt ltunitsgtcodesnippet
2020,i believe
2020,perfect thanks
2019,ive never seen this before you should file an issue
2019,wed need more details about your mac setup probably
2019,eg where did gcc come from xcodehomebrewmacports
2019,also how are you building yt exactly
2019,i found a way to get around this so i closed the issue users solution almost worked though codesnippet only applies for osx not macos so you have to run codesnippet first thanks for your help
2019,im suspicious of the fact that you had to hack around anything here people shouldnt have to do that
2019,unfortunately apple has made development on macs increasingly difficult for several years now
2019,probably this is something that cython upstream needs to handle
2019,we cant do much about it
2019,well beyond dropping c code but thats a big ask ewahboolarray wraps a c library
2019,the whole c stdlib situation on macs is a huge headache
2019,hyperlink
2019,rkingery in that issue is also using anaconda so that might have something to do with it too
2019,i dont use conda on macs partially because of headaches like this
2019,so it might also be an issue that needs to be fixed in conda or some conda package
2019,if someone can reproduce the issue and dive and debug that would be great it looks like plenty of other people are hitting the issue outside of yt
2020,hello again world is it possible to make a profile plot of a subset of dataive been able to make profiles with codesnippet but i get a blank screen and profilex is an empty array if i try using dsdisk
2020,actually i managed to select the subregion i wanted with cut_regions slightly_smiling_face
2020,i cannot recall is there a good way to effectively remove a derived field from a dataset i can remove it from codesnippet and from codesnippet but if i redefine a derived field with the same name and a different definition it just remembers the old one
2020,this is a sort of way of manually overriding a derived field definition in trident we removed the codesnippet keyword when adding new fields because of recursion errors in field definitions that were causing all sorts of problems
2020,i just figured if we manually deleted the references to an existing derived field we could add a new one without problems but im having problems actually achieving this any ideas on how to make this happen
2020,i think codesnippet is the way to do it
2020,if thats not working then its a yt bug
2020,i cannot use codesnippet and was instead trying to figure out if there was a way to just remove references to the existing field
2020,i dont think theres an api to do that
2020,i dont even need an api to do it im just looking to do it
2020,right well the issues youre running into would need to be fixed presumably by adding an api that does what you need it to do
2020,you may be the first person to try to do this
2020,nathan i know what im doing is weird and novel i dont need an api im just asking where fields are formally defined for a dataset and if it is possible for me to go into the code and remove references to that field so that i can achieve my goal here effectively removing a derived field from a dataset
2020,ok well im sorry i dont know offhand
2020,you could look at what codesnippet does i think it is doing most of what you need to do
2020,but if thats buggy it would be nice to get a bug report about it
2020,yeah ive been looking at it a bit ill continue poking
2020,i think you might run into issues later messing with yt internals
2020,eg if we change something in yt in the future that might break trident
2020,it would be less brittle if there were a public tested api that trident could use
2020,its not buggy as far as i know as i said the issue is on the trident side because ion fields are generated dependent on each other and we were running into recursion loops when we allowed codesnippet to work
2020,i think what you need it he contents of the codesnippet dict
2020,but yts field system is very complicated
2020,im not trying to make a hardcoded solution here yet im just looking for a way to remove a derived field from a dataset if i come up with a solution i will consider adding it into the yt api or discussing it here to see if it passes muster just wanted to see if others had ideas of a solution before i deepdive
2020,so just removing an entry from that dict might not be sufficient
2020,right that is what i found was true
2020,removing it from the dict and from codesnippet doesnt seem sufficient there is some memory of the field beyond that
2020,ill see what i can find thanks for the discussion
2020,if you can make a short script that demonstrates the issue i can try poking around
2020,here is a short script demonstrating the issue
2020,hyperlink
2020,ill keep digging to see if i can make headway on this manual override
2020,this is with yt40 right
2020,yup
2020,oh i guess trident isnt even needed for this script
2020,im still compiling but i bet if you did codesnippet youd get the right answer in the second field access
2020,oh i will give it a shot
2020,yeah that does it
2020,the codesnippet caches on data objects are just plain old dicts
2020,it would probably be better if they were keyed on more than the field name eg some sort of hash of the field definition itself too
2020,unfortunately cache invalidation is hard confused
2020,oh interesting so the codesnippet call wipes the cache for an object
2020,thats super helpful
2020,thanks nathan
2020,one wrinkle for you is that trident doesnt necessarily control all of the data objects that a user might create
2020,thats true
2020,i think this will work in a pinch but i dont imagine there is a datasetwide version of that codesnippet command right
2020,its just object by object
2020,because if there were a dataset wide solution it might be worth me making an api for this based on what i wrote in the script for removing a derived field from a dataset
2020,for me to do this not you
2020,no there isnt i dont think there could be either given how its written
2020,theres no way to go from a dataset to all of the data objects that depend on that dataset
2020,ok
2020,thanks for the help nathan
2020,much appreciated
2020,user i synthesized this into hyperlink
2020,thanks user ill comment on it there
2019,user has joined the channel
2019,where are the keyword arguments for ytload documented im loading amrex data and id like to suppress the verbosity with just a simple ytload call i get messages like this codesnippetyt info 20190219 084055701 parameters current_time 125yt info 20190219 084055701 parameters domain_dimensions 50 200 20yt info 20190219 084055702 parameters domain_left_edge 0 0 02yt info 20190219 084055702 parameters domain_right_edge 05 2 0 codesnippet
2019,that doesnt get suppressed via keyword arguments to ytload you can suppress it via the yt config file though
2019,hyperlink
2019,in particular the suppressstreamlogging option
2019,you can also do it inside a script
2019,hyperlink
2019,to answer your specific question load passes keyword arguments to the codesnippet method of the codesnippet subclass that ultimately gets loaded
2019,hyperlink
2019,user has joined the channel
2019,actually this doesnt work i tried it with other frontends maybe theres a typo
2019,i think you need to make an offaxissliceplot to do that at the moment
2019,i didnt actually try it this has come up on the mailing list before many times can you try searching
2019,sliceplot makes a bunch of assumptions about your data and how you want it displayed if you want to make very custom plots then you can always get the image buffer from the plot and then plot that image however you wish
2019,ah the reason it didnt work is because the code was wrong for what you were trying to do you actually want
2019,codesnippetdscoordinatesx_axis2 1dscoordinatesx_axisz 1dscoordinatesy_axis2 0dscoordinatesy_axisz 0codesnippet
2019,slices of 2d simulations are always slice through z so the keys to the dictionary you want to change are the keys for slices through z
2019,i dont actually know for sure if its possible to do what youre trying to do with offaxissliceplot youll need to try
2019,how would i do this getting the image buffer
2019,ill try
2019,plotfrbgas density
2019,or whatever field youre plotting
2019,you can create the fixedresolutionbuffer directly without going through the plot first as well
2019,this is just the api if you already have a plot
2019,sorry i wasnt aware there was an archive for the mailing list will try to search there first from now on
2019,and thanks for the update
2019,hyperlink
2019,err hyperlink
2019,theres one for ytdev as well
2019,nice ill subscribe to some of them then partyparrot
2020,thanks for the headsup with this i thought i had removed all the extern code we dont need it anymore since python2 support has been dropped if youd like to issue a pr to remove the bits that use codesnippet i think its just codesnippet that would be awesome
2020,hi im yajieim trying to plot surface density radial profile i found ytcreate_profile creates a radial profile but not for the surface density and yt projectionplot calculates the surface density but plot in countour is there a way to realise this can i somehow get the integrated density value from projectionplot
2020,not straightforwardly no although its straightforward to calculate from the projectionplot image
2020,codesnippetplot projectionplotimage plotfrbplotted_fieldcodesnippet
2020,frb is a fixedresolutionbuffer object which you can create and customize separately from the projectionplot see the yt docs for details
2020,thats helpful thanks
2020,user dunno if youre still around but whats the output of codesnippet on your machine
2020,hi its long but i send you the output
2020,ivy bridge from 2013
2020,cool thank you slightly_smiling_face
2020,one of the condaforge maintainers was also able to reproduce it hopefully therell be a fix soon
2020,if you happen to have a server with newer cpus available itll probably work there you can also downgrade gmp to 612 with conda and it should work
2020,yes the same version of yt properly works on a newer cluster my machine is bit old
2020,its likely a bug in the c compiler that condaforge uses but also its a bug in gmp for the compiler to produce incorrect code like this fun bug
2020,user has joined the channel
2020,it gets clear how can i downgrade gmp to 612
2020,codesnippet i think
2020,thank you i try this
2020,by downgrading gmp i successfully import yt thank you so much
2019,i know ive done this before but i cant seem to figure it out or find it in the documentation at the moment
2019,does anyone know offhand how to specify the dpi of a plot youre saving
2019,i have a 4000 by 4000 frb id like to get a png with that resolution i guess i need to specify the figure size and the dpi
2019,i think its codesnippet or codesnippet
2019,i think that one gets the frb to be 4000 by 4000 but it looks like the image still gets saved at lower resolution
2019,i think i have to pass the right figure size and dpi to matplotlib
2019,right yes
2019,looks like codesnippet accepts a dict called codesnippet
2019,so i think you could do codesnippet
2019,or whatever the matplotlib kwarg to codesnippet is
2019,thanks user that helps a lot
2019,no prob
2019,yes thats exactly right
2019,we should have a doc page explaining this point because it comes up a lot
2019,its really a matplotlib thing confused
2019,if i want to overwrite an alias field do i simply have to remove it from the codesnippet and codesnippet itself before adding a new one or are there other little corners that its storedcodesnippetfield_infofield_aliasespopftype fieldfield_infopopftype fieldcodesnippet
2019,does force_override not work
2019,codesnippet doesnt seem to have a force_override
2019,hyperlink
2019,sorry a little more context about what youre doing
2019,youre doing this in a frontend
2019,force_override is an argument to add_field
2019,in trident we add new field for different ion species sometimes we add neutral ion species in which case we need to alias codesnippet to codesnippet
2019,but it sounds like youre not writing a derived field
2019,which is all fine and good most of the time
2019,but we allow the user to codesnippet the native fields sometimes eg h i number density
2019,ah ok i guess if the alias already exists calling alias again should replace it
2019,yeah it doesnt seem to
2019,youre probably the first person who has tried
2019,yeah i realize this is a niche corner case
2019,slightly_smiling_face
2019,feel free to send in a pr to patch alias
2019,well thats just it when i patch alias it doesnt seem to fix my problem i guess im patching it wrong
2019,if i had it working id pr it
2019,ah i see
2019,i dont know offhand where else to look
2019,id look at how the field aliases are implemented and poke around in a debugger
2019,well in the codesnippet object are there any other locations where a field or alias field gets stored
2019,besides just codesnippet
2019,you mean a codesnippet
2019,yeah
2019,looks at the code
2019,i only saw it being stored in codesnippet and codesnippet
2019,yes i think thats right
2019,so i figured if i popped those id be golden
2019,ok just making sure i wasnt missing something
2019,can you push what you have somewhere
2019,sure
2019,actually i cant look at this immediately
2019,so that wont actually help
2019,thats ok
2019,this conversation has been helpful that im not just missing something obvious
2019,ill keep poking at it and let you know if i figure it out
2019,and pr it if i do
2019,could it be the other call to codesnippet in add_field
2019,on line 266 of field_info_containerpy
2019,codesnippet if ftype name not in self tuple_name ftype name selftuple_name derivedfieldtuple_name sampling_type function kwargs selfaliasname tuple_name else selfname derivedfieldname sampling_type function kwargscodesnippet
2019,oh
2019,thats possible
2019,good call
2019,thanks ill try that
2019,grumbles about getting rid of string field names
2019,yeah
2019,i wish wed get rid of codesnippet and just have codesnippet
2019,that would make my life much easier
2019,and be less confusing to the uninitiated
2019,probably worth having a discussion about that
2019,we can at least deprecate h_number_density
2019,if people agree
2019,yeah that would be great
2019,i think the issue is the following
2019,when you call codesnippet it doesnt automatically add to codesnippet
2019,i saw this a long time ago and cant remember quite why
2019,i think because the codesnippet is created at later stage and so doesnt necessarily exist yet
2019,well wait maybe thats not this specific issue but its a thing that does happen when you add aliases manually
2019,yeah thats fair but we manually add the field to the derived field list
2019,its just a field name no
2019,not the actual field definition
2019,yeah i guess its unrelated but maybe this is technically a bug if codesnippet is to be considered a userfacing function
2019,its not
2019,at least imo slightly_smiling_face
2019,ok fair enough
2018,related to halo finding im having a bit of trouble understanding from the worked halo analysis example hyperlink how to access one of the default quantities say codesnippet
2018,i seecodesnippetin 10 hcquantitiesout10particle_identifier particle_mass particle_position_x particle_position_y particle_position_z virial_radiuscodesnippet
2018,though this appearas to be a list not a dict of quantities
2018,relatedly is it possible to find out what the particle ids are that go into a given halo
2018,user each halo being processed by the halo catalog will have a dictionary called codesnippet with those keys
2018,so after codeblock something likecodesnippethalo hchalo_list0print haloquantitiescodesnippet
2018,
2018,so if you write some halo callback functioncodesnippetdef some_callbackhalo haloquantitiesparticle_masscodesnippet
2018,yeah your example should also work
2018,the new catalog saved to disk will also save all those quantities as fields
2018,as for getting the member particles they are not exposed to the user at the moment but they are also not far under the hood
2018,thanks user do you know off hand where in the halo_analysis codes these are i might try to see if i can find these
2018,ideally id love to to use these to track halos from snapshot to snapshot ie follow the growth of an individual halobut would need to match particle ids i think to make sure im connecting the right halos
2018,though maybe theres some functionality for what i just described and im not seeing it
2018,and were back
2018,user the place to look is codesnippet for instances of particle_index
2018,another thing that could work would be to run yts rockstar using just the gas particles you could then use consistenttrees as a way to track objects
2018,and load it with ytree hyperlink
2018,oh those are good ideas thanks
2018,whoops sorry all for posting a dm to someone else in c1ycpsx08help
2018,user has joined the channel
2018,i tried to make a sliceplot of a field that is all zeros heres what i get
2018,
2018,i thought it used to detect this and switch to linear scaling
2018,it should
2018,can you point me to roughly where in the codebase that happens
2018,hyperlink
2018,ah well then
2018,
2018,i guess we could check if the dynamic range is tiny instead of zero
2018,for some value of tiny that might require thinking more than youd like about floating point math
2018,codesnippet
2018,maybe even more generous than that we dont want the colorbar choice to switch randomly when someone is making a movie but if the dynamic range is like 01 or smaller we probably shouldnt be using a log scale colorbar anyway
2018,but i guess if we make an arbitrary choice then we might produce weird behavior where the scaling changes as someone is making a movie
2018,but yeah that would fix your issue at least slightly_smiling_face
2018,im just thinking out loud
2018,i also eventually want to make it so that if youre plotting a field that goes through zero we automatically choose a diverging colormap centered at zero
2018,but that would require metadata in the field system to work nicely i think
2018,isnt the only way checking on eps will cause the colorbar to switch when making a movie is if in some of the frames the dynamic range is roundoff level tiny
2018,yeah im just spitballing that if we chose a much larger cutoff that it might lead people to on average get nicer plots
2018,i agree with you the movie thing isnt an issue if you make the cutoff really tiny
2018,im not sure eps is the right answer though
2018,because what matters is the ratio between the min and max values in the array
2018,and floating point numbers dont have even spacing across the range of floating point numbers so the appropriate ratio to choose depends on the min and max
2018,npnextafter might be useful here
2018,it looks like in this case there actually is a representable number in between 0 and my nanmax codesnippet494065645841e324 dimensionless
2018,yeah so that argues for choosing an arbitrary but still small cutoff
2018,106
2018,i might even go with 01 but that might be controversial slightly_smiling_face
2018,i guess another way to deal with this is if either the min or max is zero go with linear scaling
2018,zero or negative
2018,that would unconditionally avoid the error youre hitting and we wouldnt need to make arbitrary guesses about peoples data
2018,but doesnt a symlog scaling still possible make sense in that case
2018,i think we only go with symlog if there are negative values
2018,so i guess if the min is zero but the max is greater than zero use log scaling
2018,all other cases where the min or max is lt 0 use symlog scaling
2018,sorry
2018,the first one should use linear scaling
2018,symlog has an extra parameter that you need to care about so we avoid it unless we need to use it
2018,linthresh
2018,that fixes my issue but what if the min is 00 and the max is 108 isnt that an appropriate thing to logscale after masking out the resulting inf pixels
2018,i thought yt relied on that stuff a lot
2018,like in phaseplots where some of the cells have 0 stuff in them
2018,ah yeah thats true
2018,i guess we could check if the max is greater than 1 and use a onesided symlog scaling with the linthresh set to 1
2018,and if its less than one use linear scaling
2018,or just use symlog scaling with the threshold always set to one maybe that works in all cases
2018,user what version are you on right now a stable release or the dev version
2018,and do you use conda
2018,user has joined the channel
2018,user sorry that i was away for a while i do use condo and im on a dev version
2018,what version do you want to go back to
2018,the one in use about a year ago i dont remember the number though
2018,ok i guess the easiest thing to do is put you back on the last stable release
2018,which came out last august iirc
2018,codesnippetpip uninstall ytconda install ytcodesnippet
2018,hmmm any earlier version like the one on june or july last year
2018,user you can do codesnippet for example to install any version
2018,user i think we can get you up and running though with the latest version i know youre on campus most of the time if you wanted to come by my office at ncsa this afternoon we could go through the issues youre having
2018,thank you
2018,user has joined the channel
2018,user has joined the channel
2019,hi any idea of why the codesnippet is in codesnippet instead of codesnippet i am loading a very large gt232 gizmo snapshot the value of the codesnippet is correct
2019,its a python float i think
2019,which are 64 bits
2019,can you give more detail about what is going wrong exactly
2019,it should probably be an int though not sure why offhand its coming out as a float
2019,i dont know how to track why the codesnippet is float instead of int64
2019,right im not asking you to do that
2019,im just saying i dont know why its coming out that way offhand
2019,i think it is related to the large number of particles in the simulation the same gizmo format with smaller particle number is totally fine
2019,id probably need to mess with the raw output file
2019,what yt version is this
2019,a quick hack might be to just say codesnippet
2019,thatll paper over the error
2019,i think youre on yt 3x
2019,in which case switching to the yt40 branch might also be a good idea
2019,particularly for a very big particle dataset
2019,yes i can do that but that should be something roots in the loading part which may cause other issues version is 351
2019,so in yt 40 we completely redid the particle indexing system
2019,specifically to better support very large datasets
2019,which is why i think it might be impactful here
2019,all right i will try that
2019,it looks like youre using python27 though youll need to use python3 we dropped support for python27 in the yt40 branch
2019,anyway good luck
2018,user has joined the channel
2018,user has joined the channel
2018,hello i hope this is the appropriate place is it possible to set the background of a 3d volume rendering scene i am trying to use the background command in saving an image like codesnippetim screnderimwrite_pngblue_bgpng background0011 sigma_clip3codesnippet yet the png still has a black background is this the proper technique also in the cookbook here hyperlink it doesnt appear to have any effect either
2018,yeah there is a bug tracking that
2018,it used to work in the old volume rendering infrastructure and unfortunately it wasnt noticed when we made a big change
2018,im not sure what the ultimate fix is
2018,hyperlink
2018,hmm okay thanks for the quick answer its unfortunate that it is broken and i hope it gets fixed i tried the modifications made in one of the posts on that thread but it didnt seem to fix it for me even with grey opacity did that require a different branch of code
2018,user no as far as i understood this functionality could be used to spread your grid over several processors for some operations so if you have a large grid that could be useful however the numprocs there should be substantially smaller than the number of grid points if you have several grids you can process them individually which yields naturally the largest speedup see hyperlink for help on parallelization
2018,something different a problem i ran into myself i obtain the error message codesnippet from line 669 in ytunitsunit_objectpyc if i do something simple like this example should i create a bug report on github
2018,ptest isnt a unit thats know by yts unit system
2018,what is ptest
2018,oh wait sorry
2018,i didnt read closely
2018,that should work please file a bug
2018,ok will do
2018,another question i have is how yt handles athena input when the ghost cells are also outputted i noticed that codesnippet is changed accordingly but codesnippet is greater than codesnippet this leads to weird artefacts such as shown on the file attached
2018,ok i filed 2032
2018,seems buggy
2018,i bet no one has tried to load data with ghost zones output into yt before
2018,is there some way we can tell by looking at the output that this is the case
2018,my memory is that the athena vtk format isnt especially selfdescribing
2018,yeah i thought so so i tried to fix it for a while but couldnt figure out the structurealso because the value of codesnippet is very strange ie doesnt fit any expectations i had so not sure whats going on there
2018,user
2018,user has joined the channel
2018,yeah our problem here is that we dont yet support this kind of data but if there is a way from the file to tell that the ghost cells are there we can ignore them
2018,do you have a file i can look at for this user is the one you give me already like that
2018,no its not that one sure i can upload another one with added boundary conditions should i file a bug report note that apart from the visual artefacts things seem to run fine so it is not that important
2018,well if there are visual artifacts i wouldnt trust anything else
2018,you should definitely not trust anything about this data at this point
2018,oh ok smile thanks
2018,but please do file a bug report
2018,will do thanks for your help
2018,ok i filed 2033 thanks for your help with these two issues
2018,awesome will try to look at the first one today i think we should get that one fixed for yt 35
2018,is there a way to calculate the angular momentum for some particular cells that satisfy some conditions as an example i want to calculate the angular momentum for all the dense gas within a sphere but this way doesnt work thankssp dsspherecenter 10 kpcdense_sp spcut_regionobjh_p0_number_densitygt 1e2dense_spquantitiesangular_momentum_vector
2018,and another question im trying to understand how yt calculates the quantitiesangular_momentum_vector i thought its a combination of the x y z specific angular momentum of all the particles but clearly its not here is how i did it anything wrong here
2018,
2018,what do you mean by it doesnt work do you mean the results are not coherent with what you expect
2018,also be aware that the codesnippet accepts some arguments to control what is actually computed am of the particles am of the gas if that makes sense for your dataset
2018,for my first question i cant do dense_spquantitiesangular_momentum_vector it gives me an error like this one
2018,indexerror traceback most recent call lastltipythoninput52000e9aaa8dcgt in ltmodulegt 1 sp dsspherehalo_center 10 kpc 2 dense_sp spcut_regionobjh_p0_number_densitygt 1e2gt 3 dense_spquantitiesangular_momentum_vectorlocallibpython36sitepackagesyt35dev0py36macosx109x86_64eggytdata_objectsderived_quantitiespy in __call__self args kwargs 65 storage 66 for sto ds in parallel_objectschunks 1 storage storagegt 67 storesult selfprocess_chunkds args kwargs 68 now storage will have everything and will be done via pickling so 69 the units will be preserved credit to nathan for thislocallibpython36sitepackagesyt35dev0py36macosx109x86_64eggytdata_objectsderived_quantitiespy in process_chunkself data kwargs 462 rvalsextenddataall particle_specific_angular_momentum_s axis 463 dataall particle_masssumdtypenpfloat64 gt 464 for axis in xyz 465 rvalsappenddataall particle_masssumdtypenpfloat64 466 return rvalslocallibpython36sitepackagesyt35dev0py36macosx109x86_64eggytdata_objectsderived_quantitiespy in ltlistcompgt0 462 rvalsextenddataall particle_specific_angular_momentum_s axis 463 dataall particle_masssumdtypenpfloat64 gt 464 for axis in xyz 465 rvalsappenddataall particle_masssumdtypenpfloat64 466 return rvalslocallibpython36sitepackagesyt35dev0py36macosx109x86_64eggytdata_objectsdata_containerspy in __getitem__self key 280 return selffield_dataf 281 elsegt 282 selfget_dataf 283 fiunits is the unit expression string we depend on the registry 284 hanging off the dataset to define this unit objectlocallibpython36sitepackagesyt35dev0py36macosx109x86_64eggytdata_objectsselection_data_containerspy in get_dataself fields 824 parent getattrself parent selfbase_object 825 selffield_datafield gt 826 parentfieldself_part_indfield0 827 else 828 selffield_datafield selfbase_objectfieldindlocallibpython36sitepackagesyt35dev0py36macosx109x86_64eggytunitsyt_arraypy in __getitem__self item 1034 1035 def __getitem__self itemgt 1036 ret superytarray self__getitem__item 1037 if retshape 1038 return ytquantityret selfunits bypass_validationtrueindexerror boolean index did not match indexed array along dimension 0 dimension is 3 but corresponding boolean dimension is 331
2018,for this question i was expecting my way of calculating the angular momentum of all particles shows the same result as the one from quantitiesangular_momentrum_vector but its not so i wonder whats the argument that the angular_momentum_vector takes could you point me to the source code of this thanks
2018,btw im not using yt40 maybe thats the reason
2018,there were a bunch of fixes to the angular momentum calculation done in the last six months that are in yt40 but not the master branch but these may only affect particlebased datasets it could be beneficial to look these over for both the discussion as well as the location where things are getting calculated as it may provide some insight for your particular problems userhyperlinkhyperlink
2018,these look great thanks user
2018,slightly_smiling_face
2018,i think we made those fixes on master too
2018,ah youre talking about something different nm
2018,this seems like a bug to me you should be able to use the angular momentum vector derived quantity with a cut region is there any chance you can file a bug about this
2018,please include a short example script demonstrating the issue optimally making use of one of the test datasets on hyperlink if you can trigger it with one of those
2020,i guess the point there is that its still using ad rather than ds and hence will likely be just as fast as the method that i copied above thanks anyway smile
2020,and yes i have been running with parallelisation on following some of the docs on the website
2020,using the tip of yt4 im seeing some new errors with basic functionalitycodesnippetimport ytds ytloadfire_m12i_ref11snapshot_600hdf5_ c dsfind_maxdensitycodesnippet
2020,this script fails for both a new os x install as well as a windows install for entirely different reasons disappointed
2020,ughhhhhh thats not great
2020,codesnippetloading particle index 100 1010 0000lt0000 158725itstraceback most recent call last file testpy line 3 in ltmodulegt _ c dsfind_maxdensity file userschummelssrcytcondasrcytgitytdata_objectsstatic_outputpy line 854 in find_max sourcequantitiesmax_locationfield file userschummelssrcytcondasrcytgitytdata_objectsderived_quantitiespy line 622 in __call__ rv supermaxlocation self__call__field sample_fields file userschummelssrcytcondasrcytgitytdata_objectsderived_quantitiespy line 578 in __call__ rv supersampleatmaxfieldvalues self__call__field sample_fields file userschummelssrcytcondasrcytgitytdata_objectsderived_quantitiespy line 65 in __call__ values selfdata_sourcedsarrvaluesi for i in rangeselfnum_vals file userschummelssrcytcondasrcytgitytdata_objectsderived_quantitiespy line 65 in ltlistcompgt values selfdata_sourcedsarrvaluesi for i in rangeselfnum_vals file userschummelssrcytcondalibpython36sitepackagesunytarraypy line 528 in __new__ return _coerce_iterable_unitsinput_array registry file userschummelssrcytcondalibpython36sitepackagesunytarraypy line 223 in _coerce_iterable_units raise iterableunitcoercionerrorinput_objectunytexceptionsiterableunitcoercionerror received a list or tuple of quantities with nonuniform units unyt_quantity436017291e22 gcm3 unyt_quantity058903652 code_masscode_length3 unyt_quantity040852755 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3codesnippet
2020,maybe i need to update to a newer unyt
2020,what version are you using
2020,271
2020,looks like its up to date
2020,user can you run the script above and see if it bails for you on yt4 tip
2020,yep ill try
2020,presumably this error would be caught by the unit tests so maybe it isnt a global problem
2020,were testing with 271 on travis for osx so youre using the same version there
2020,ok good
2020,i just went to check to make sure
2020,oh interesting it seems to work ok if you give it the full field tuple codesnippet but fails for just codesnippet
2020,at least on the os x box
2020,ok thats better then
2020,but on the windows machine i get a totally different error even when i use the full field tuple
2020,we should build in a readable error though if density is passed
2020,or an ambiguous field
2020,i guess i can work on this issue hyperlink
2020,but it seems like maybe the changes necessary to fix it will be in all sorts of places in the code
2020,it doesnt all have to be in one pr
2020,i wonder if we could have a validator function that checks the field is valid thats passed to the various operations that we use in yt
2020,itd make it so all the logic was in one place at least
2020,hmmm
2020,i havent looked into this issue at all yet so im not sure how big of an effort thatd be
2020,sorry its taking me a bit on my machine ive been downloading the ds you used in your example
2020,i can use density on isolatedgalaxy though
2020,but im guessing this ds has particles or something
2020,yeah thats odd both of those datasets lack any native fields with codesnippet so theres no interference there
2020,oh weird ok so i loaded that fire dataset and i am getting other weird errors now
2020,but they have native codesnippet fields
2020,are you getting errors with codesnippet buffer size
2020,because those are the errors im getting in windows and another user reported in os x
2020,im going to try to reinstall 40 and see that this isnt a local error before i say anything
2020,ok
2020,oh so if i do codesnippet it works
2020,but codesnippet is a native field not a derived field
2020,right right
2020,intriguing though
2020,i havent followed enough of what unyt does these days to know whats happening in there
2020,yeah so my traceback with density looks similar
2020,codesnippetiterableunitcoercionerror traceback most recent call lastltipythoninput46a57cf8f4536gt in ltmodulegtgt 1 _ c ds2find_maxdensityreposytytdata_objectsstatic_outputpy in find_maxself field 852 source selfall_data 853 max_val mx my mz gt 854 sourcequantitiesmax_locationfield 855 this is a hack to fix the fact that some noncartesian datasets have 856 dimensionless quantities and we cant yet handle thatreposytytdata_objectsderived_quantitiespy in __call__self field 620 selfdata_sourceindex 621 sample_fields get_position_fieldsfield selfdata_sourcegt 622 rv supermaxlocation self__call__field sample_fields 623 if lenrv 1 624 rv rv0reposytytdata_objectsderived_quantitiespy in __call__self field sample_fields 576 577 def __call__self field sample_fieldsgt 578 rv supersampleatmaxfieldvalues self__call__field sample_fields 579 if lenrv 1 rv rv0 580 return rvreposytytdata_objectsderived_quantitiespy in __call__self args kwargs 63 valuesiappendstoragekeyi 64 these will be ytarraysgt 65 values selfdata_sourcedsarrvaluesi for i in rangeselfnum_vals 66 values selfreduce_intermediatevalues 67 return valuesreposytytdata_objectsderived_quantitiespy in ltlistcompgt0 63 valuesiappendstoragekeyi 64 these will be ytarraysgt 65 values selfdata_sourcedsarrvaluesi for i in rangeselfnum_vals 66 values selfreduce_intermediatevalues 67 return valuespythonanacondaenvsytdev37libpython37sitepackagesunytarraypy in __new__cls input_array units registry dtype bypass_validation input_units name 526 elif _iterableinput_array and input_array 527 if isinstanceinput_array0 unyt_arraygt 528 return _coerce_iterable_unitsinput_array registry 529 530 input array is an already formed ndarray instancepythonanacondaenvsytdev37libpython37sitepackagesunytarraypy in _coerce_iterable_unitsinput_object registry 221 ff getattrinput_object0 units null_unit 222 if anyff getattr_ units null_unit for _ in input_objectgt 223 raise iterableunitcoercionerrorinput_object 224 this will create a copy of the data in the iterable 225 return unyt_arraynparrayinput_object ff registryregistryiterableunitcoercionerror received a list or tuple of quantities with nonuniform units unyt_quantity436017291e22 gcm3 unyt_quantity058903652 code_masscode_length3 unyt_quantity040852755 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3 unyt_quantity1e90 code_masscode_length3codesnippet
2020,i cant find any other fields that generate this problem than density
2020,yeahhhh hmmm
2020,ok well im stopping for now but im happy to help figure this out tomorrow
2020,ok
2020,i think this might be a separate issue outside of the ambiguous field thing
2020,yeah
2020,it might be worth checking to see if another frontend has the same issue
2020,this is definitely a new error as ive run this code under yt4 without issue this code is actually in the trident tests based on yt4
2020,ill do some more digging
2020,its interesting that isolatedgalaxy worked so i wonder if its just gizmo or its all particle frontends
2020,yeah thanks for reporting it
2020,i think we can track it down together
2020,or maybe youll figure it out in the remaining hours of your day
2020,ill give it a shot
2020,it looks like for whatever reason the gizmo dataset is reporting its codesnippet values sometimes in cgs units and sometimes in code units and unyt is having a problem including numbers with different units in the same array but its weird because 1 i dont understand why gizmo would be reporting density values sometimes in code units and sometimes in cgs and 2 unyt should be smart enough to use its conversion to put the code_length units into cgs in the array but i imagine 1 is the source of the problem
2020,so after some more digging here is what i findthe problem persists at least as far back as a year ago in the yt4 branchthe problem occurs for any of the particlebased datasets that ive tested both from gizmo and gadget frontendspresumably this is due to an ambiguous fieldname access since gadget and gizmo datasets both have derived fields for codesnippet as well as codesnippet my guess is that when the derivedquantity is being called on this data some of the chunks are being processed on the codesnippet field which returns in cgs and some of the chunks are being called on the codesnippet field which returns in code_units then codesnippet doesnt know how to combine the quantities with different units presumably this will occur for all derived quantitiesnotably this problem goes away if you first calculate a derivedquantity on one of the gas density fields using the full tuple first egcodesnippet_ c dsfind_maxgas density_ c dsfind_maxdensitycodesnippetpresumably because it already has codesnippet in its cache from the first function call before trying to do the second function callso in the end it looks like the problem could be resolved with code to address this issue hyperlink im happy to work on this i guess maybe whenever a field access is called it should check the derived_field_list if there are any ambiguities and error out if there are this would be done in the fieldinfocontainer
2020,the data we have suppose the enzo_cosmology_plustargz i wish to create a field and calculate the valuefaraday rotation measure it over a length in the dataset i have a term of length in the formula which has units of kpc so how do calculate over some length ie which field should i use in my formula for specifying the length parameter
2020,you can also do codesnippet to get the position or other field values at the max
2020,as a note codesnippet and codesnippet do both in a single pass and cache the results so if you do one doing the other should be fast
2020,indeed additionally i note that codesnippet and codesnippet generate heterogeneousunit coordinates in noncartesian as we discussed in many occasions this is the correct though not widespread behaviour for non angular coordinates slightly_smiling_face
2020,thanks every one
2020,hi user i think it would help if you posted the code for the definition of your luminosity field and for how you are creating the sphere could you do that
2020,hi britton this is my code
2020,import ytimport mathimport numpy as npfrom yt import derived_fieldfn tigresscenchris_chooredshift0045ds ytloadfn file_stylesgridcpu04i unit_systemcgsfilename tigresscenchris_chooc31z3000finegalaxiesstsaf openfilename rfrom ytunits import gram centimeter erg s kg k gdefining constantsclightytphysical_constantsclightplanckytphysical_constantshcgsb_constantytphysical_constantskboltzproton_massytphysical_hyperlinkdefining additional necessary parameterse_transition 2178961011ergphi1se_mass 91091028gn_one31n_two 30delta_n 1z 1m_delta_n 0190775defining necessary formulasfrequency e_transition1n_two21n_one2planckf_n1_n2n_onem_delta_n115delta_nn_oneprintclight clightprintplanck planckprintb_constant b_constantprintproton_mass proton_massprintfrequency frequencydef _emissivityfield data return 34691012phizf_n1_n2n_one13delta_n2n_onedatah_number_densityin_units1cm3dataelectron_densityin_unitsg1cm3e_massdatatemperaturein_unitsk52npexp1579105n_one2datatemperaturein_unitsk2b_constantdatatemperaturein_unitskfrequency2clight2ytadd_fieldemissivity sampling_type cell function _emissivity units ergsk52cm8def _luminosity_fieldfield data return dataemissivityin_unitsergsk52cm8datacell_volumein_unitscm3ytadd_fieldluminosity_field sampling_type cell function _luminosity_field units ergsk52cm5
2020,the part with the sphere
2020,x y z for line in f words linesplit xappendfloatwords13 yappendfloatwords14 zappendfloatwords15 inc1
2020,for some reason if i try running
2020,sp_2 dssphere04326766 05219305 03977057 50 kpcluminosity_sum_2 sp_2sumluminosity_field
2020,before defining the sphere the code runs however if i try running it after defining the sphere i see the error that i posted
2020,i meant beforeafter getting the values for x y z
2020,this doesnt actually seem to be explicitly related to hardcoding more something about how getting the values for x y z interferes with my ability to sum luminosity for a sphere
2020,thank you
2020,hi shai i havent tried to run this yet but i noticed that your code has a line codesnippet so you are clobbering the list of z positions for the spheres or the other way around one of those two variable names needs to be changed i suspect this is the issue
2020,youre absolutely right
2020,thank you
2020,excellent glad i could help
2019,thanks user the demeshened yt40 version works beautifully with gas density and temperature does it also work for doing a projectionplot of density of stars parttype4 and highres dm parttype1 for the example fire sim used in that notebook
2018,user has joined the channel
2018,user has joined the channel
2019,hey i think ive already asked this question in the past but is there an efficient way in yt to get the value of a given field at a list of position
2019,say i have an array of shape codesnippet is there a way to query eg the pressure at each location
2019,i think codesnippet is what youre looking for
2020,user has joined the channel
2020,hi i tried installing yt40 in a separate conda environement but neither codesnippet nor codesnippet workedthe first fails withcodeblockthough i did install it while codesnippet just runs forever printing nothingany clue
2020,id strace the latter to see what its doing
2020,and i avoid conda so i wont help much with the former slightly_smiling_face
2020,strace
2020,hyperlink
2020,im on mac i dont think i can use this confused tried getting it with homebrew to no avail
2020,i use conda on a mac
2020,is your cython in your base env or the new env you created
2020,i installed it on the target env
2020,hmmm
2020,if you switch to master does it build with codesnippet is this just an issue with 40
2020,well thats what i did in my usual not base env and yes it worked
2020,i actually did it multiple times on this machine and it always worked with master but never with yt40
2020,is it always an issue detecting cython or do other things happen sometimes
2020,i dont remember last time i tried i did not keep trace of what exactly had gone wrong confused
2020,no worries
2020,can you do codesnippet in the env
2020,codesnippet packages in environment at usersclmminiconda3envsyt4 name version build channelappnope 010 py38h32f6830_1001 condaforgebackcall 010 py_0 condaforgebzip2 108 h0b31af3_2 condaforgecacertificates 20191128 hecc5488_0 condaforgecertifi 20191128 py38h32f6830_1 condaforgecftime 111 py38h65ad66c_0 condaforgecurl 7680 h8754def_0 condaforgecycler 0100 py_2 condaforgecython 02915 py38hc84c608_1 condaforgedecorator 442 py_0 condaforgeexpat 229 h4a8c4bd_2 condaforgefreetype 2101 h8da9a1a_0 condaforgegettext 01981 h46ab8bc_1002 condaforgegit 2250 pl526hdc91d69_0 condaforgehdf4 4213 h84186c3_1003 condaforgehdf5 1105 nompi_h3e39495_1104 condaforgeipython 7130 py38h32f6830_2 condaforgeipython_genutils 020 py_1 condaforgejedi 0160 py38h32f6830_1 condaforgejpeg 9c h1de35cc_1001 condaforgekiwisolver 110 py38ha0d09dd_1 condaforgekrb5 1164 h1752a42_0 condaforgelibblas 380 16_openblas condaforgelibcblas 380 16_openblas condaforgelibcurl 7680 h709d2b2_0 condaforgelibcxx 901 1 condaforgelibedit 3120170329 hcfe32e1_1001 condaforgelibffi 321 h4a8c4bd_1007 condaforgelibgfortran 400 2 condaforgelibiconv 115 h0b31af3_1006 condaforgeliblapack 380 16_openblas condaforgelibnetcdf 473 nompi_hda4e5f1_101 condaforgelibopenblas 039 h3d69b6c_0 condaforgelibpng 1637 hbbe82c9_1 condaforgelibssh2 182 hcdc9a53_2 condaforgellvmopenmp 901 h28b9765_2 condaforgematplotlib 321 0 condaforgematplotlibbase 321 py38h1300a51_0 condaforgempi 10 openmpi condaforgempi4py 303 py38h5dec745_1 condaforgempmath 110 py_0 condaforgencurses 61 h0a44026_1002 condaforgenetcdf4 153 nompi_py38hcf2264a_102 condaforgenumpy 1181 py38hde6bac1_0 condaforgeopenmpi 402 hed52333_4 condaforgeopenssl 111e h0b31af3_0 condaforgeparso 062 py_0 condaforgepcre 844 h4a8c4bd_0 condaforgeperl 5262 haec8ef5_1006 condaforgepexpect 480 py38h32f6830_1 condaforgepickleshare 075 py38h32f6830_1001 condaforgepip 2002 py_2 condaforgeprompttoolkit 304 py_0 condaforgeptyprocess 060 py_1001 condaforgepygments 261 py_0 condaforgepyparsing 246 py_0 condaforgepython 382 hdc38147_4_cpython condaforgepythondateutil 281 py_0 condaforgepython_abi 38 1_cp38 condaforgereadline 80 hcfe32e1_0 condaforgescipy 133 py38h82752d6_0 condaforgesetuptools 4600 py38h32f6830_2 condaforgesix 1140 py_1 condaforgesqlite 3301 h93121df_0 condaforgesympy 151 py38h32f6830_2 condaforgetk 8610 hbbe82c9_0 condaforgetornado 604 py38h64e0658_1 condaforgetraitlets 433 py38h32f6830_1 condaforgewcwidth 018 py_0 condaforgewheel 0342 py_1 condaforgexz 524 h0b31af3_1002 condaforgezlib 1211 h0b31af3_1006 condaforgecodesnippet
2020,ok im trying out something on my machine
2020,i also tested user on my machine mac and yt40 pip install e is also running forever
2020,user sorry i lied it works for me disappointed
2020,damn it
2020,i mean good for you sweat_smile
2020,i dont need it just was testing to see if it was also the case for my conda to better pinpoint the problem slightly_smiling_face
2020,and thank you for that
2020,hope you find the problem soon slightly_smiling_face
2020,user what version of python are you using in your build
2020,ok i just made a fresh py38 env and tried to build 40 and had an issue too
2020,or i think i did
2020,i walked away from my computer and it hung
2020,i didnt have any issue picking up cython though
2020,anyways i will do my best to figure this out later in the week but for now i would try building in a different python version i didnt have issues building with 36 for the yt40 branch
2018,user has joined the channel
2018,im trying to generate some multipanel images for a fire paper using this cookbook recipe as a template hyperlink these are great templates on how to use the mpl codesnippet object but i had a quick question i couldnt seem to figure out i need to put the colorbar on the top of the image not on the side since im putting several panes next to each other but if i use the method described in these cookbooks which just grabs the ytgenerated colorbar and sticks it in the codesnippet colorbar position it looks all smooshed because yt generates one for a vertical placement and mpl wants one for horizontal is there any easy way around this example imagehyperlink
2018,no idea
2018,it might be easier to do it fully manually using the frb interface
2018,yt plots in general dont know how to draw themselves with horizontal colorbars
2018,so youd be fighting against that
2018,yeah thats what i thought i dug into the code a bit but seemed problematic
2018,is there a good example of doing it fully manually using the frb interface presumably the frb interface wont account for the annotations on the plot window right
2018,yeah youd need to draw those manually too confused
2018,gotcha
2018,well the plot axes themselves look good i wonder if there is a way to use them asis and then just create the colorbar manually by doing an codesnippet or something
2018,even if i dont use the imshowd frb
2018,hyperlink
2018,but that doesnt use axesgrid
2018,it would be similar though
2018,maybe
2018,i guess youd need to draw the colorbar manually
2018,and not rely on yts plotting code to do it
2018,righti guess im not sure how to do that
2018,i dont know either
2018,its hard for me to say without looking at your code
2018,yeah thats fair
2019,user has joined the channel
2019,yes take a look at this pull request which added that capability hyperlink
2019,user has joined the channel
2019,user has joined the channel
2019,hi all a dumb question when creating an index from an sph dataset does this ignore the bounding box and create the index for all particlescodesnippetx 10ds ytloadsomedummydatah5 bounding_boxxxxxxxdsindex does this ignore bounding_boxcodesnippet
2019,ok ignorant question time ive got yt installed via conda and im struggling to figure out howto upgrade from codesnippet to codesnippet codesnippet conda update ytcollecting package metadata repodatajson donesolving environment done all requested packages already installedcodesnippetthinks for a _long_ time before doing this and still the 341 shrug
2019,is there a way to specify 351 explicitly hyperlink is unclear on what i should be doing here and codesnippet only has stuff about 341
2019,user im not exactly sure if i do codesnippet i can see 351 appearing in my search what channels are you looking in and what version of python are you using
2019,ive got python 35 i just explicitly did codesnippet and it took a while to think but found this
2019,the codesnippet is surprising to me
2019,i dont think there are builds of yt for python 35 on condaforge
2019,at least the latest version of yt
2019,only python 36 and 37 at the moment i believe
2019,the default channel is maintained by anaconda inc we have no way to update the yt package in defaults
2019,user what yt version are you using
2019,user for your question see above
2019,ah no 27 36 and 37 you can see all the builds that are available here hyperlink
2019,so the codesnippet is just misleading
2019,im not sure what that string means exactly
2019,but there definitely arent builds of yt 351 on condaforge for python35 so id guess thats the issue
2019,heh
2019,ok will try updating python to 36 and see what rabbit hole that leads me down thanks
2019,id do 37
2019,38 is about to come out so youll just have to deal with this again soon
2019,updating to 37 now delays that pain for a year or so slightly_smiling_face
2019,see_no_evil
2019,oh lord
2019,so 36 looked like itd work but i was going to take your advice and do 37
2019,codesnippet conda install python37collecting package metadata repodatajson donesolving environment failed with initial frozen solve retrying with flexible solvesolving environment found conflicts looking for incompatible packagescodesnippet
2019,partyparrot
2019,conda install c condaforge python37
2019,basically you always want to use condaforge
2019,except i dont
2019,shrug ok
2019,i use astroconda for everything for many reasons
2019,really defaults doesnt have 37 yet
2019,lol
2019,_ツ_
2019,hopefully the 36 will fix the problem
2019,this is all to get the latest version of trident working
2019,thanks user i saw that the builds were up for 36 and 37 but not 35 slightly_smiling_face
2019,condaforge in general only supports builds for the two most recent python3 releases
2019,oh interesting i didnt realize that
2019,yeah otherwise builds would take too long theyre using free ci resources to do almost all of the builds
2019,ahhhhh yeah that makes sense still thanks for that im sure itll be helpful to know when 38 comes out slightly_smiling_face
2019,hi nathan its 351
2019,and is this an sph dataset
2019,its a gizmo output so for the purpose of yt its particles yeah i think
2019,yes it is
2019,id suggest running the indevelopment yt40 branch see hyperlink for installation instructions
2019,i dont know offhand why its using all of the particles to do the indexing i dont think it should but also the yt3 sph support is in maintainance mode at the moment as ongoing development goes towards releasing yt40
2019,lots of things are faster in yt4 you might find you dont need to use the bbox keyword at all anymore
2019,alright i assume this has enhancements for building the grid on subsets
2019,ah gotcha
2019,theres no mesh in yt4 for sph data
2019,we index particles using a ewahcompressed bitmaps instead of using an octree
2019,this saves a ton of ram and has the side benefit that many operations will be much faster since we just process the raw particle data instead of smoothing data onto the octree
2019,thats fair ill go and check it out cheers for the help duck
2019,yeah i was hitting ram issues loading a big cosmo box
2019,i only needed a small subset of particles around a given galaxy but bbox didnt seem to limit the particles used for indexing
2019,if its a zoomin passing codesnippet will often be a lot faster
2019,that will use the sph particles to build the index instead of all the particles
2019,for yt3x again not really an issue in yt4
2019,this particular one wasnt a zoom just a single galaxy selected from a periodic sim so the majority of gas particles billions were outside the required region
2019,user has joined the channel
2019,hello running into installation issuesi have been attempting to install on a machine running windows with linuxunix enabled and have also attempted to do so on a virtual machine running ubuntu but both fail at this same point
2019,user could you paste the command that youve used to install
2019,userbash install_scriptshusing wget hyperlink as the script with everything set to 1
2019,do you need rockstar
2019,and embree
2019,rockstar yes embree probably not but it fails wo embree anyway
2019,user has joined the channel
2019,hi trying to get the intro import data tutorial working hyperlinkyt seems to be installed correctly but get the following error is it possible im missing a package oryt error 20190530 130152957 couldnt figure out output type for foodataisolatedgalaxytargz
2019,hip and custom python asset attached
2019,
2019,apologies different error nowpython error traceback most recent call lastfile line 19 infile applicationshoudinihoudini175173frameworkspythonframeworkversionscurrentlibpython27sitepackagesytconveniencepy line 98 in loadraise ytoutputnotidentifiedargs kwargsytoutputnotidentified supplied volumessd03_projects20190527_visualizingastronomy03_production01_houdinidataisolatedgalaxytargz but could not load
2019,also the reference hip file here hyperlink is supposed to have a custom python sop but the hip file appears empty could someone confirm this is the case
2019,user has joined the channel
2019,user you need to unpack isolatedgalaxytgz first codesnippet it will create a directory codesnippet and you can load the dataset via codesnippet
2019,user hyperlink has content when i download it locallycodesnippet curl jo hyperlink total received xferd average speed time time time current dload upload total spent left speed100 32062 100 32062 0 0 4472k 0 6262k head withpythonsophipnc hounc1033600baa057ec6cd709a7e5953startfplayback i on r off f 1 e on h on t on a on k on s 1tcur 0fps 24tset 0 10frange 1 240unitlength 1unitmass 1prompt codesnippethounc1033600ba6057ec6cd7043eeba26variablesset g activetake mainset g e 27182818284590452354codesnippet
2019,heythanks a million
2019,hey forgive me if this is the wrong place or way to ask but im having some difficulty with actually saving plots theyre all named slice plots despite being other kinds of plots
2019,how do i fix this
2019,changing the contents of savename only causes the beginig of the file name to change its still always called slice
2019,user make sure youre passing a proper file name with suffix eg my_plotpng
2019,that did it
2019,thanks
2019,one question regarding ytini framework can it be used to load a csv subset of the gaia data source here hyperlinkmy goal is to create a simulation of our own milkway by using a galaxy that is similar to ours obviously i dont want to load the entire gaia source i thought if i knew exactly which csv files contained the andromeda or other isolated galaxy i could load just those
2020,hi trying to make a profile
2020,codeblock
2020,raises this errorcodeblock
2020,what to do
2020,im on the latest version 36 currently
2020,user could you share your entire script whats the location of sphere whats the size of the computational domain
2020,codesnippetgtds ytloadmntzfsbergusersjegnewhorizonoutput_diroutput_00448info_00448txt extra_particle_fieldsparticle_birth_time d particle_metallicity dgtsphere dsspherecenter0450756 0521550 0539467 radius10 kpcthis is a sphere located on centre coordinates of a galaxy identified by adaptahopgtprofile ytcreate_profilesphere radius gas velocity_cylindrical_theta weight_fieldcell_mass accumulationfalsecodesnippet
2020,this was working totally fine in the previous version
2020,also sorry this new code is when i didnt specify any bins at all and it still raised the same error ascodeblock
2020,did something change in the way yt creates profiles between versions 541 and 6
2020,can you do codesnippet after its created and see if coordinates in the same units still make sense
2020,and also codesnippet
2020,needs to run but will be back later
2020,codesnippetprintspheregtytsphere info_00448 center987174778e25 114221664e26 118145563e26 cm radius30856775809623245e22 cmprintdsdomain_left_edge dsdomain_right_edgegt0 0 0 code_length 1 1 1 code_lengthcodesnippet
2020,user i cant reproduce it on datasets i have how big is your codesnippet would it be possible to tar it and upload to hyperlink
2020,i dont have permissions to upload it because im working on a shared computing cluster
2020,its a ramses dataset if that helps
2020,how many cells does it actually select in that sphere
2020,user can you show me the output of codesnippet
2018,hi i have a question regarding how we can access the data values after we have done some yt plotting functions for example i have a variable codesnippet which add the density values along zaxis when i try to print out the summed values in codesnippet python returns an image object with the message codesnippet is there a way to access the changed valuesarrays thanks for the help
2018,you should be able to get an nxn array of the image plane from your summed projection if you look at codesnippet frb stands for codesnippet
2018,user has joined the channel
2020,user is 3mpch a reasonable smoothing length within eagle i know typically iteratively solves that equation for nearest neighbours and density how does that map to the hsml used by a cubic spline
2020,3 mpch may indeed be a reasonable maximal smoothing length however note that this is the kernel cutoff for a wendlandc2 kernel so if you are using the cubic spline for visualisation you will need to multiply all of your smoothing lengths by 1825742 1936492 a pretty small change tbh to have it exactly right
2020,hey apologies couldnt get back to you yesterday yes those fields exist in codesnippet along with fields for other ions in self_ions
2020,i would note that your point about the mean baryon density being off is definitely not the case there are in all of these codes consistency checks to ensure that the mean density is within something like 1e5 of the true value
2020,can i ask what happens if you double half the grid resolution
2020,i actually dont know if my comment about the smoothing lengths above is correct from your code that you use to produce the illustris images it appears that the smoothing length youre giving yt is the fwhm of the kernel whereas in the eagle situations it is giving you the cutoff radius perhaps ash can clarify which one of these that yt expects
2020,its the cut off radius i believe the yt deposition follows the eq 3 of the splash method paper whereas most codes follow eq 9 i think our choice of eq 3 means that the method is very sensitive to the smoothing length and the calculated density being consistent essentially we demand that mh3 rho eq 9 does not require thishyperlink
2020,in the case that mh3 differs from rho then we will end up with the complete wrong density it will look right but the normalization will be incorrect which sounds like the problem we are running into here
2020,that does explain why it works better when using the mass and densities to estimate a smoothing length
2020,ok i see now setting codesnippet and codesnippet was an active decision made back in this prhyperlink so codesnippet is no longer an alias of codesnippet i was the one who sent this conversation over here from trident but now im pretty sure that yt is doing the right thing if trident is still assuming that codesnippet and codesnippet are the same then we need to go there
2020,alright thanks
2020,user has joined the channel
2020,hey i have a gadget dm only dataset and i was wondering if there was a way to make some volume rendering of the dm density
2020,and if not could i do some kind of sphlike projection of the data onto a regular mesh
2020,this is a script for a volume rendering for gizmo sorelated simulations that include baryons that user wrote a while ago this is what i modify to make my own vrcodesnippetbase desikanarayananlogin4 yt_tools more vrpywritten by nathan golbaumimport ytimport numpy as npfrom ytunits import kpcds ytloadgadgetdiskgalaxysnapshot_200hdf5m c dsfind_maxgas densityle c 25kpcre c 25kpcag dsarbitrary_gridle re 2563fields density temperature velocity_x velocity_y velocity_zdata for f in fields printf dataf aggas f printdatafshapebbox nparraylistziple reds2 ytload_uniform_griddata 2563 length_unitdslength_hyperlinkkpcbboxbboxsc ytcreate_sceneds2sccamerazoom2scsavecodesnippet
2020,thanks
2020,and do you know whether it is possible to trick yt into thinking dm particles are like sph
2020,hmmmthat i dont know
2020,didnt someone work on adding smoothing lengths to particles that dont have them stored thats all youd need right
2020,i think so but its the first time i work with sph data ill try to dig up the pr
2020,are you referring to this pr hyperlink
2020,yes i think so it was a fragment of a memory
2020,yeah thats the one
2020,unsure if this is a bug or im just passing it incorrectly butcodesnippetcodesnippetcodesnippetall return a plot in which the xaxis is scaled logarithmicallysetting codesnippet does correct the issue
2020,looks like a bug to me
2020,although i was not able to reproduce it on the master branch im getting a linearly spaced xaxis with either codesnippet or codesnippethowever its true that passing codesnippet and getting a logspaced xaxis feels counter intuitive i think the api can be improved to solve this pretty easily
2020,user i opened a pr to solve this here hyperlinkbut im still not sure im capturing your whole issue
2020,in which case its likely related more to the fact my yt repository is the amrvac frontend version rather than the official yt version i think the amrvac frontend was due to be incorporated in yt 40 but maybe i should ask my local dev team about it instead thanks for the info
2020,note that the amrvac frontend is part of the latest yt release 36
2020,and indeed it will soon be part of the 40 branch
2020,if you have issues with the frontend though im here to help too i wrote the frontend with user and im interested in any form of feedback
2020,hi allim trying to plot multiple line plots on the same plot but of two different quantities with wildly differing orders of magnitude currently i guess yt detects this and plots them on two different axes but as can be done in matplotlib is there a way to specify which quantity is plotted on which axis ie same x range two y axes one quantity to each
2020,cool thanks for the clarification indeed user and i have been in near constant communication as i learn both yt and python in general slightly_smiling_face
2020,is there any way to access cells within a certain distance of other cells i have a binary field where gas is in state 0 or 1 and i want to know what fraction of state 0 gas cells are within 2 kpc of a state 1 gas cell but i have no idea how to ask about nearbyalmost as good would be cells which are adjacent is there a way to access a cells immediate neighbors ie how many state 0 cells are adjacent to a state 1 cell im using art but i dont know how to do this in any mesh code though it seems like it would be possible
2020,i think youd have to write up code to do this explicitly as i am not aware of this functionality existing already within yt
2020,i could try to do it by using the cells physical distance is the xyz position of a cell available explicitly though just imagining it having to scan through all the state 1 cells for each state 0 cell might be really slow but maybe not horrible idk
2018,user has joined the channel
2018,user i think thats unrelated to the issue you linked to
2018,if youre dealing with amrex anyway
2018,if youre getting a seg fault trying to volume render amr data then its a different issue
2018,how big is the dataset youre dealing with
2018,any chance you can generate the segfault while running with the python faulthandler
2018,you could also get a clevel traceback with gdb
2018,feel free to open an issue on github about your specific problem if you can somehow create an example one of us can run to trigger the issue that would be a huge help but i understand how that can sometimes be difficult for realworld issues
2018,hmmm okay the plt folders are fairly large on the order of 10100 gb the thing that seems odd about the issue is that i get the codesnippet but sometimes it will still output an image that feels correct
2018,maybe you can just output the amr hierarchy
2018,eg all the grid left and right edges
2018,what do you mean exactly
2018,sometimes these issues are caused by how yt handles the grid geometries not the underlying actual dataset
2018,usually for amr data storing the grid hierarchy takes a lot less ram
2018,anyway 10 gb isnt so big actually
2018,if you can reproduce it with one that small and upload it somewhere i can try to reproduce
2018,another thing to check would be to turn on bounds checking in the volume renderer
2018,we have it turned off for speed but that assumes there are no bugs slightly_smiling_face
2018,that has to happen at compile time though
2018,yep thats what i am going to do with this and the codesnippet issue i mentioned earlier i just havent had time to pair down and simplify everything to completely narrow down the problem to make it easier to sift through
2018,i will give that a try though
2018,do you guys have access to an hpc system to test problems scaling up
2018,yes we do but we dont run the unit tests on huge datasets like that
2018,if youd like to help us set that up that would be awesome
2018,theres probably a way to test these sorts of scaling issues in a more sustainable way right now its more or less oneoff
2018,anyway looking forward to hearing more id be happy to also walk you through the debugging suggestions ive made if you dont know how to do it getting a faulthandler traceback from python getting a gdb traceback and turning on bounds checking
2018,if i had to guess theres some overflow issue or grid geometry bookkeeping issue in the volume renderer that causes an oob access which sometimes causes a crash
2018,its all written in cython and theres a compiletime toggle to turn on bounds checking on a function by function level
2018,we have it turned off because its a large performance overhead
2018,but you can turn it back on if you want
2018,that would at least give you a better traceback
2018,okay cool that sounds good i will give you a shout when i try it again because i am not entirely sure how to do those debug tests
2018,what would setting up a scaling test entail
2018,and what do you mean run unit tests
2018,so we have a full automated test suite that runs on travis ci appvveyor and a jenkins instance running on a server at ncsa every change to the codebase needs to pass the tests
2018,in principle someone could add some sort of automated test run with big datasets on an hpc system to our testing configuration it would be a big job though
2018,but it would be valuable to have scaling tests and to make sure were not introducing issues that only trigger for large datasets eg memory or performance issues
2018,not saying you need to do this just saying we have limited resources and was trying to fully answer your question
2018,anyway im trying to take the day off here just wanted to quickly answer your question slightly_smiling_face
2018,have a nice day and looking forward to hearing more about your issues
2018,yes of course i couldnt do it at the moment but in the future i would definitely like to help because i think these kinds of problems are fun to tackle and i should probably be on my own hpc allocation thanks for the answers enjoy the day
2018,what sort of data are you working with
2018,like how are the data structured in space
2018,if you have xyz positions i guess not a uniform resolution grid
2018,hello and thank you very much my data is on a uniform resolution gridif i plotted just the xyz i would have a uniform cubic grid with nx ny nz points in direction
2018,ah then youre looking for ytload_uniform_grid
2018,hyperlink
2018,thank you i figured it out the plots look incrediblethis is an awesome package i have pasted my code mostly based on the tutorials below in case it is useful to othersone small question what does codesnippet do does it need to equal the number of grid pointscodesnippetimport ytimport numpy as npimport matplotlib as pltfrom ytvisualizationapi import streamlinesfrom ytunits import mpcfrom mpl_toolkitsmplot3d import axes3dwspan 2grid_pts 64v_x wspan2nprandomrandomsizegrid_pts grid_pts grid_pts1v_y wspan2nprandomrandomsizegrid_pts grid_pts grid_pts1v_z wspan2nprandomrandomsizegrid_pts grid_pts grid_pts1data dictvelocity_x v_x cms velocity_y v_y cms velocity_z v_z cmsbbox nparraywspan wspan wspan wspan wspan wspands ytload_uniform_griddata v_xshape length_unitmpc bboxbbox nprocsgrid_ptsc dsdomain_centern 100scale dsdomain_width0pos_dx nprandomrandomn3scalescale2pos cpos_dxpos posnormposaxis1gt1 create streamlines of the 3d vector velocity and integrate them through the box defined abovestreamlines streamlinesds pos velocity_x velocity_y velocity_zlength100mpcstreamlinesintegrate_through_volume create a 3d plot trace the streamlines through the 3d volume of the plotfigpltfigurefigsize1010ax axes3dfigfor stream in streamlinesstreamlines stream streamnpallstream 00 axis1 stream streamnormstreamaxis1gt1 remove points in forbidden region axplot3dstream0 stream1 stream2 alpha8 colorklinewidth02codesnippet
2019,hi all im looking into ways to distort a 3d volume rendering by modifying the ray tracing i have an equation that describes how the ray passes through the scene based on the field data at each point can someone point me to where would be a good place to start building this in yt
2019,user yes the trickiest bit will be if the scatteringdistortion changes the order in which the grids are traversed but this can be addressed either by using a modification of the streamlines code or you could try out some new stuff that user has been implementing for path traversal if theo rder of the grids does not change you can change the lens objects in codesnippet
2019,user has joined the channel
2020,hey all we have a version of arepo where we have some custom fields in parttype3 dust density id like to make a projection plot of that but find that the projection plots work only on eg gasdensity like fieldsim not really sure how to convert my codesnippet field to one like codesnippet in order to make a projection plot is this straight forward to do
2020,does codesnippet have smoothing lengths definedif notcodesnippet reload pt3 particles into a stream datasetad dsall_datapt parttype3fields particle_mass fparticle_position_ax for ax in xyz dust_densitydata field adpt field for field in fieldsds_pt3 ytload_particlesdata data_sourcead generate the missing sph fieldsds_pt3add_sph_fieldscodesnippet
2020,if it does have smoothing lengths defined like codesnippet then maybe you can just trycodeblock and then try to projectcodeblock
2020,thanks user we do have the fieldcodeblockthough this is different than how its defined for parttpye0codeblockso its possible yt wont know it existsthe stream idea is creative i tried it and the only thing is that it stuffs the codesnippet into bothcodeblockandcodeblockis there an obvious way to get it intocodeblock i think that might be the ticket if so
2020,hello all im trying to plot vorticity magnitude fields in gaseous bluffbody flow this was working fine with a native yt install on the hpc resources i was using before but i switched to a new computer where i did my own fresh install of yt last week using the bash install script miniconda version and since then when i try and plot vorticity magnitude the fields are wrong and blocky other fields eg temperature velocity magnitude seem to be working fine this is amr boxlibtype data and the fields look to be polluted levelwide with distinct leveltolevel chunkiness any idea what could be causing this andor what i can do to fix it
2020,do you know which yt version you were using before it might be a regression which if so would help us to fix it if you can file an issue about this including a version of the image where things are correct the yt version used to create the image and a version where things are incorrect and that yt version that would help us track down why its wrong if you can also include a test script we can run locally using either a dataset you uplpad somewhere or one of the datasets at hyperlink that would also help
2020,user user fyi with the dataset codesnippet and yt 4 i seem to reproduce the issuecodesnippetimport ytds ytloadmaestro_subch_plt00248p ytsliceplotds x vorticity_magnitudepsavecodesnippet
2020,
2020,
2020,thanks yes before i was using version codesnippet of yt whereas now i am using codesnippet my datasets are too large to share conveniently but i was able to reproduce this issue on my laptop with the turbboxlowres orion 2 dataset at the link you provided i created a new conda environment with yt codesnippet and produced the nonchoppy attached image whereas the default conda environment with yt codesnippet produces the choppy version the simplified code to reproduce this issue is also attached
2020,
2020,great can you file an issue on github so we dont lose track if youre feeling ambitious you could also try running git bisect to find the precise commit that broke things
2020,also maybe ping user same github username
2020,im on phone right now so its not so easy to do it myself
2018,user has joined the channel
2018,user has joined the channel
2018,hey is there something in yt where i can refind particles in halos within eg 12x r_vir instead of 1x r_vir
2018,i would just try to write something myself but i imagine there are a _lot_ of optimizations that can be made
2018,theres a project that builds off of yts capabilities called codesnippet by user hyperlink
2018,it can do what youre asking for maybe with a tiny bit of modification
2018,and works for gadgetoids
2018,ah yeah i am already using caesar id be interested to figure out how to get that ive been chatting with romeel about it but i think i need to escalate to a higher support level stuck_out_tongue
2018,it uses fof to find halo and galaxy groups and then dumps them into an object to use it in its default form you can do something likecodesnippetimport caesarobj caesarloadsnapshot_nameobjmember_searchobjsavecaesarfile for future usage of the caesar file in the future you can just caesarload the caesarfile i thinkcodesnippetthen the codesnippet is an object that holds all the galaxy and halo info you could access the particle indices from the most massive halo bycodesnippetglist objhalos0glist get the gas particles in the halo slist would do star particlesds ytloadsnapshotnameobjyt_dataset dsad dsall_datagas_masses adparttype0massesglistcodesnippet
2018,or something like that anywaysmight be some slight syntax errors
2018,thanks slightly_smiling_face i also still need to figure out how to properly get my ahf stuff into caesar this project has been a bit fastpaced so ive just been running around like a headless chicken
2018,do you collaborate with romeel at all i know mika rafierferantosa was trying to get codesnippet to play nice with codesnippet and had it working though i could never get it to produce reasonable results
2018,if you do get ahf to play nice with codesnippet let me know user was working on this for a bit as well on our end though we decided to stay with the built in codesnippet fof for now
2018,i have a thing that emulates part of the api for caesar for ahf because we didnt trust the fof rightly so actually in our case its in hyperlink but of course its a piece of crap and isnt ready for primetime ill probably be doing a little touchup on caesar soon to make it work properly with py3 as well so ill try to let you know when thats sorted
2018,yeah im working with romeel on the project id like this for actually we still havent got velociraptor working yet unfortunately i would like to work on that because we have velociraptor running onthefly in swift ie during the simulation we output halo catalogues at a higher frquency than particle data
2018,oh cool ill point user at the above github page
2018,its not particularly helpful but there are some conversion scripts in there that stick things in a fakecaesar object if you really need something to work asap
2018,i think the way to do this in the halo objects api in yt is to create a callback on the halo finding process that attaches a sphere data object at 12 rvir to the halo object during processing
2018,it might be easiernicer in caesar tbh the halo objects api in yt needs some love could be a lot nicer and easier to use however we tend to think things like that should be outside core yt going forward
2018,thanks for your help both ill try to contact mika and we can chat about how to do this within caesar failing that ill look into the callback in yt
2018,hey i was trying to save and load a geometric data container a sphere based on a ramses dataset however when i reload it it seems that i cant do plot anymore
2018,i get the errorcodesnippetin 49 p ytprojectionplotdss x gas density deposit gas_tracer_density centercenter widthrvir mpcyt debug 20180724 191750821 appending object to info_00143hdf5h5 type ltclass ytdata_objectsselection_data_containersytregiongtytinvalidfieldtype traceback most recent call lastcodesytscriptsiyt in ltmodulegtgt 1 p ytprojectionplotdss x gas density deposit gas_tracer_density centercenter widthrvir mpccodesytytvisualizationplot_windowpy in __init__self ds axis fields center width axes_unit weight_field max_level origin right_handed fontsize field_parameters data_source method proj_style window_size aspect 1452 plotting classes to avoid an exception 1453 test_data_source dsall_datagt 1454 validate_mesh_fieldstest_data_source fields 1455 1456 if isinstanceds ytspatialplotdatasetcodesytytvisualizationplot_windowpy in validate_mesh_fieldsdata_source fields 137 138 if leninvalid_fields gt 0gt 139 raise ytinvalidfieldtypeinvalid_fields 140 141 ytinvalidfieldtype sliceplot projectionplot and offaxisprojectionplot can only plot fields thatare defined on a mesh but received the following particle fields gas densitydid you mean to use particleplot or plot a deposited particle field insteadcodesnippet
2018,is there a way to directly plot eg the gas density or do i have to do a deposition but then some information would be lost
2018,i dont think its possible to do that with a sphere data object no
2018,you can make a codesnippet with a codesnippet data source and then save the slice object
2018,youll be able to make a codesnippet from that
2018,the basic issue is that we dont save the amr index information when you save a 3d data container
2018,so it cant reconstruct the original amr hierarchy
2018,i think we treat everything as particle data when we reload it from a data object
2018,for the slice we can save a 2d version of the amr hierarchy information so we can reconstruct the plot
2018,ok and in general is it possible to somehow convert the region to a sphlike dataset and then reload it
2018,the issue i have is that i have a massive simulation that takes ages to load and i would like to be able to extract the relevant information once and for all to speed up the analysis
2018,even with codesnippet
2018,im doing a zoom simulation for which 50 of the cpus are in the central region so i dont gain much using bbox
2018,the converting to an sphlike dataset is basically whats happening already except support for sph data isnt so great right now
2018,so we treat it as pure nbody
2018,to treat it like sph wed need a way of generating smoothing lengths
2018,which we dont have until the yt40 branch
2018,ok that makes sense
2018,ill stick to my good ol amr then
2018,are there any special instructions for installing yt from source with intel compilers loadedcodesnippetdesikanarayananlogin3 module listcurrently loaded modules 1 intel2018 2 hdf51101 3 openmpi310 4 git2141codesnippetafter what seems like a successful codesnippet installation from sourcecodesnippetin 1 import ytimporterror traceback most recent call lastltipythoninput12d2292a375dcgt in ltmodulegtgt 1 import ytytyt__init__py in ltmodulegt 23 import numpy in case anyone wishes to use it by name 24gt 25 from ytfuncs import 26 iterable 27 get_memory_usage ytytfuncspy in ltmodulegt 45 ytequivalentdimserror 46 from ytexterntqdm import tqdmgt 47 from ytunitsyt_array import ytarray ytquantity 48 from functools import wraps 49ytytunits__init__py in ltmodulegtgt 1 from ytunits import unit_symbols 2 from ytutilities import physical_constants 3 4 from ytunitsyt_array import ytquantity 5ytytunitsunit_symbolspy in ltmodulegt 12 the full license is in the file copyingtxt distributed with this software 13 gt 14 from ytunitsyt_array import ytquantity as quan 15 16 ytytunitsyt_arraypy in ltmodulegt 37 positive divmod_ isnat heaviside none4 38gt 39 from ytunitsunit_object import unit unitparseerror 40 from ytunitsunit_registry import unitregistry 41 from ytunitsdimensions import ytytunitsunit_objectpy in ltmodulegt 32 unit_prefixes prefixable_units latex_prefixes 33 default_base_unitsgt 34 from ytunitsunit_registry import 35 unitregistry 36 unitparseerrorytytunitsunit_registrypy in ltmodulegt 19 from ytunitsunit_lookup_table import 20 default_unit_symbol_lutgt 21 from ytutilitieslibfnv_hash import fnv_hash 22 from ytextern import six 23 from sympy import importerror homedesikanarayananytytutilitieslibfnv_hashcpython36mx86_64linuxgnuso undefined symbol __intel_sse2_strchrcodesnippet
2018,alsocodesnippetdesikanarayananlogin3 cd ytdesikanarayananlogin3 yt git revparse headf3ee5f35fbcf43bfde322be0e56465e2dbe0eb8fcodesnippet
2018,we dont test compiling with the intel compilers and ive never tried doing it
2018,is there no gnu toolchain on this system
2018,if i had to guess what the issue is youre not linking against the intelprovided standard library
2018,ah yeah there are gnu compilersill probably just do that
2018,pretty sure thats how ive done it beforesysadmins get fussy when you report a problem and find out that we compiled without intel so i just thought id reinstall
2018,yeah that workedcodesnippetdesikanarayananlogin3 module listcurrently loaded modules 1 git2141 2 gcc520 3 hdf51816inactive modules 1 openmpidesikanarayananlogin3 ipythonimporpython 365 anaconda inc default apr 29 2018 161456type copyright credits or license for more informationipython 640 an enhanced interactive python type for helpin 1 import ytin 2codesnippet
2018,in principle its something that would be nice to support in practice its a pita because we need to ask intel special permission to get binaries
2018,i have thought about trying to have save_as_dataset save an amr format that would be a subset of the full dataset i think this would be great to have for this type of case but i havent gotten far with it yet
2018,awesome ideally we could simultaneously support block structured and octree amr
2018,hahaha i tried really hard to figure out how that was related to our conversation
2019,user has joined the channel
2019,user can you share the code you have right now makes it easier for me to help if i can build off a runnable example bonus points if your example uses one of the public data files on hyperlink so i can run the full script myself
2019,halos_ds ytloadhalo_catalogscatalogcatalog0h5hc halocatalogdata_dsds halos_dshalos_dsoutput_dirhalocataloghcload
2019,hi the above is what i do to load the catalog which was generated with the followingimport ytds ytloadpathhc halocatalogdata_dsds finder_methodhophccreate
2019,and then im stuck as to what to do with the catalog i can overplot it on a projection of the dm field but i cant easily access the halo properties
2019,its unfortunately not from the public data files this is from a ramses puredm simulation
2019,sure but the workflow with one of the public datasets should hopefully match the workflow with yours one sec
2019,actually is there any chance you can share that data file i dont have one produced by hop
2019,you can do codesnippet on the bash command line and then share the link it prints
2019,user
2019,ah nm i think i can do it with codesnippet
2019,ah i see
2019,i dont think you need the halocatalog at all if you have the halos dataset
2019,codesnippethalos_ds ytloadrockstar_haloshalos_00binad halos_dsall_dataadhalos particle_masscodesnippet
2019,each particle is an individual halo
2019,so the particle_mass field is the mass of the halo
2019,yes this works thanks
2019,im uploading the ramses snapshot just in case its useful
2019,if you have more questions it will be slightly_smiling_face
2019,take a look at codesnippet and codesnippet for more fields that are available
2019,one more stupid questionhow do i access the box width
2019,dsdomain_width
2019,theres also dsdomain_left_edge and dsdomain_right_edge
2019,awesome thanks
2020,hello everyone
2020,im working on cosmological simulation using gadget2 but when i load the snapshot file i got this errorcodeblocki dont know how to fix it and it is strange that just only one snapshot file has this error there is no problem when i load another snapshot file
2020,does anyone know whats wrong with this
2019,user has joined the channel
2019,user following up on yesterday i think that the codesnippet isnt actually doing exactly what i want what im hoping for is to create a new ds that is a subvolume of the originally loaded ds that is if i run the followingcodesnippetimport ytimport numpy as npsnapshot usersdesikanarayanandropboxyt_datasetsenzo_iso_galaxygalaxy0030galaxy0030ds ytloadsnapshotcenter dsarr050505code_lengthlen dsquan025code_lengthregion dsregioncentercenterlencenterlenprintdsdomain_right_edgeprintregiondsdomain_right_edgeprintregionright_edgecodesnippetthe return output iscodesnippet1 1 1 code_length1 1 1 code_length075 075 075 code_lengthcodesnippetin other words what i want is that codesnippet also 075075075 in this example
2019,the use case is that if i want to find the values corresponding to a particular derived_field_list quantity say stellar positions accessing them from codesnippet looks like it will still just access the original loaded dataset and not the regionathe usecase is that if i want to find the values in a particular field in
2019,maybe you want the ytdata frontend then
2019,or just get the fields from the data object
2019,codesnippet
2019,theres no need to reload as a new dataset if all you want is field values in the data object
2019,ah i think this is exactly what i need thanks user
2019,hello all im trying to make an off axis projection plot for a ramses simulation new horizon and im getting confused with the output im putting in vectors to do the projection along but when i run it the xlim ylim and zlim values are strange as the box goes from 0 gt 1 but values are running from negative to positive
2019,here is an example of what i made
2019,and here is what is coming up
2019,the limits issue and the off axis projection plots are still there even when i dont use a sphere and the l vector which i chose as my axis was obtained from the angular momentum information from the newhorizon hop catalogs
2019,and even when i use spquantitiesangular_momentum_vector and use that value for l the same issue comes up and the projection plot looks pretty much the same
2019,my key issue here seems to be that the limits are being fed in incorrectly as these are not around the centre value that i put in
2019,so the values being negative is a red herring the origin of the plot coordinate system is the center of the plot
2019,whats dsdomain_left_edge and dsdomain_right_edge
2019,im curious if the center values youre putting in by hand disagree with the coordinate system yt is inferring
2019,oh wait its in your output
2019,i dont see anything obviously wrong in the screenshot you shared
2019,if you can make a runnable example using one of the ramses datasets on hyperlink that would make it easier for one of us to see exactly whats going wrong since well be able to run your code locally and poke around
2019,ok will do thanks
2019,hey is there a way to access adjacent cells in artamr codes i want to check if a cell has a certain property and one of the cells touching it has the opposite property that is im looking for a boundary i could make little spheres and ask about npany but that seems like itll be prohibitively slow my best guess is that itll have something to do with particle indexing
2018,user has joined the channel
2017,user has joined the channel
2018,im trying to use codesnippet as an io wrapper is there any way to stop it meshing my data and just give me access to the particle fields
2018,not without the demeshening no
2018,the yt40 branch
2018,no worries thanks nathan
2020,user has joined the channel
2018,hey there i find myself very frequently calling things like codesnippet is there a way to make this permanent
2018,user i believe theres a config option for default cmap globally i dont think there is per field though
2018,too bad that would have been neat
2018,user has joined the channel
2018,i agree completely i think user and i chatted about that a little bit ago i do know that if you set your yt config parameter codesnippet itl change the default
2018,its a reasonable feature request please feel free to file an issue about it
2018,there you go hyperlink
2019,hi im trying to take a sphere out of a halo with codesnippet i wonder if the radius is in proper or comoving units
2019,hi codesnippet is in proper units unless you set it like codesnippet
2019,the suffix codesnippet stands for comoving this is probably only supported if your dataset is detected as a cosmological one
2019,i see so i calculate the distance between two points it will always be in proper unless i change it to cm
2019,youd get proper cm
2019,whats proper cm
2019,proper cm would be the physical distance between two objects
2019,oh i see thank a lot
2019,dont trust me too much on that topic though you should probably check all that in a textbook so that everything makes sense slightly_smiling_face
2019,in any case codesnippet in yt is physical parsec while codesnippet would be comoving parsec
2019,yeah append cm to the name of any length unit to get the comoving version
2019,you can also divide by h if youre a masochist like that wink
2019,so comoving kiloparsecsh would be kppcmh
2019,im pretty sure this is covered in the docs
2019,hyperlink
2019,i guess i need to introduce a particle filter but i dont know what the stargasdark matter particles are assigned as ie 1 2 etc in ramses
2019,hi kriti if you are using ramses then there is no such thing as gas particles as the code is gridbased
2019,if you want to do weighted projections of data on the grid you can use codesnippet
2019,for particlebased data you can either use their projection on the grid eg codesnippet which would be the cicdeposition of all the particles or use codesnippet
2019,hi
2019,i tried the gas density thing
2019,and another problem has arisen where all of my plots seem to just be coloured squares
2019,which i also assume is a resolution issue but when i tried to use the set_buff_size function it didnt recognise it
2019,and also in response to the particle projection plot answer how would i isolate just the stars or just the dark matter
2019,it depends on how old your ramses version is if you use recent versions less than 12 years old then yt detects stars from dark matter automatically otherwise you dark matter particles have a null birth time while star do not
2019,so you can use a particle filter look in the doc to distinguish between the two
2019,by default yt uses a 800x800 grid so you should be fine if you see only coloured squares it may indicate that your run has only very coarse cells or that you tried to make a plot that is too small
2019,in any case you can look at the ramses log to know how much cells have been created at each level
2019,ahh ok ok nice
2019,which version are you using
2019,im using new horizon
2019,not sure how to tell how old it is
2019,but i think it might be 2019
2019,im yohan dubois old phd student
2019,and no it is not based on a recent version of ramses unfortunately youll have to use a particle filter
2019,are you using new horizons code or new horizon the simulation
2019,new horizon the simulation
2019,hyperlink
2019,cphyc would know better than me how to identify particle types in your output
2019,codesnippetdef starspfilter data select stars particles if datadscosmological_simulation1 filter dataioparticle_birth_time 0 amp dataioparticle_birth_time none else filter dataioparticle_birth_time 0 return filterdef dmpfilter data select dm particles if datadscosmological_simulation1 if dataioparticle_birth_time none filter dataioparticle_birth_time 0 amp dataioparticle_identity gt 0 else filter dataioparticle_identity gt0 else filter dataioparticle_birth_time 0 amp dataioparticle_identity gt 0 return filterdef young_starspfilter data select particles created after the beginning of the simulation that are younger than 10myr filter dataioparticle_birth_time gt 0 amp dataioparticle_birth_time lt datadsarr10 myr amp dataioparticle_birth_time none return filtercodesnippet
2019,what do i do about the fact that any time a try and pan zoom or set buff size it keeps saying attributeerror list object has no attribute pan_rel
2019,you can use this code to filter the particles
2019,or no attribute zoom or no attribute buff size
2019,could you paste the code that doesnt work from the look of it youre trying to apply functions that work on codesnippet objects but on codesnippet objects
2019,sure one sec
2019,plot1 ytprojectionplotds z gas density width 140 kpcsaveyt info 20191128 141105307 projection completedyt info 20191128 141105308 xlim 0499014 0500986yt info 20191128 141105308 ylim 0499014 0500986yt info 20191128 141105309 xlim 0499014 0500986yt info 20191128 141105309 ylim 0499014 0500986yt info 20191128 141105310 making a fixed resolution buffer of gas density 800 by 800yt info 20191128 141105733 saving plot info_00448_projection_z_densitypnggtgtgt plot1set_buff_size1600traceback most recent call last file ltstdingt line 1 in ltmodulegtattributeerror list object has no attribute set_buff_sizegtgtgt plot1pan_rel01 02traceback most recent call last file ltstdingt line 1 in ltmodulegtattributeerror list object has no attribute pan_rel
2019,is it because i did the save thing
2019,surely not
2019,yup codesnippet returns the list of the file names that have been stored
2019,lame ok
2019,if you print plot1 youll see codesnippet
2019,yeah confused
2019,ok ok so to be able to move around on it i need to do the projection plot without saving it
2018,i think this is a unit issue ill take a look this afternoon i think its because one of your plots is gas density which defaults to cgs but this is filter for parttype0 density which defaults to code length
2018,well code_masscode_length2 for projected density
2018,i think those results are correct youre just comparing different units but this was just a 2 minute glance
2018,replace this linecodesnippetplot pltimshow nparrayimage cmapmagma normmatplotlibcolorslognormcodesnippetwithcodesnippetplot pltimshow imagein_basecgsd cmapmagma normmatplotlibcolorslognormcodesnippet
2018,i think that will fix your issue sorry this has been a pain for you slightly_smiling_face
2018,ahha that fixes it
2018,thought it would be nice to get rid of this potential tripping point by not needing to blow away the units thinking_face
2018,i suppose thats why codesnippet exists and eventually itll be supported in 40
2018,it is supported
2018,as is codesnippet
2018,user is something wrong with either of those im puzzled by your comment that theyre not supported
2018,hm i swear i tried that and i got a notimplementederror ill check back in a bit
2018,and you dont need to blow away the units either you do need to convert them to whatever units you want to plot them in though
2018,hunh thats very strange i have no idea what i was doing that threw a notimplementederror but as you say ytprojectionplot works just fine
2018,oh found it its from doing a ytprojectionplot with a filtered field
2018,ah ok if you can make an example triggering that error i can try to take a look
2018,i bet this is the internals going codesnippet
2018,
2018,this is really no big deal for me i can easily just use the manual plotting interface it was just a bit of a tripping hazard with units earlier
2018,because codesnippeting an array with units doesnt work
2018,yeah it should work though
2018,i suspect we have a few areas where we check the basic codesnippet maybe we should boilerplate this and make it more general for derived fields user
2018,yup agreed slightly_smiling_face
2018,ah really
2018,argh matplotlib keeps breaking that
2018,i keep on fixing it and they keep on breaking it lol
2018,are you fixing codesnippet itself
2018,i swear i got an exception last night about a ufunc not being applicable between a yt array and something unitless but i cant triviall reproduce it now
2018,yes fixing matplotlib itself
2018,hyperlink
2018,most of those are things found by yt users
2018,matplotlib is a fun codebase to dive into i like big python codebases slightly_smiling_face
2018,mercurial is also pretty fun although also kind of insane in the things it tries to handle
2018,heisengbug spotted
2018,is there a way to prevent yt from using all the cpus when doing projectionsslices
2018,codesnippet doesnt seem to do the trick
2018,oh wait sorry i was being stupid
2018,didnt type it in the right terminal
2018,heh
2018,and is there a way with matplotlib styles to mimic the look of yts plot
2018,im thinking about the fonts in particular
2018,theres a codesnippet you can use
2018,not sure if it does everything you want it to do slightly_smiling_face
2018,the math fonts are annoying and need to be controlled with the style context manager
2018,but the other fonts are codesnippet
2018,math fonts are used for anything inside of latex the other fonts are used for all the other text
2018,wheres the matplotlib_style_context object located i dont have it under yt
2018,oh sorry codesnippet
2018,you can use it as a context manager it just sets a couple of matplotlib rc values
2018,great let me try this
2020,hold on yt installed succesfully but it definitely is broken i made lightrays using trident and when i try to load them using codesnippet it breaks and gives me this error codesnippetin 7 ad r1all_datayt info 20200615 202502892 allocating for 7715e04 particlesoserror traceback most recent call lastafsmpatempmrmgehlmytytgeometryparticle_geometry_handlerpy in _initialize_indexself 131 trygt 132 rflag selfregionsload_bitmasksfname 133 rflag selfregionscheck_bitmasksafsmpatempmrmgehlmytytgeometryparticle_oct_containerpyx in ytgeometryparticle_oct_containerparticlebitmapload_bitmasksoserrorduring handling of the above exception another exception occurredattributeerror traceback most recent call lastltipythoninput7b84353e50918gt in ltmodulegtgt 1 ad r1all_dataafsmpatempmrmgehlmytytdata_objectsstatic_outputpy in all_dataself find_max kwargs 928 which covers the entire simulation domain 929 gt 930 selfindex 931 if find_max c selffind_maxdensity1 932 else c selfdomain_right_edge selfdomain_left_edge20afsmpatempmrmgehlmytytdata_objectsstatic_outputpy in indexself 503 raise runtimeerroryou should not instantiate dataset 504 self_instantiated_index self_index_classgt 505 self dataset_typeselfdataset_type 506 now we do things that we need an instantiated index for 507 first off we create our field_info nowafsmpatempmrmgehlmytytgeometryparticle_geometry_handlerpy in __init__self ds dataset_type 25 selffloat_type npfloat64 26 superparticleindex self__init__ds dataset_typegt 27 self_initialize_index 28 29 def _setup_geometryselfafsmpatempmrmgehlmytytgeometryparticle_geometry_handlerpy in _initialize_indexself 138 selfregionsreset_bitmasks 139 self_initialize_coarse_indexgt 140 self_initialize_refined_index 141 wdir ospathdirnamefname 142 if not dont_cache and osaccesswdir osw_okafsmpatempmrmgehlmytytgeometryparticle_geometry_handlerpy in _initialize_refined_indexself 177 mylogdebugusing estimated thresholds of s and s for refinement mask_threshold count_threshold 178 total_refined 0gt 179 total_coarse_refined mask gt 2 amp selfregionsparticle_counts gt count_thresholdsum 180 mylogdebugthis should produce roughly s zones for s of the domain 181 total_coarse_refined 100 total_coarse_refined masksizeattributeerror ytgeometryparticle_oct_containerparticlebitmap object has no attribute particle_countscodesnippet
2020,so i guess copying the contents of codesnippet from an older version breaks it
2020,for reference it seems like the actual yt40 release is still a substantial ways out based on the discussions online last week the yt40 merge with the master branch is going to happen soon though but that will still require building from source at some level
2020,yes i didnt mean to make it seem like it was only a matter of days though i couldnt resist the use of soon its merely a product of my personal enthusiasm sweat_smile
2020,wow really nice
2020,hyperlink
2020,thats isolatedgalaxy for you galactic types
2020,i made a cookbook receipe with that
2020,this looks perfect for the galaxy class brought up at the cca workshop
2020,wink
2020,i had a lot of trouble because the densities are 40 orders of magnitude smaller than i am used to
2020,excuse is there a simple way to quick access the field at the location of the particle for example the gravitational potential at the location of the particle
2020,i think you could use the codesnippet data object for example you could create a codesnippet for your desired location then sample any arbitrary field from that locationcodesnippetimport ytds ytloadisolatedgalaxygalaxy0030galaxy0030p dspointxyzprintpgas densitycodesnippet
2020,you might have to make a new derived field for the gravitational potential in your sim what sort of dataset are you using
2019,hey is there a way in yt to do spherical projection eg mollweide projections from data on in cartesian coordinates
2019,i know i can use cartopy but i was wondering if there was some stuff already included in yt i remember seeing a long pr about this some time ago but i cant remember what it was about
2019,user hyperlink but i dont know if thats what youre looking for
2019,doesnt it work only for data that has a geographic geometry ie can i use with cartesian data
2019,i dunno user would be the person to ask
2019,theres code in the volume renderer to do stuff like this but not elsewhere
2019,the code you need is probably in yt but would need to be wired up
2019,and yeah theres no reason in principle why the cartopy wrappers couldnt work with your cartesian data but youd probably need to wire that up
2019,you could probably pass images to cartopy directly
2019,thats what im going to do then
2019,its just a matter of doing a phaseplot and get the frb to be displayed on a regular projection
2019,so i set up the projections stuff so that it could be extensible to other types coordinate systems but i didnt test this out too much because i didnt have a dataset immediately accessible to look at
2019,there are properties in the coordinate handler called codesnippet and codesnippet that for all systems other than the geographic handler that are set to codesnippet you could change these for your dataset and use them i think but itll still be backed by cartopy
2019,the codesnippet property should be what your data is in i havent checked this but i imagine that cartopy has a way of handling a regular mesh
2019,and then you could set codesnippet to codesnippet
2019,again i didnt check this out for nongeo datasets but id love to help refine this feature if you have a good dataset i can use user itd be great to at least get an example in the docs to show that it can be done for non geo datasets
2019,thanks
2020,user has joined the channel
2020,hi all im a bit new to working in parallel with yt my script appears to get stuck at the end of a ytparallel_objects loop this is happening on stampede2 python 2715 not sure which yt version since yt version on command line doesnt work if anyone has experienced something similar to this i appreciate any advice you may have
2020,never mind i forgot that my version at least of yt doesnt like it when i try to use more than 1 node here is a minimal working example might be possible to make more minimal but i had to wait a while to get the job started the first time aroundidev p skxnormal n 2 n 96 a tgyouraccounthere t 000959ibrun python testpy begin testpyimport numpy as npimport yt ytenable_parallelismstorage num 1250arr1 npzerosnumarr2 npzerosnumarr3 npzerosnumarr4 npzerosnumvals listrangeintnumfor stoval in ytparallel_objectsvals storagestorage printval this gives values from 0 to 1249 out of order since parallel but increasing every 96 storesult_id val storesult storesultarr1 val1 storesultarr2 val2 storesultarr3 val3 storesultarr4 val4 end forprintdone this never executes
2020,i posted this in general first oops but am deleting it from there now sorry
2020,user has joined the channel
2019,hi mihir yes but at the moment it has to be done in a slightly different way ie by calling the rockstarhalofinder directly with a timeseries object here is a sample script that should get you goinghyperlinkwe need to add this to the docs
2019,thanks britton i knew this way of doing it i was thinking of a situation where i didnt have the initial parameter file for some reason but i realized that i can also use a snapshot file in place of the initial parameter file to load the time series thanks again
2019,youre welcome you can also specify a timeseries with a list of snapshots too
2019,hi folks quick question im trying to extract data from a ytphaseplot and cant figure out how to do it so for example if i say something like thiscodesnippetdens cen dsfind_maxdensitysphere dsspherecen300kpcphase ytphaseplotspheredensitytemperaturecell_masscodesnippetand then want to extract the relevant information from the codesnippet object the actual 2d array values as well as limits for x and y axes how would i go about doing that
2019,its relatively easy to do that for a slice or projection but i cant find an analogous process for a phase plot
2019,the bigpicture reason im trying to do this is because one of my students is trying to make a multipanel movie that includes slices projections and phase diagrams all together and it seems easiest to try to extract them all to numpy arrays and then recombine them in a multipanel plot
2019,you mean creating a file with just cosmologyoutputredshift values specified i tried that but it fails saying that it couldnt find topgriddimensions but it works with using the output of the earliest snapshot anyway so not a problem
2019,user i think hyperlink covers how to get it out including the mask as well as the other statistical quantities that come with it
2019,aha
2019,ok this should do the trick for me thank you
2019,hello i am trying to get a fixed resolution buffer out of an off axis projection plot how do i set the resolution of the frb
2019,this is what i tried
2019,ppytoffaxisprojectionplotds100 density weight_fielddensitycentercenternorth_vector001
2019,ppset_buff_size100
2019,nibappfrb
2019,but the shape of this thing is still 800 by 800
2019,also there is off_axis_projection and offaxisprojectionplot which one should i use
2019,thank you
2019,hi userthis can be done with ytoff_axis_projectionfor instance to make an 100x100 image you could docodesnippetthe resolution parameter can be a single int or list of ints for a different number of pixels in each dimension the item parameter is used to specify the field note this returns an imagearray not an frb object but i think the effect probably the same the imagearray is what youd get if you did codesnippet with a true frb object
2019,thanks corey it turned out that there was a bug with offaxisprojectionplot so yes i am using off_axis_projection now
2020,hi again would you mind surrounding your code snippet by triple backticks instead of single ones ie codesnippet without the spaces that would make the code much easier to readalso would you mind sharing an image of what you get out of your code and what you expect
2020,i am sorry what do you mean with codesnippet please i used ctrlshiftc for the code or is it better to share it in hyperlink i got from me code these outputs
2020,the streamlines are not in correspondence to the vector field
2019,user has joined the channel
2018,user has joined the channel
2017,user has joined the channel
2019,if its counts in bins you want then i think you need to make the profiled field codesnippet with codesnippet
2019,oooh
2018,user oh no i also thought we had support for that
2018,well the thing is in my script i have some commands that also load the dataset halo that i want to analyse so since i dont know what to tell you exactly in order for you to help me i uploaded a tar with all the scripts i am using to do the analysis hyperlink thats the link at make_the_catalogpy i load the data and create the catalog whereas in examplepy i calculate the radial velocities of the sub_halos in order to make radial profiles the latter is not done with yt because i couldnt understand how to transform the positions to a meaningful center and insert the hubble flow the simulation ds has only dm particles and is at z0
2018,i hope that those scripts will work
2018,can do ill submit a bug report thanks
2018,hi user whats the order that i would run these codesnippet first is there one script that demonstrates the problem youre seeing
2018,if you could send some explicit instructions for the order in which things are run that would be great
2019,user if you want to apply the patch i sent you save it into a file then docodesnippetgit checkout mastergit patch pathtothepatchpip install e codesnippet
2019,commenting out codesnippet in codesnippet is not enough
2019,dsfield_list has codesnippet just using codesnippet gives the error codesnippet
2019,it sounds like these fields are getting detected as particle fields for some reason
2019,what type should codesnippet and codesnippet be for example here hyperlink
2019,user they should be mesh fields for that annotation
2019,so in that example were working with a enzo amr simulation which is very different from your exodus ii data
2019,i think the field type of your fields should be eg codesnippet id need to have a copy of it to work with to understand whats going wrong here
2019,its probably not specific to anything about your data more our support for exodus ii data in general its possible you could trigger this with one of the test datasets on hyperlink
2019,in which case you wouldnt need to share your data if thats an issue
2019,because yt works with realworld research data its sometimes very difficult to understand whats going wrong without a dataset to trigger issues with and test with
2019,thanks my codesnippet gives some variables that are codesnippet and some that are codesnippet i have no problem sharing the exodus file where can i shareupload
2019,codesnippet
2019,thatll print out a url
2019,please file an issue on github hyperlink
2019,there are instructions in the issue template
2019,hi i am trying to select a subset of halos in ytree and access their properties at once after loading a merger tree i select a subset of halos ascodeblockwhere codesnippet is an array of treenodes satisfying the given criterion is there any way to access fields for these selected halos without looping over them codesnippet for example doesnt seem to work i know i can loop over selected halos and save fields of interest in a list but was wondering if there is a simplerinbuilt way of doing this
2019,user
2019,hes in europe and may be asleep
2019,opened an issue here hyperlink
2019,im having trouble with gizmo data it loads just fine but when i try to call any functions with the data object i get an error message the error message when using dsfield_list is oserror unable to open file unable to open file name usersmichaeljenningsdesktopschoolresearchsnapshot_1600hdf5 errno 2 error message no such file or directory flags 0 o_flags 0
2018,user has joined the channel
2018,hi everyone i am bhavesh a student at georgia tech i have recently started using yt to visualize some of my simulations results first of all thanks to all the developers of yt for creating this amazing toolkit
2018,i had a small question about adding plots to yt i wanted to extract the grid structure from h5 file and create a scatter plot of two numpy arrays over this grid structure i see that there is a feature of annotate_grids in yt but i always need to use some object like slice plot in order to visualize the grid is there a way to visualize just the grid structure and is there a way to add a scatter plot of two numy arrays over it
2019,user yep i can do that and submit a bug report if i still see it in the meantime i wrote a script to compute grid level based on simulation data which seems good enough at the moment
2020,while installing yt on pycharm by conda environment i faced a situation while doing the statement bash install_scriptsh the error was bash is not recognised as internal or external command operable program or batch file will someone please tell me how to proceed with this situation
2020,hi atharva can i suggest instead of the install script if you already have conda installed you can do one of the followingcodeblockor clone the source with git and installcodesnippetgit clone hyperlinkcd ytpip install e codesnippet
2020,i got it fixedi just had to update my git bashthank you for your instant reply
2020,excellent
2019,regarding this hyperlink i was able to render multiple regions in unstructured mesh data using codesnippet function in the codesnippet class actually it was documented unstructured mesh rendering hyperlink however it must be necessary to explicitly specify the same color map because each mesh source is independent now i am wondering if i can create a color bar for rough idea of values i think that for volume rendering the color doesnt precisely represent the value but it would be helpful for me to know where high or low values in initial analysis
2019,i think you can use any matplotlib colorbar you want in the volume rendering
2019,hyperlink
2019,also great slightly_smiling_face
2019,if there are places where our docs are lacking for this or if we can make the codesnippet you initially got point to doing the correct thing pull requests are very welcome slightly_smiling_face
2019,no pressure though
2019,i just want you to feel empowered to poke around and maybe alter or hack the yt codebase
2019,thank you for the suggestion i will try to contribute the project when i have something i can do
2018,user has joined the channel
2018,user has joined the channel
2018,user has joined the channel
2018,is there any way to generate a renderingimages multiband images of galaxies in the ramses box i have the halo coordinates similar to the way pybody does with hyperlink
2018,this uses the star particles
2018,no we dont have anything like that in yt
2018,ok thx
2018,didnt see it in the docs but wanted to be sure slightly_smiling_face
2018,we used to have a way to export data to sunrise
2018,but unfortunately it bitrot confused
2018,im also not sure if sunrise is still a going concern
2018,sunrise
2018,i guess thats another package
2018,hyperlink
2018,it is
2018,the original author left the field 7 or 8 years ago
2018,ah yeah chris hayward took it over
2018,but it looks like it hasnt been touched since 2015
2018,yea just checked it out 2015 slightly_smiling_face
2018,btw when i say it bitrot i mean the sunrise exporter in yt
2018,not sunrise itself
2018,one more question
2018,in principle someone could update it i have no idea how hard that would be
2018,to my knowledge sunrise is still operational but in stasis
2018,user set the channel topic general help with yt please mute this channel if you feel its too noisy
2018,if i want to do a vol render on just a small fraction of my volume say 20 kpc around a halo location how do i specify that with codesnippetsc ytcreate_sceneds lens_typeperspective sccameraset_widthdsquanhalo_size kpc codesnippet
2018,youd want to set the cameras focus at the halos position
2018,but wait youre using ramses right
2018,yep
2018,i thought the volume renderer didnt work with ramses data at all
2018,oh good to know was just starting to play with it this afternoon
2018,yeah the current blocker on that is generating vertex centered data
2018,for octree data
2018,ok that explains this error thencodesnippet sc ytcreate_sceneds lens_typeperspective file home102744earnriclocallibpython27sitepackagesytvisualizationvolume_renderingvolume_renderingpy line 70 in create_scenecodesnippet
2018,thx saved me a bunch of time
2018,what error
2018,oops didnt cut enoughcodesnippet sc ytcreate_sceneds lens_typeperspective file home102744earnriclocallibpython27sitepackagesytvisualizationvolume_renderingvolume_renderingpy line 70 in create_scene if field not in data_sourcedsderived_field_listcodesnippet
2018,heh still not enough slightly_smiling_face
2018,hehe yea i was running on 12 cpus so the errors are a bit jumbled i think want me to post a loooong cutout
2018,you can use hyperlink
2018,codesnippet file rendergalaxypy line 56 in ltmodulegt sc ytcreate_sceneds lens_typeperspective file home102744earnriclocallibpython27sitepackagesytvisualizationvolume_renderingvolume_renderingpy line 70 in create_scene if field not in data_sourcedsderived_field_list file home102744earnriclocallibpython27sitepackagesytdata_objectsstatic_outputpy line 213 in ireq file rendergalaxypy line 56 in ltmodulegt sc ytcreate_sceneds lens_typeperspective file home102744earnriclocallibpython27sitepackagesytvisualizationvolume_renderingvolume_renderingpy line 70 in create_scene if field not in data_sourcedsderived_field_list file home102744earnriclocallibpython27sitepackagesytdata_objectsstatic_outputpy line 213 in ireq selfindex file home102744earnriclocallibpython27sitepackagesytdata_objectsstatic_outputpy line 504 in index self dataset_typeselfdataset_type file home102744earnriclocallibpython27sitepackagesytfrontendsramsesdata_structurespy line 357 in __init__ selfindex file home102744earnriclocallibpython27sitepackagesytdata_objectsstatic_outputpy line 504 in index self dataset_typeselfdataset_typecodesnippet
2018,hows that
2018,i still dont see the actual error anywhere it looks like its dying when it tries to create the index
2018,i dont think that has anything to do with volume rendering
2018,all i can tell is its at the line codesnippet
2018,thats line 56
2018,right but inside of that something is doing codesnippet which is crashing
2018,which is a bit surprising to me
2018,does the same script work on one core
2018,this could be a bug in yts parallelism
2018,i can try
2018,but its hard to say without the actual error slightly_smiling_face
2018,one core
2018,heres everything from the parallel run hyperlink
2018,
2018,ah the actual error is a codesnippet
2018,you ran out of memory
2018,probably because yt was trying to construct the octree repeatedly on each core
2018,i dont think octree construction is parallelized
2018,hum ok but it wont work for ramses create_scene anyway right
2018,yeah youd hit a different error later
2018,but this is a general problem with trying to run yt in parallel like youre trying to do
2018,not everything in yt is parallelized so just running yt in parallel wont necessarily get you any speedup
2018,in fact here i bet its slower
2018,especially if theres io contention reading the data from disk
2018,ok im running single threaded now its still going you want me to post the error i eventually get
2018,user has joined the channel
2018,no thats ok
2018,and you dont need to run single threaded either
2018,i now understand why it died slightly_smiling_face
2018,and im not worried
2018,btw
2018,corentin cadiou has been working recently on making constructing the octree a lot faster
2018,like 2030x faster
2018,if you switch the development version of yt you might get some nice speedups
2018,this will be in yt 35
2018,ok great news
2018,ill pull the current dev version now
2018,thx
2018,i have codesnippet
2018,user has joined the channel
2019,ive been looking for an easy way to force the center color of a diverging colormap to map a conceptually meaningful value for instance here when plotting signed velocities not mapping white to zero make the figure somewhat misleading
2019,in matplotlib this can be achieved with egcodesnippetimport matplotlibpyplot as pltfrom matplotlibcolors import divergingnormpltcontourfx y z normdivergingnormvcenter00 cmaprwbcodesnippet
2019,but im falling to grasp how that would be passed down to yt is the api there any information on this would help slightly_smiling_face
2019,i usually set zlim to of maxminval maxval
2019,i think at one point we talked about having a way of indicating whether a field can have a zero point and then automagically choosing a diverging colormap with the diverging point set to the zero value
2019,i think right now though youd need to poke at the matplotlib figure that your sliceplot wraps
2019,if you wanted to have full control
2019,alright thanks guys if that discussion is ever revived im interested in contributing meanwhile ill go by users solution
2019,user has joined the channel
2019,guys i dont understand how to download yt on my macbook the yt help thing keeps returning bash yt command not found
2019,im using terminal
2019,i know this is a pretty basic question
2019,hi how did you install yt in the first place
2019,i just typed in pip install yt user onto terminal
2019,maybe you already found that page but if not hyperlink should help you
2019,i am a h u g e beginner this is for my university project
2019,no worries we all started as beginners at some point wink
2019,slightly_smiling_face
2019,what does codesnippet returns
2019,351
2019,great so you got it installed it is just missing from your path
2019,ok what does that mean because i read it everywhere
2019,let me answer in a thread to prevent clogging the channel
2019,ok sounds good
2019,when youre typing commands in a terminal they are looked for in a set of different directories
2019,ok
2019,the list of directories that will be used to search commands is stored in the codesnippet variable try codesnippet to see its content
2019,whatever is in one of these directories you can execute in your case you installed codesnippet but the script is not in any of the directories of your codesnippet
2019,is this what i was supposed to do
2019,no echo path
2019,its casesensitive slightly_smiling_face
2019,which pip might also be helpful
2019,
2019,whats the output of which pip
2019,also you can copypaste this stuff you dont need to uplaod screenshots slightly_smiling_face
2019,oh right lol
2019,
2019,last one
2019,and how did you install python in the first place
2019,or is it the version of python that shipped with the os
2019,i think all i did was install pip
2019,and then i think python came with it
2019,rly not sure
2019,ok so the place that pip puts executable binaries isnt in your path and it needs to be
2019,im just not sure where that is on your system
2019,can you do pip uninstall yt
2019,then pip install yt
2019,done
2019,and copypaste all of the output from that command into hyperlink
2019,and then share the gist here
2019,error could not install packages due to an environmenterror errno 13 permission denied librarypython27sitepackagesytconsider using the codesnippet option or check the permissions
2019,oh ok
2019,i bet you did user
2019,so i got this the first time i tried to install anything and then i did the user option
2019,yep
2019,and now im confused
2019,so you need to add localbin to your path
2019,how do i do this
2019,sorry
2019,whats the output of codesnippet
2019,binbash
2019,if i may i would suggest using anaconda since the python version kriti is using seems to be 27 which will not be supported soon
2019,yeah i would as well
2019,yeah it keeps saying that on my pip
2019,is it possible to use yt through the online jupyter notebook
2019,
2019,yes but youll still need to update your path if you want it to work with your current python
2019,do you know how to use a text editor
2019,youll need to open your codesnippet file and then add a line that looks like this to the bottom
2019,codesnippetexport path homelocalbinpathcodesnippet
2019,i sort of know how to use a text editor
2019,id also strongly encourage you to go through the software carpentry lessons on the unix shell
2019,hyperlink
2019,another way to do this would be to install the anaconda python distribution
2019,the installation process for that will update your path for you
2019,ok
2019,is that just another pip install
2019,no its a separate python distribution you can download the installer here
2019,hyperlink
2019,id suggest installing the python 37 version
2019,ok awesome
2019,am reading this unix shell thing now
2019,once you have that installed you can get the latest version of yt by doing codesnippet
2019,yes going through that lesson and the python lesson would be a very good idea for you given your level of experience
2019,maybe the git lesson too
2019,good luck
2019,thank you so much
2019,there is more than one python lesson published on the carpentries pages i have heard that the gapminder lesson is generally a bit more approachable than the inflammation lesson if you plan on checking it out
2019,hello yt world
2019,im reading in a dmonly enzo output that gives the following error
2019,
2019,note that the task im trying to do is very ordinary boiled down to eliminate any extraneous function calls
2019,the issue occurs at the step within grid_geometry_handlerpy where the list of grid names enzogrid_ is sorted
2019,from examining that list im not able to see anything wrong with it and my installation of yt successfully opens a lot of other outputs that ive created over the years here is the output in question hyperlink
2019,i think user ran into and fixed this a little bit ago which version of yt are you on user
2019,341 perhaps fixed in 35
2019,yeah i think this is hyperlink that said it looks like the fix didnt make it into 350
2019,were pretty overdue for a 351 i should probably get that set up
2019,but for now you can run yt from the master branch hyperlink to load these data
2019,oh wait that might be wrong the fix that was actually accepted was hyperlink
2019,ah yeah and that did make it into 350 so yeah updating to the latest yt release should fix your issue
2019,in general with any yt issue updating and seeing if the latest version has a fix is always worth a try slightly_smiling_face
2019,corner case is a polite way of saying wtf are you doing but i am glad to report that the corner case im using was ultimately derived from users own ic scripts
2019,and i just did a fresh update to 35 on my other machine where i install from conda and its fixed
2019,so all good
2019,user the situation where this pops up is a rather strange one its a situation of a dark matter only simulation in which there is an amr grid with no particles in this case the grid object doesnt get written to disk at all because there is no gas information to save its only when i was doing the runs like youre doing now that i ever encountered this hence why it only recently got fixed
2018,hey is there a way to do a deposition onto particles eg create a new particle field that would contain the density of the cell containing the particle in the case of an amr dataset
2018,i know i can always find the value in the cell using codesnippet but it is extremely slow for a large number of particles
2018,hm yeah thats probably what i would have done as well to create a new particle dataset theres likely a better way im unaware of
2018,hyperlink this almost does what you want i think youd need to write a new deposit operation
2018,thanks im just a bit lost about the signature of the codesnippet function
2018,is there a way to access the data stored in the amr structure from there
2018,no for ramses data i think it would be processed oct by oct
2018,so you only get information about the oct youre in
2018,ok but then is there a way to quickly get say the density of each cell in the oct
2018,nope it looks like codesnippet is specifically hacked in there for the codesnippet deposit operation i think youd need to modify the signature of codesnippet to accept an npfloat64_t that can optionally hold field values
2018,is there somewhere i could read to know to get the field values from eg hyperlink
2018,you mean you want to know where codesnippet is getting called from
2018,im just a bit lost in all the yt internal machineryif i understand correctly the correct way to deposit field values onto the particles is to modify codesnippet so that is passes the relevant field value to the codesnippet function that is overloaded for each subclass of codesnippet
2018,however i dont know how to actually get the field values
2018,yeah theres definitely a couple levels of indirection here
2018,ill take a look
2018,to get an idea of how the flow control works you can take a look at the derived fields defined in codesnippet in codesnippet
2018,then look at the codesnippet method of both codesnippet and codesnippet
2018,codesnippet gets called in codesnippet
2018,codesnippet acts like a yt data object you can get field values from it
2018,the only thing is youre also going to need to get this working for block amr data which shouldnt be too much harder
2018,if you want to upstream it anyway which would be very much appreciated it sounds like useful functionality
2018,i need to drive to work so ill be a little while before i can respond hope that provides some context
2019,hi folks im trying to do a projection through a large unigrid dataset 40963 and running into outofmemory issues
2019,this dataset has one single precision variable in it so the data takes up 275 gb
2019,im running it on 16 mpi tasks 1 task per node and each node has 128 gb of ram
2019,so 2 tb total memory to work with
2019,it runs out of memory during this part of the projection
2019,
2019,in the codesnippet method of codesnippet
2019,turning the log level to codesnippet the memory usage reported is 68 gigs per task which should fit
2019,
2019,i verified that all the task report less than 70 gb
2019,i think that this is memory that the python garbage collector thinks is in use and wouldnt include any mallocing that might happen at the cython level
2019,if i use the codesnippet tool on cori that shows the max memory used per task it does show that the usage goes up to over 128 gb on task 1
2019,any advice on how to debug this
2019,even if the data is getting promoted to double internally that seems like a lot of memory usage
2019,could be a memory leak
2019,how much memory does the python garbage collector say its tracking
2019,it looks to me like all the tasks have 70 gb
2019,how are you measuring that
2019,codesnippet
2019,which does this
2019,sorry where does that come from
2019,
2019,ytfuncspy
2019,ah ok so that is total memory used according to the os
2019,but you said one task exceeds that
2019,the outcome of codesnippet gets reported to the debug log every time a chunk is added to the tree in those logs i never see any usage go over 70 gb
2019,i see so something transient might be happening
2019,so definitely the data are getting promoted to double precision
2019,yt doesnt keep data in single precision like you seem to be expecting it would be nice if it could but it doesnt
2019,i would offhand think that this operation shouldnt need a huge amount of ram since its a loop over chunks
2019,and each chunk is independent
2019,do you have any idea where the memory usage is going
2019,running under tracemalloc might be instructive
2019,you can also use a tool like objgraph to find what python objects use the most memory although that wont see memory thats allocated in c
2019,user or user might have other ideas
2019,how many grids in the dataset
2019,or is it one huge grid
2019,the grids are 1283
2019,in principle id think the operation could be done with 128409640968 bytes 17 gb total
2019,clearly its not slightly_smiling_face
2019,unfortunately these sorts of issues are often hard to debug in python
2019,a quick and dirty hack would be to add a call to codesnippet in the problematic loop
2019,i doubt that will fix anything but its a quick thing to check
2019,it would be interesting to see what objgraph says about the state of the heap inside that loop
2019,it could be that were caching something for speed and thats causing issues here
2019,i dont have any concrete suggestions unfortunately i dont know enough about the details of how the projection works at the c level to be helpful thats more a matt question
2019,i guess try again with more ram if you dont have the appetite to dive into debugging this
2019,thats an option
2019,user it should be able to be but right now an issue is that its caching the masks
2019,i would guess that is currently theb iggest and most problematic issue
2019,masks ires icoords
2019,one thing it that the the memory usage reported by codesnippet and that reported by the codesnippet tool which is a slurm thing dont correspond
2019,user thanks for chiming in those are per cell quantities on each grid
2019,yup
2019,you could try commenting out the decorators that cache them and see if that helps
2019,grep for codesnippet
2019,dunno offhand if everything will explode if you turn off those caches
2019,user thanks ill try that
2019,more specifically instead of commenting it out replace it with codesnippet
2019,it looks to me like a large spike in memory usage happens here
2019,
2019,ie in between the start and the end of that function which gets called on each proc the memory usage jumps from 4 gb to 82 gb max over all procs
2019,so this is grid metadata
2019,ah yeah i bet its ires icoords and masks
2019,codesnippet in particular needs those i believe
2019,this is with the codesnippet decorator changed fwiw
2019,does this actually need to be done in the case that the dobj is all_data
2019,i think not for this dataset unless there are psuedogrids that are fully masked
2019,but if all the grids are unmasked then no we dont need to do this
2019,ah ok so its not the caches i was worried about then its something else
2019,it would be nice to find out where the bulk of the allocations are happening
2019,tracemalloc might tell you that
2019,it is doing it but it should not have to especially for a unigrid datasdet
2019,user and i are in my office talking about this use case right now and where it fails
2018,hey britton i think you have the right idea of what im trying to do but i dont think that you should commit development time to it at this point ill experiment around with a few things and get back to you if i need more help thanks
2020,the problem turned out to be that i added units _before_ using codesnippet which meant that the field produced a codesnippet instead of a codesnippet the error went away when i simply added the units by multiplying the symbolic units to the output of codesnippet
2020,well done thanks for the feedback
2019,hi folks quick question if i generate a sphere data object in a cosmological simulation eg around a galaxy and then make a phase plot of radial velocities are those radial velocities calculated using the raw velocity values in the simulation or is the mean velocity of the sphere weighted by baryon or dark matter mass in some way perhaps used instead
2019,i very much hope its the latter but one of my students is seeing some odd behavior that makes me suspect the former confused
2019,hi user you have to set the codesnippet field parameter by hand otherwise its 0 by default
2019,eg
2019,codesnippetsp dsspherec radiusvx spmeanvelocity_x weightdensityvy spmeanvelocity_y weightdensityvz spmeanvelocity_z weightdensityspset_field_parameterbulk_velocity vx vy vzcodesnippet
2019,oops
2019,let me edit
2019,aha
2019,that is extremely useful thank you
2018,shouldnt the results of codesnippet be the same as codesnippet
2018,this is what i expected but i am finding this to not be true
2018,i think based on my reading of ytep 3 this should also be true hyperlink
2018,im looking through the code to see what is going on but not sure what is up
2018,isnt h p 1 plus 1
2018,yeah
2018,sorry misread
2018,you werent asking that
2018,im looking for the mass fraction of h ii
2018,i thought it was over the total density
2018,rather than neutral
2018,oh youre right
2018,in this instance im misspeaking
2018,but i get the same results when i do this with nuclei density
2018,one sec
2018,codesnippet codesnippet
2018,codesnippet
2018,codesnippet
2018,again it seems like these should be the same
2018,but maybe im just missing something
2018,its the same if i replace codesnippet with the sum of the codesnippet and codesnippet number densities
2018,rather the same mismatch occurs if i swap the nuclei density with the sum of the two species number densities
2018,theres helium in your sim right
2018,yup
2018,im just using codesnippet to test this out
2018,i guess i need you to tell me what the numbers should be
2018,because they kind of match up with my expectations
2018,my issue isnt so much that 075 is better than 099
2018,its that those two calculations should be giving the same values
2018,i think
2018,one is over total the other over just h
2018,oh
2018,so youre saying the codesnippet is the total h ii out of the entire density field
2018,oh i guess i naively would have thought that h_p1_fraction was just the ionization fraction of the gasie the h ii out of the hydrogen density
2018,thats how we do it in trident
2018,i hope we arent making bad assumptions using that info
2018,hmmmm
2018,but ill double check what youre saying that may make sense at explaining these numbers
2018,yup codesnippet is mass fraction out of total density
2018,yeah confirmed
2018,interesting
2018,ok that resolves my confusion about this now i just have to make sure trident isnt going haywire on that
2018,oh my bad we create an codesnippet field
2018,ok ok sorry for the noise thanks for the help in understanding this user much appreciated
2018,hooray everyone is okay
2018,slightly_smiling_face
2020,ah ok thats certainly good to know smile i still think you stumbled across some gatherscatter disagreements so still good to do some digging
2020,user has joined the channel
2020,hi all is add_volume_weighted_smoothed_field only for particles is there a way to smooth a field for griddata to make the grid less obvious
2020,there are a couple of ways to remesh grid data such as codesnippet codesnippet or codesnippet that latter is probably what you are looking for
2019,user oh weird let me check into that it may be that we dont special case for jpg just png and pdf
2019,user so we use the codesnippet for anything that isnt postscript or pdf looks like the routine is just to see if its asked for png pdf eps ps and if not it uses agg which may or may not do the right thing with jpg
2019,user so should i create a new issue for this
2019,user yup
2019,user i will do that later today
2019,thanks
2019,user i created two issueshyperlinkandhyperlink
2019,thanks
2019,sure seems fine prs welcome slightly_smiling_face
2020,is the cic or nearest deposition method for particle fields working correctly it appears to be amplifying all my velocities by a factor of 104
2020,user interesting is it exactly 104
2020,sounds suspiciously like a units bug
2020,if you can make a short script demonstrating the issue preferably using one of the public datasets on hyperlink that would clarify things
2020,also what yt version is this
2020,its hard to tell which values in the star field correspond to which values in the deposit field but when i make a profile plot of deposit star_cic_velocity_cylindrical_theta for example the velocities come out on the order of 104 higher than what im expecting them to be
2020,sorry this is so dumb but how do i check the yt version i tried just typing in yt version but it said invalid syntax on version
2020,codesnippet
2020,oh this is a profile
2020,i bet you are plotting the sum of the field and not the average
2020,what does the codesnippet call look like
2020,or however youre creating the profile object
2020,i guess with codesnippet maybe
2020,351
2020,eg maybe codesnippet is set to codesnippet
2020,another way to to check if the actual field values are correct is to make a plot of that field or to print out the raw field values with a data object
2020,sorry make a codesnippet specifically
2020,im using profile plotcodesnippetdsadd_deposited_particle_fieldstar particle_velocity_cylindrical_theta methodcic out deposit star_cic_velocity_cylindrical_thetacheck1 ytprofileplotsphere radius star_cic_velocity_cylindrical_theta n_bins 256 weight_fieldnone accumulationfalse codesnippet
2020,yeah codesnippet means that the profile is the sum of the field in each bin
2020,hyperlink
2020,if you want an average than codesnippet is what you want
2020,and i get this which really shouldnt be negative but whatever
2020,so i tried doing weight_fieldstar_mass
2020,often for amr data thats not the most sensible thing though which is why the default weight field is codesnippet
2020,you could do codesnippet
2020,now ive checked the star_mass profile and it is definitely correct when i use accumulation then it sums up to exactly the value i have in the catalogs
2020,and this is what happens
2020,
2020,which was even more depressing
2020,here is the accumulated and non accumulated star mass profiles for the galaxy using deposit star_mass
2020,whats wrong with that plot
2020,well here are the star mass profile plots
2020,
2020,this is non accumulated
2020,ok
2020,this is accumulated
2020,theres really nothing that should be causing the cylindrical velocity to fly up and down like that at the beginning but even if we just ignore that and look at the rest of the plot more zoomed in it looks like this
2020,
2020,this is just chopping off anything before r1kpc
2020,so youre worried about that dip at 2 kpc
2020,the order of magnitude is still too high
2020,well the whole profile looks wrong
2020,can you make a codesnippet of this field
2020,user whatre you weighting it with and if youre doing a profile you may not need to use the cic deposited fields maybe i missed above why youre doing it but you can profile particles directly
2020,yeah you can directly profile the particle fields too
2020,no need to deposit
2020,i was weighting it with deposit star_mass
2020,eg you can profile with codesnippet as the x field
2020,you guys
2020,really
2020,yup
2020,oh but will particle radius give me the averaged quantity over radial bins
2020,thats what i was wondering about using that
2020,i dont quite understand that question
2020,sorry badly worded
2020,so im trying to create the profile of the cylindrical velocity of the stars as a function of radius i would like to compare this to my profiles of the cylindrical velocity of the gas as a function of radius and the way that ytcreate_profile has done the gas profile is that it has taken a series of radial bins centred on my galaxy and averaged the cylindrical velocity of the gas in each radial binmy concern is that creating a profile of the cylindrical velocity of the stars as a function of particle_radius will not create the radial bins as with the gas andor will not average the star cylindrical velocity over each radial bin as i have with the gas
2020,it would
2020,rather it will create a plot of each star cylindrical velocity plotted in line with that stars particle radius
2020,it would make bins in codesnippet
2020,every particle that falls in between 11 and 12 kpc in its codesnippet field would go into one bin
2020,say for example
2020,you can think of yts profiles as a fancy histogram
2020,in this case youre making this histogram using codesnippet as the bin field
2020,from yts perspective this is no different than using codesnippet as the bin field the actual histogramming process proceeds identically
2020,i see
2020,i think i was just confusing myself because i wasnt sure how particle_radius was organised
2020,you can take a look at all these fields just by accessing your codesnippet data object
2020,like is each element in that field paired to its corresponding star properties
2020,eg codesnippet
2020,or codesnippet
2020,yes of course but how would i be able to tell if each radii corresponded to which star_mass element
2020,or whatever property
2020,im still not quite following what youre asking sorry
2020,sorry it doesnt matter
2020,ill just make the profile with the particle fields much simpler solution
2020,also for the codesnippet field keep in mind that field uses two diferent field paramters to define the coordinate system
2020,would love to know what was up with the deposition though as that is what ive spent my last 5 hours on
2020,but no worries if not
2020,and if youre not using the correct field parameters you may get junk answers for the field values
2020,it may be the field parameter issue i just pointed out
2020,eg you might have the wrong center or north vector
2020,ah so this actually leads me to another question about north vectors
2020,but first if i docodeblockwhere lets say that unit_l is the normalised angular momentum vector that ive extracted from the sphere
2020,is that different to north vector
2020,sorry its codesnippet
2020,as i thought this might explain why all my cylindrical velocities are coming out negative
2020,north_vector is the wrong term i was misremembering
2020,codesnippet is the correct name that should work assiming codesnippet is correct
2020,but definitely doublecheck that the answers make sense
2020,got it
2020,thanks for the help
2020,also keep in mind that weighting by the deposited star mass might not be the correct thing for your data eg that big dip at 2 kpc might be caused by a single cell that happens to have a lot of massive particles
2020,its easier to reason about this imo by looking at slices or raw field values before binning and averaging
2020,i see
2020,what if i was just doing a profile of the particle fields
2020,then it would be ok
2020,that should be less noisy
2020,or perhaps particle_ones is my best bet
2020,yeah definitely compare with particle_ones
2020,cool
2020,also happy to help out in the future but notice how in this discussion we initially thought it was a units bug but it ended up being a usage issue
2020,its much easier to have concrete discussions about code if we all have a code sample we can run locally and think about
2020,my guess about it being a units issue was just a guess and it turned out to be wrong
2020,whereas if we had a code example to look at i would have immediately spotted that you were making a profile with weight_fieldnone
2020,it can sometimes be annoying to make a runnable example when asking a question like that
2020,but i think its less annoying in the end for everyone if you try to do that
2020,anyway good luck with your research slightly_smiling_face
2020,of course i understand next time will do slightly_smiling_face
2018,user has joined the channel
2018,two hopefully quick questions about getting my datasets to work better with yt
2018,how do i get yt to recognize my vector fields im loading using load_uniform_grid right now and it doesnt catch any of them besides magnetic_field_xyz ive tried messing around with create_vector_fields and create_vector_fluid_fields but i think im missing a step
2018,is there a way to override the default settings for field labels ideally id like to get ions labelled like o instead of oii without relabelling all of my plots by hand
2018,for the first one no not really i think that would require adding a new keyword argument to load_uniform_grid that tells yt that certain fields are vector fields i can point you at the lowlevel code that handles vector fields
2018,the reason it works for magnetic fields is because theres already special handling for velocity and magnetic fields
2018,for the second one i think the only way to do it right now is to add a bunch of derived fields that define aliases to your species fields
2018,i also think that if you load the species fields with the names yt expects for species itll work
2018,i think getting proper display names working with the stream frontend would also be something thats worth fixing
2018,again perhaps with another keyword argument to load_uniform_grid and friends
2018,oh so the field names work for the most part are displayed nicely but theyre in the oii oiii form rather than the o o form
2018,so it was more a domain context switching question i guess
2018,yeah i agree thats something that would eventually be covered by the domain context system
2018,having a way to switch the display names between those two types of notation would also be useful
2018,you can see how that is set up in codesnippet
2018,maybe we could add codesnippet or something like that that toggles between those two settings
2018,cool ill take a look at that and maybe see about adding a setting
2018,just didnt want to reinvent the wheel
2018,re vector fields im cool with using the low level settings until i eventually build a proper frontend but i think im just doing it wrong or in the wrong order it never seems to update the dsderived_field_list with the things i want
2018,i mean that if the names arent exactly magnetic_field_xyz or velocity_xyz yt just fundamentally wont see them as vector fields
2018,we need some what of indicating to the lowlevel machinery that some of the fields are actually vector fields
2018,actually sorry
2018,are you passing in 2d arrays for the vector fields
2018,or three 1d arrays
2018,3 1d arrays that are all things like o2_p1_velocity_x
2018,i also tried setting them as different fluid types like o2_p1 velocity_x but was still having trouble
2018,and you want yt to generate the derived fields for those vector fields like o2_p1_velocity_magnitude
2018,er i guess they arent 1d arrays theyre 3d
2018,yeah or o2_p1_radial_velocity if i make a sphere
2018,right now im doing it all by setting up derived fields that duplicate the built in ones
2018,so the reason it works for velocity and magnetic fields is these two lines
2018,hyperlink
2018,a super hacky way to do it would be to add lines after that for your species velocities
2018,i guess we could also pass in a list of codesnippet to codesnippet to also make the derived fields for
2018,does yt generate fields for the components of the velocities already
2018,i dont remember offhand if we added support to the stream frontend for that
2018,i know we do it in the particle frontends already
2018,im not sure exactly what you mean
2018,so you pass into codesnippet a 3d array with a field name like codesnippet
2018,yup
2018,if so im asking whether you can access codesnippet already
2018,oh no no sorry
2018,i pass in o2_p1_velocity_x y and z
2018,same with magnetic_field_x as an nxnxn array
2018,ahhhhh i see
2018,so one way to do this would be in the stream frontend to look for group of fields that might be the components of a vector field
2018,and automatically say ah they passed in codesnippet
2018,so therefore codesnippet is a vector field and we should treat it as such and generate the derived fields for that
2018,that might require modifying the codesnippet function i linked to earlier so it can optionally set up additional vector fields
2018,got it
2018,i guess another more general way to do this would be to define codesnippet that lets you setup the vector fields manually for a set up of three field components
2018,like codesnippet for example
2018,i think my plan for now will be to go the super hacky way and get that to work but eventually do sometime more general to make a valid scientific workflow tm
2018,thanks so much for your help
2018,np any time slightly_smiling_face
2018,user has joined the channel
2018,user has joined the channel
2018,question about fluxes and surfaces and derived fields im trying to get the flux in out of a series of surfaces of increasing radii so i have like codesnippetfor radius in radii surface dssurfacebig_sphere radius radius code_length gas_flux surfacecalculate_fluxvelocity_x velocity_y velocity_z densitycodesnippetwhere codesnippet is a sphere with radius larger than the ones in codesnippet but this returns the _net_ flux through that surface sooo
2018,
2018,and then do like codesnippet gas_flux_in surfacecalculate_fluxvelocity_x velocity_y velocity_z gas_density_in gas_flux_out surfacecalculate_fluxvelocity_x velocity_y velocity_z gas_density_outcodesnippetfor all the radii fine but
2018,this is what i get for codesnippet and codesnippet versus radius but shouldnt one be all positive and one all negative
2018,any guesses what im doing wrong im sure this is just me not understanding the derived fields andor surfaces andor fluxes correctly
2018,i dont see you doing anything obviously wrong
2018,damn upside_down_face
2018,it could be that the flux calculation happens using vertex centered data
2018,and when we interpolate to generate vertex centered versions of your derived field something goes wrong there
2018,tbh id approach this by modifying the yt source code
2018,one could imagine adding a keyword argument to calculate_flux to tell it to ignore values above or below a threshold
2018,related question what exactly does codesnippet do its in my loop but after everything is calculated because shrug
2018,why did you need to do that
2018,thats destroying the cached isocontour data yt created when it calculated the isocontour
2018,i have no idea laughing the comment in the code is codesnippet
2018,ok im surprised you need to do that maybe theres a bug somewhere
2018,its hard to say without an example demonstrating the behavior
2018,for your original question i think youd need to modify codesnippet
2018,ok so unrelated to the actual issue im having
2018,which does the actual isocontour flux calculation
2018,what does vertex centered data mean where would i find some documentation on that ive tried reading about th emarching cubes it but its all kind of hairy still
2018,normally data in yt are defined at the centers of cells
2018,but many operations isocontours volume rendering need data defined at the vertices of the cells ie the 6 faces
2018,generating vertex cenerted data means that yt does a trilinear interpolation to generate data at the cell faces based on the surrounding cell centered data
2018,your derived fields are defined at the cell center
2018,aaaaaah and the radial velocity is the velocity at the center of the cell
2018,yes ok still wild that itd cause that much of a difference given the large number of cells that go into the calculation
2018,thats just me guessing
2018,it may not be the real issue
2018,tbh all of this isocontour flux machinery is overboard for your use case
2018,but yt doesnt have a way to calculate fluxes across geometric objects
2018,it would be nice to have that though particularly spheres and disks
2018,yeah hence how we wound up with this it would be nice to have but i have no clue if id be up for writing it _ツ_
2018,doing marching cubes to generate a spherical surface is the part thats going overboard its also giving you an approximate answer when in principle we could get the exact answer
2018,ooh fair point
2018,i did a thing a while ago to do this for uniform resolution data for cylindrical surfaces
2018,to calculate the radial mass flux in a galaxy sim
2018,it would be a fun project to port that to yt
2018,anyway
2018,did you check that the radial_velocity is with respect to the center of your sphere
2018,i thought it was automatically
2018,i think so but easy enough to double check
2018,weve had bugs related to ensuring field parameters get passed around yt correctly in the past
2018,the few spot checks i have done look pretty reasonable but i havent dont the full subtract the bulk velocity from what the quivers plot but i think i know how to do that
2018,yeah id try dropping into a debugger in your field definition
2018,heres a trick
2018,is there a way to tell codesnippet which bv centerpoint to use
2018,add the following to a field definition and youll pop into a debugger when the field is first called with real data ie not during field detectioncodesnippetdef my_fieldfield data if fielddetector not in strtypedata import pdb pdbset_tracecodesnippet
2018,you need to set the codesnippet field parameter
2018,it respects codesnippet as well iirc
2018,im doing my testing in a notebook so i should have access to all the things it was unclear to me how to set the codesnippet for the radial_velocity since im adding the field to the full codesnippet but it doesnt make sense until theres actually a sphere or surface
2018,how are you generating the isocontour in the first place
2018,from codesnippet
2018,ah i see codesnippet
2018,codesnippet and then later codesnippet
2018,so youd do codesnippet
2018,and i do the eg codesnippet before codesnippet gets defined
2018,that should work
2018,in your field definition you should be able to say codesnippet and get the value you supplied back
2018,if not then theres a bug
2018,ill try it but it looks like its in there right
2018,if the field parameter isnt being used in the field definition that could explain the behavior youre seeing
2018,easy enough to check slightly_smiling_face
2018,im just guessing though slightly_smiling_face
2018,yep codesnippet gives the same thing as codesnippet thumbsup
2018,if you want you could make a runnable version of your script and then file an issue i can try to look closer at this in the next few days sometime
2018,if you decide to do that it helps if you either upload the dataset youre using or make use of one of the public datasets on hyperlink
2018,ok thanks may or may not happen im traveling between now and the enzo workshop next week airplane_departure airplane_arriving
2018,ok
2018,ill be at the enzo workshop
2018,i may also just try to hack together a spherical flux calcuation
2018,sure if you want you can take a look at hyperlink which does this for cylinders
2018,i also generated a covering grid so i didnt need to worry about amr
2019,hi i am wondering if i can rotate the figure by 90 degree in a slice plot
2019,this is a different issue than fixed by hyperlink
2019,yes ive opened an issue here if you want to follow user hyperlinkit seems to have more to do with data retrieval in yt as opposed to spectrum deposition once the ray is retrieved
2019,i got the issue but have to finish up teaching this week before i can really dig in unfortunately
2019,no worries user
2018,user has joined the channel
2020,maybe a silly question but is it possible to change the background of a volume rendering to white for example instead of the usual black ive looked into the codesnippet method which calls codesnippet but for the life of me i cant figure out how to change the background colour the codesnippet method accepts a kwarg called codesnippet which defaults to black but changing this to something else does nothing any thoughts on this or suggestions where i should look
2020,this has come up before and unfortunately because of the way the volume renderer works this is very hard or at least it wasnt obvious to me how to do it the last time i looked
2020,the reason the keyword is there is that it used to work but a major change to the volume renderer to do alpha compositing broke it and no one noticed
2020,hyperlink
2020,there are some possible workarounds in there
2020,aah i see
2020,thanks for clarifying this ill see if i can get one of the workarounds to do what i want
2018,yeah you would need to multiply codesnippet by the physical length of the ray
2018,does anyone know offhand why a codesnippet would through an valueerror setting an array element with a sequence compared to codesnippet which runs perfectly correct my x code units go from 1 to 1
2018,user i bet a bug report an issue and ill take a look
2018,okay will do thanks
2019,user ugh that is annoying i think it is possible but it would be via matplotlib and honestly i dont know how
2019,one solution altough very hacky and not satisfactory is to export in pdf and edit it using for example inkscape but if you have multiple plots thats really cumbersome
2019,user i generate a lot of plots from the data of many simulation studies so there are so many plots it wold be very useful if i can do that with just one line of codeuser if i want to use a particular matplotlib option do i have to implement an interface in yt like codesnippet which changes the range of colorbar
2019,user you can get access to the codesnippet object if you save it once or call codesnippet or something i cannot recall the fastest way it will be stored in something like codesnippet and codesnippet
2019,user thank you for your advice i think i have found the way to do that though it is not straight forward and not robust because colorbar tickers contain latex characters
2019,here is a plot in which s are added in front of the positive numbers
2019,hi everybody im trying to get yt40 working on nersc so i can use codesnippet to look at the agora galaxies hyperlinkit seems like yt40 cant be installed on login nodes on nersc as it tries to use mpi in a way that isnt allowed can i install it without testing mpi4py but in such a way that mpi will still be installed when i am allowed to use it on compute nodes later terminal output belowcodesnippetmyenv cstrawncori11ytgt pip install e deprecation python 27 will reach the end of its life on january 1st 2020 please upgrade your python as python 27 wont be maintained after that date a future version of pip will drop support for python 27obtaining fileglobalu2ccstrawnyt complete output from command python setuppy egg_info using openmp to compile parallel extensions running egg_info writing requirements to ytegginforequirestxt writing ytegginfopkginfo writing toplevel names to ytegginfotop_leveltxt writing dependency_links to ytegginfodependency_linkstxt writing entry points to ytegginfoentry_pointstxt mon feb 25 104758 2019 unknown fatal error in pmpi_init_thread other mpi error error stack mpir_init_thread537 mpid_init246 channel initialization failed mpid_init638 pmi2 init failed 1codesnippet
2019,so yt doesnt actually need the mpi functionality in cykdtree
2019,the easiest thing to do would probably be to manually disable the mpiparallel kdtree in cykdtrees setuppy
2019,i realize this is a pain point and ill hopefully have a fix for this soon
2019,user i was able to do it by filtering the list of arguments hyperlink
2019,ok
2019,i think ultimately it might make the most sense to vendor the bits of cykdtree we need into yt itself
2019,for a while there we were talking about making cyktree its own going concern
2019,and its not really
2019,user by manually disable the mpiparallel kdtree in cykdtrees setuppy do you mean changing the true here to falsecodesnippet cython_trace required for coverage and line_profiler remove for releaseif not release ext_optionsdefine_macros cython_trace 1ext_options_mpi copydeepcopyext_optionscompile_parallel trueif rtdflagcodesnippet
2019,i think thatll do it
2019,nope still hitting the error it was actually able to install cykdtree either way thats not where the problem was it just breaks on ytcamerons notebook hyperlink for installing sphviz says to install cykdtree from source before trying to install yt so i have that installed from a separate repo that went fine both before and after i changed the cykdtree setuppy file
2019,oh interesting
2019,i have no idea why thats happening
2019,yts setuppy shouldnt be invoking mpi
2019,can you do pip install v e to get more verbose output
2019,codesnippetmyenv cstrawncori11ytgt pip install v e deprecation python 27 will reach the end of its life on january 1st 2020 please upgrade your python as python 27 wont be maintained after that date a future version of pip will drop support for python 27created temporary directory tmppipephemwheelcachejnmja5created temporary directory tmppipreqtracker6phufocreated requirements tracker tmppipreqtracker6phufocreated temporary directory tmppipinstallxkhv1zobtaining fileglobalu2ccstrawnyt added fileglobalu2ccstrawnyt to build tracker tmppipreqtracker6phufo running setuppy pathglobalu2ccstrawnytsetuppy egg_info for package from fileglobalu2ccstrawnyt running command python setuppy egg_info using openmp to compile parallel extensions running egg_info writing requirements to ytegginforequirestxt writing ytegginfopkginfo writing toplevel names to ytegginfotop_leveltxt writing dependency_links to ytegginfodependency_linkstxt writing entry points to ytegginfoentry_pointstxt compiling ytutilitieslibparticle_kdtree_toolspyx because it depends on globalu2ccstrawncykdtreecykdtreekdtreepxd compiling ytutilitieslibpixelization_routinespyx because it depends on globalu2ccstrawncykdtreecykdtreekdtreepxd 12 cythonizing ytutilitieslibparticle_kdtree_toolspyx 22 cythonizing ytutilitieslibpixelization_routinespyx mon feb 25 114048 2019 unknown fatal error in pmpi_init_thread other mpi error error stack mpir_init_thread537 mpid_init246 channel initialization failed mpid_init638 pmi2 init failed 1cleaning upremoved fileglobalu2ccstrawnyt from build tracker tmppipreqtracker6phuforemoved build tracker tmppipreqtracker6phufocommand python setuppy egg_info failed with error code 6 in globalu2ccstrawnytexception informationtraceback most recent call last file globalhomesccstrawncondaenvsmyenvlibpython27sitepackagespip_internalclibase_commandpy line 179 in main status selfrunoptions args file globalhomesccstrawncondaenvsmyenvlibpython27sitepackagespip_internalcommandsinstallpy line 315 in run resolverresolverequirement_set file globalhomesccstrawncondaenvsmyenvlibpython27sitepackagespip_internalresolvepy line 131 in resolve self_resolve_onerequirement_set req file globalhomesccstrawncondaenvsmyenvlibpython27sitepackagespip_internalresolvepy line 294 in _resolve_one abstract_dist self_get_abstract_dist_forreq_to_install file globalhomesccstrawncondaenvsmyenvlibpython27sitepackagespip_internalresolvepy line 226 in _get_abstract_dist_for req selfrequire_hashes selfuse_user_site selffinder file globalhomesccstrawncondaenvsmyenvlibpython27sitepackagespip_internaloperationspreparepy line 382 in prepare_editable_requirement abstract_distprep_for_distfinder selfbuild_isolation file globalhomesccstrawncondaenvsmyenvlibpython27sitepackagespip_internaloperationspreparepy line 158 in prep_for_dist selfreqprepare_metadata file globalhomesccstrawncondaenvsmyenvlibpython27sitepackagespip_internalreqreq_installpy line 530 in prepare_metadata selfrun_egg_info file globalhomesccstrawncondaenvsmyenvlibpython27sitepackagespip_internalreqreq_installpy line 609 in run_egg_info command_descpython setuppy egg_info file globalhomesccstrawncondaenvsmyenvlibpython27sitepackagespip_internalutilsmiscpy line 761 in call_subprocess command_desc procreturncode cwd
2019,installationerror command python setuppy egg_info failed with error code 6 in globalu2ccstrawnytcodesnippet
2019,compiling pixelization_routinespyx triggered an mpi failure
2019,super weird
2019,maybe its the use of openmp
2019,i guess you could disable openmp in yts setuppy
2019,it also seems worth noting that while cykdtree would install ok actually calling codesnippet in a python terminal gave a similar error
2019,ah i see
2019,so yes it is the cykdtree parallel stuff
2019,when you turned it off earlier did you clean the installation
2019,eg git clean fxd
2019,that will delete the old installation you could then recompile
2019,yt doesnt use cykdtrees parallel kdtree stuff so you can just completely disable it
2019,oh okay that worked i hadnt done the git clean fxd so i guess it may have continued trying to use the parallel installation of cykdtree after i did that and reinstalled with parallel off it was able to install yt
2019,thanks
2019,ok great slightly_smiling_face
2019,user has joined the channel
2020,ive since tried again in a new environment and everything seemed to work im afraid im not sure what i did differently the second time around
2020,user the important thing is that its now working
2020,thanks for reporting back
2020,user has joined the channel
2019,hi now i can load the ramses data but there is a new issue when i try to add a field or make a plot the error is raise ytfilenotparseablefname i1ytutilitiesexceptionsytfilenotparseable error while parsing file
2019,there is no problem if i go back to yt 341
2019,hmm let me se if i can reproduce with that dataset you shared yesterday
2019,there was some reworking of how ramses outputs get parsed for yt 35 ping user
2019,ah yes i can reproduce it too
2019,user the line in the descriptor file its dying on looks like codesnippet
2019,its dying trying to deal with this regex hyperlink
2019,let me see
2019,the dataset is this one hyperlink
2019,5 gb zipped
2019,oh right the regexp is missing the backslash codesnippet
2019,where should that go
2019,the regexp should become something likecodesnippet var_desc_re recompilersssssscodesnippethyperlink
2019,instead of using codesnippet any alphanumeric character underscore codesnippet would match any character except white spaces
2019,seems to work slightly_smiling_face
2019,let me submit a pr
2019,user hyperlink does that look right
2019,user thank you for the reports please keep them coming slightly_smiling_face
2019,and sorry for the trouble and confusion we try to avoid breaking things but when we do its really great to hear about it
2019,user this should fix your bug hyperlink
2019,thanks for the quick fix corentin slightly_smiling_face
2019,always a pleasure
2019,great thank you all
2019,hi there should be another line var_desc_re recompilersdswsw in iopy reads the fluid data that line should also be replaced
2019,user hyperlink feel free to comment on github slightly_smiling_face
2019,hi im trying to load some codesnippet data it gets past the ytload ok but then when i try to do things it breakscodesnippetc dsfind_maxgasdensity1in_unitskpctraceback most recent call last file ltstdingt line 1 in ltmodulegt file volsciastrohomecjstrawnytytdata_objectsstatic_outputpy line 855 in find_max sourcequantitiesmax_locationfield file volsciastrohomecjstrawnytytdata_objectsderived_quantitiespy line 638 in __call__ rv supermaxlocation self__call__field sample_fields file volsciastrohomecjstrawnytytdata_objectsderived_quantitiespy line 594 in __call__ rv supersampleatmaxfieldvalues self__call__field sample_fields file volsciastrohomecjstrawnytytdata_objectsderived_quantitiespy line 75 in __call__ storesult selfprocess_chunkds args kwargs file volsciastrohomecjstrawnytytdata_objectsderived_quantitiespy line 603 in process_chunk if datafieldsize gt 0 file volsciastrohomecjstrawnytytdata_objectsdata_containerspy line 257 in __getitem__ selfget_dataf file volsciastrohomecjstrawnytytdata_objectsdata_containerspy line 1411 in get_data particles self self_current_chunk file volsciastrohomecjstrawnytytgeometrygeometry_handlerpy line 227 in _read_particle_fields fields_to_read file volsciastrohomecjstrawnytytutilitiesio_handlerpy line 218 in _read_particle_selection for field_r vals in self_read_particle_fieldschunks ptf selector file volsciastrohomecjstrawnytytfrontendstipsyiopy line 237 in _read_particle_fields tf self_fill_fieldsfield_list p hsml mask data_fileunboundlocalerror local variable hsml referenced before assignment codesnippeti went and checked out the source code and it indeed looks like that variable is never assigned id try to fix it myself but i have not idea what hsml is supposed to do can anyone explain
2019,it might be fixed in this recent pr hyperlink
2019,user could you try updating to yt40 tip and see if its solved
2019,oh ok thanks i did a codesnippet but i forgot to merge it into my fork first so i pulled before it came in thanks user
2017,user has joined the channel
2018,user has joined the channel
2018,user has joined the channel
2019,user has joined the channel
2018,user has joined the channel
2018,ive been doing stuff like thiscodesnippetwhere codesnippetis there a way for me to just grab all the codesnippet stuff then index into that with an integer ndarray and pull off the coordinates or such later
2018,i would like tocodesnippetdata dsall_datagas dataparttype0 some time latergas gasglist some time laterfuncgascoordinatescodesnippet
2018,nope
2018,not offhand anyway
2018,disappointed
2018,user so the issue is that we dont have great support for vector field parameters at the moment so during field detection we assume that field parameters are scalars
2018,there are a special set of whitelisted field parameters that do get set up as vectors during field detection but its all hardcoded in the field detection machinery
2018,as a workaround if you modify your script like this it does work
2018,codesnippet if isinstancedata fielddetector vec_a nparray0 0 1 elif datahas_field_parametervector_a vec_a dataget_field_parametervector_a else vec_a nparray0 0 1codesnippet
2018,where codesnippet is imported like this codesnippet
2018,sorry for the trouble ideally your script would work but i think in order for it to do so well need to change the field detector api to first make you register a default value for new field parameters that are unknown to yt
2018,thanks user this is very helpful ill give it a try soon
2019,thanks for responding i actually figured it out now im having trouble loadingvisualizing particle data
2019,yt has documentation here hyperlink sounds to me like you want the quickstart notebooks or the cookbook in the top bar
2019,thank you i will check this out
2020,hey yallim having problems with the codesnippet and the codesnippet fields in my gadgetowls snapshots the two fields have the exact same values from what i understand the codesnippet fields represent the neutral ion number densities right so codesnippet and codesnippet values should be equalnot sure why codesnippet and the codesnippet are equal but this doesnt seem to be right can someone confirm this thanks
2020,hello everyone i was hoping i could get some help herei am trying to put my cosmological simulation data onto a regular grid with sph smoothing using yt40dev0 but i consistently seem to be running into a problem with any simulation i try i have tested this on illustris and llustristng both high resolution and low resolution 75 mpch boxes eagle and some of my own arepobased simulations and for all of them the mean baryon density seems to come out too low compared to the critical density the factor off is of the order of 1z³ although not exactly which would imply that yt is converting the densities to physical ones but i am not feeding the redshift into load_particles so i do not understand how this is possiblehere is my script in this case running on the lowresolution tng1003 box snapshot 33 which is z 2codesnippetimport numpy as npimport h5pyfrom astropycosmology import flatlambdacdmfrom astropy import units as uimport ytsim tng1003 path to the simulation filessnap 33 snapshot numberextracting cosmology etcheader h5pyfilesimsnap_0d0hdf5snaprheaderattrsrs headerredshiftmaxchunks headernumfilespersnapshotl headerboxsizecosmo flatlambdacdmh0headerhubbleparam100om0headeromega0ob0headeromegabaryontcmb02725rhocrit_bar cosmocritical_densityrscosmoobrs critical_density in cgs unitsrhocrit_bar_simunits rhocrit_hyperlink1e10um_suncosmohukpccosmoh3 critical density in simulation unitsloading necessary parameters from hdf5 files into memoryposx posy posz dens m smolen for chunk in rangemaxchunks data h5pyfilesimsnap_0ddhdf5snapchunkr coords nparraydataparttype0coordinates density nparraydataparttype0density mass nparraydataparttype0masses posxappendcoords0 posyappendcoords1 poszappendcoords2 densappenddensity mappendmass if sim illustris1 or sim illustris3 smolenappendnparraydataparttype0smoothinglength elif sim tng1001 or sim tng1003 smolenappend34nppimassdensity13 posx nphstackposxastypefloat64posy nphstackposyastypefloat64posz nphstackposzastypefloat64dens nphstackdensastypefloat64m nphstackmastypefloat64smolen nphstacksmolenastypefloat64bbox nparray0l0l0l data dictdensity dens particle_position_x posx particle_position_y posy particle_position_z posz particle_mass m smoothing_length smolen ds ytload_particlesdatabboxbboxdsnum_neighbors 16dssph_smoothing_style gathern 600 number of gridcells per sideag dsarbitrary_griddsdomain_left_edgedsdomain_right_edgedimsnnnmesh_dens agiodensitycodesnippetnote that i am using ytload_particles instead of ytload because for the higher resolution simulations i need to split up the box to conserve memoryoverall the sph smoothing seems to be working fine just the units seem to be off after coming out of yt see attached image of the central slice in rhorho_critbhas anyone else noticed similar problems or does anyone see if im doing something wrong
2020,if i follow it looks like you are computing the physical baryon density at z2 using astropy unitsthen the image is doing the sph deposition in simulation units which is typically is comoving units halso just to note you calculate the baryon density in 1e10 msunh kpch3 is the simulation in kpc or mpc
2020,isnt the astropy critical density comoving its just 3h²8pig obindeed the simulations are in kpch
2020,hi user this is far from my expertise but i think i can answer a specific point in your question gt which would imply that yt is converting the densities to physical onesyes yt will _always_ convert known quantities such as density to physical units how it does so in this case with incomplete data i dont know but id guess that some default assumption about the redshift is done internally
2020,thank for your replies its still surprising then that it manages to get the redshift roughly correct every time i tried this with snapshots at z 2 z 3 and z 20 and the outcoming mean density is always off by a factor of the order of 1z³ but not exactlyfor reference i get a factor of 23 for z 2 a factor 556 for z 3 and a factor 9290 for z 20
2020,im not familiar with astropy but if astropy was returning the physical baryon density would that explain the difference
2020,assuming the simulations output comoving kpc
2020,if i manually calculate 3h²8pig ob i get the same answer as atropy and that should be comoving so i dont think it would explain the difference also note that it is not exactly 1z³ so it could just be a coincidence
2020,ok just checking
2020,i think this is the part of the source code youd want to inspect hyperlink
2020,no problem i have been thinking and checking the same for the past few days sweat_smile really appreciate any help i can get
2020,is yt reporting the units of codesnippet as code_masscode_length3
2020,yes it is
2020,what happens if you set codesnippet before you deposit
2020,does not seem to make a difference
2020,hi user thanks for moving the discussion over here im pretty sure this is because your data is not tracking the ionization states of the elements so in essence what is listed as codesnippet is in reality the codesnippet ie the total density of all ions of that element are there specific elements where you track the individual ion species i think you said h but are there others as well
2020,hi user thanks a lot for your response the simulation tracks h i he i and he ii ion fractions individuallyfor metals only the total metal mass fractions are tracked and not individual ionization states for different species
2020,that is strange
2020,ok i think i know why the normalization didnt work i think thats a bug in yt not sure if that relates to the whole problem you find though
2020,indeed curiousi guess normally people define the overdensity by simply taking the mean of the entire simulation so thats why nobody notices one other unlikely thing i can think of is that the densities given by simulations are actually in physical kpch instead of comoving as their specifications say
2020,it could be that i do think this could be a yt issue though i can make a pull request with a potential fix i think it could be the normalization as i dont codesnippet is doing anything right now
2020,in fact i dont think the backend is even switching to gather
2020,do you see a progress bar when you deposit with the description codesnippet
2020,yes it showscodeblock
2020,ah that means its doing both a scatter and a normalization i think i know why ill make a pr now
2020,alright thanks for looking into it
2020,using this pr hyperlink and the codesnippet should fix the issue i hope
2020,stupid question but how do i install the pr with pip sweat_smile never done this before
2020,my git and pip foo is subpar im afraid i assume user user or user will know though
2020,in looking through codesnippet there is a section that sets up these ionic fields look for the codesnippet loop there should be fields available called codesnippet and codesnippet do these exist when you load your dataset
2020,will be in an out today but will check back
2020,here you go
2020,great thank youit definitely makes a difference for one it runs much faster nowtheres no more status bar instead it displayscodeblockthe resulting image looks better valuewise but now the mean is about a factor 120 too high correct me if im wrong but it looks more like scatter doesnt it there are a lot of completely empty cells and overall the image looks much less smooth
2020,that is strange locally i get codesnippet
2020,it tells me it is doing a codesnippet
2020,also thanks a lot user i learnt something there stuck_out_tongue
2020,youre welcome slightly_smiling_face
2020,i think youve discovered some fishy behaviour user i think this will require a bit of digging
2020,alright i was affraid of thatlet me know if there is anything you need me to contribute
2020,ah so i ended up manually changing the code in my installed version maybe i looked at it the wrong way but in the pr it looks like you changed codesnippet to codesnippet codesnippet to codesnippet and codesnippet to codesnippetif i do keep the false in codesnippet then now things seem to be gather smoothing again as the status bar came back and it took much longer to allocate the kdtreecodeblockand things took much longer againthe result is a density field whos mean is 06 of the critical density and whose values by eye look much better
2020,ill test it on the other sims as well just to make sure
2020,ah yeah i think there is an issue with the frontends so if the frontend inherits from sphfrontend eg if you do a ytload on a gadget dataset then it should codesnippet but if you do what you do and make a yt dataset that doesnt know it holds sph data then it should not have an codesnippet i need to fix this and make it consistent across all datasetsi also suspected the result without normalisation would be better i think that it is something we need to look at in yt i think the normalization is redundant given how we deposit so we end up over normalizing
2020,thanks a lot for digging into this your feedback has been really useful in diagnosing what is going wrong internally
2020,thank you for helping figure it out slightly_smiling_face i have been scratching my head over this problem for two weeks so glad to see it working
2020,feel free to open an issue on the yt github about getting strange results with the normalizationtrue or i can do it if you prefer slightly_smiling_face
2020,while running hyperlink
2020,for the isolatedgalaxy dataset
2020,galaxy0030
2020,i am getting a runtime error in scshow
2020,could somebody help
2020,volume renderring tutorialcodesnippetimport yt import numpy as npfrom ytvisualizationvolume_renderingtransfer_function_helper import transferfunctionhelperfrom ytvisualizationvolume_renderingapi import scene volumesourcecodesnippetcodesnippetdsgalaxy0030codesnippet1codesnippetsc ytcreate_scenedsyt info 20200423 234538473 setting default field to gas densitycodesnippetcodesnippetprintscltscene objectgtsources source_00 ltvolume sourcegtytregion galaxy0030 center1543e24 1543e24 1543e24 cm left_edge0 0 0 cm right_edge3086e24 3086e24 3086e24 cm transfer_functionnonecamera ltcamera objectgtposition1 1 1 code_lengthfocus05 05 05 code_lengthnorth_vector 081649658 040824829 040824829width15 15 15 code_lengthlightnoneresolution512 512lens ltlens objectgtlens_typeplaneparallelviewpoint86602533679714 86602533679714 86602533679714 code_lengthcodesnippetprintscget_sourceltvolume sourcegtytregion galaxy0030 center1543e24 1543e24 1543e24 cm left_edge0 0 0 cm right_edge3086e24 3086e24 3086e24 cm transfer_functionnone
2020,codesnippetscshowyt info 20200423 234005922 rendering scene can take a whileyt info 20200423 234005924 creating volumeyt info 20200423 234031386 creating transfer functionyt info 20200423 234031387 calculating data bounds this may take a while set the transferfunctionhelperbounds to avoid thisruntimeerror traceback most recent call lastesoftwaresanacondalibsitepackagesipythoncoreformatterspy in __call__self obj 343 method get_real_methodobj selfprint_method 344 if method is not nonegt 345 return method 346 return none 347 elseesoftwaresanacondalibsitepackagesytvisualizationvolume_renderingscenepy in _repr_png_self 926 png self_last_renderwrite_pngfilenamenone 927 sigma_clipself_sigma_clipgt 928 backgroundblack 929 self_sigma_clip none 930 return pngesoftwaresanacondalibsitepackagesytdata_objectsimage_arraypy in write_pngself filename sigma_clip background rescale clip_ratio 287 288 if rescalegt 289 scaled selfrescaleinlinefalse 290 else 291 scaled selfesoftwaresanacondalibsitepackagesytdata_objectsimage_arraypy in rescaleself cmax amax inline 240 npmultiplyself 3 10amax out 3 241 gt 242 npclipout 00 10 out 243 return out 244 lt__array_function__ internalsgt in clipargs kwargsesoftwaresanacondalibsitepackagesnumpycorefromnumericpy in clipa a_min a_max out kwargs 2082 2083 gt 2084 return _wrapfunca clip a_min a_max outout kwargs 2085 2086 esoftwaresanacondalibsitepackagesnumpycorefromnumericpy in _wrapfuncobj method args kwds 59 60 trygt 61 return boundargs kwds 62 except typeerror 63 a typeerror occurs if the object does have such a method in itsesoftwaresanacondalibsitepackagesnumpycore_methodspy in _clipa min max out casting kwargs 130 else 131 return _clip_dep_invoke_with_castinggt 132 umclip a min max outout castingcasting kwargs 133 134 def _meana axisnone dtypenone outnone keepdimsfalseesoftwaresanacondalibsitepackagesnumpycore_methodspy in _clip_dep_invoke_with_castingufunc out casting args kwargs 83 try to deal with broken casting rules 84 trygt 85 return ufuncargs outout kwargs 86 except _exceptions_ufuncoutputcastingerror as e 87 numpy 1170 20190224esoftwaresanacondalibsitepackagesytunitsyt_arraypy in __array_ufunc__self ufunc method inputs kwargs 1399 raise runtimeerror 1400 support for the s ufunc with i inputs has not beengt 1401 added to ytarray strufunc leninputs 1402 if unit is none 1403 out_arr nparrayout_arr copyfalseruntimeerror support for the ltufunc clipgt ufunc with 3 inputs has not beenadded to ytarrayltscene objectgtsources source_00 ltvolume sourcegtytregion data0029 center196740872e26 196740872e26 196740872e26 cm left_edge0 0 0 cm right_edge393481744e26 393481744e26 393481744e26 cm transfer_functionnonecamera ltcamera objectgtposition1 1 1 code_lengthfocus05 05 05 code_lengthnorth_vector 081649658 040824829 040824829width15 15 15 code_lengthlightnoneresolution512 512lens ltlens objectgtlens_typeplaneparallelviewpoint86602533679714 86602533679714 86602533679714 code_lengthcodesnippet
2020,this is the error i am gettingbut in the volume rendering tutorial in documentation no such error was spotted with same code and same input data
2020,excuse me anybody knows how i can change the marker size in particleplot eg i would like to make a particle plot with a single particle the default maker size is too small to be seen
2020,hello i think you can try codesnippet but this might not be the best way
2020,ill see what i can do but i found another issue when testing it on eagle and illustrisin their case the smoothing length is given so i didnt estimate it by hand like i did for tng however it turns out that the density comes out much too low again for those two simulations note that for eagle i increased the number of nearest neighbors to 58 which is the number they mention in the simulation paperhowever when i determine the smoothing length from the density and mass like i did for tng the gridded density comes out fine againso i had a look at the values of the smoothing lengths when using the density and mass i get maximum smoothing lengths of 270 kpch but the values from eagle and illustris themselves can be as large as 3 mpchany idea why things could go so wrong with the smoothing lengths provided by the simulations themselves
2018,hi user im not sure if this answers your question but if the node youre looking for is codesnippet ie the first ancestor 2nd node of the first tree then its mass would be codesnippet or as well you could docodesnippetnode a0tree1nodemasscodesnippet
2018,im around all day if you want to talk this out
2018,hey user thanks for chiming in this isnt really what im looking forbut now that im thinking more about it i think i might be able to make it work will think about this a bit morein the meantime though what im really looking for is a way to go from the codesnippet interface to the root field interface in other words how do i get the location of the properties of codesnippet in your example above in aposition_x for example
2018,im still not quite sure what you mean by going from the node interface to the root field interface
2018,it may be possible for me to make the treenodebased interface work thoughwhat im trying to avoid is having to work on the halobyhalo level and instead copy over propertiesset indices treebytree wherever possible our existing codebase works with a structure where each halo is an entry in a set of arraylikes and there are index properties that allow you to move im looking to set those indices basically
2018,umm let me try to give a clearer example
2018,you want the field values for all nodes in a single tree expressed as an array is that right
2018,no more the other way around i want the indices of the field values for all the nodes in a single tree
2018,oh ok i think i got it one sec
2018,codesnippetnode a1ancestor nodeancestors0printancestortreenode343ancestorprintaposition_x343printancestorposition_x0675810317993164 unitary06937116980552673 unitarycodesnippet
2018,so here i have an ancestor which is treenode343 that 343 is the same as the codesnippet of the node ive found but its not an index and unfortunately it doesnt match with the codesnippet i get if i do codesnippet
2018,right codesnippet will just be the uids of the roots
2018,each node has a codesnippet attribute
2018,as illustrated herecodesnippetprintancestoruidprintancestoruid in auidprintancestoruid in auidastypeint343falsefalsecodesnippet
2018,so for examplecodesnippettid nparrayttreeid for t in a0treecodesnippet
2018,but as far as i can tell that is only valid _within_ the tree
2018,codesnippetnode a1ancestor nodeancestors0printancestortreeidnode a2ancestor nodeancestors0printancestortreeid11codesnippet
2018,right thats local to the tree
2018,so i still cant use that to directly reference codesnippet
2018,yeah is there a nonlocal version of that
2018,right no unfortunately codesnippet will only ever give you the field values for the roots
2018,wait im not sure i understand thatif i do codesnippet i get a lot more than z 0
2018,yeah those are trees that had no further descendents past that redshift
2018,oooooh
2018,ok
2018,you see that frequently with rockstar
2018,hmm
2018,presumably trees that would get tied in with others that do go to z 0 via phantoms if consistent trees were run
2018,ok so i was misunderstanding what codesnippet was giving me
2018,if you run your rockstar catalogs through consistenttrees all of your trees go down to the final redshift i dont totally understand what happens to the rest of them
2018,ah i see
2018,yes im running into some issues with consistent trees unfortunately so im trying to work with the raw rockstar trees
2018,ok sounds like i may need to rethink how i was tackling this problem i may hit you up for more help later if thats ok but this did give me a couple ideas
2018,sure not a problem
2018,how do i get more pixels in a particleprojectionplot i set codesnippet but then yt still prints codesnippet so i think i set the wrong thing
2018,user i think theres a codesnippet argument
2018,window_size is the figure size in inches
2018,if you want to increase the resolution you can do codesnippet or whatever resolution you want
2018,ohhhhh thanks
2018,that sets the resolution of the image generated by the frb
2018,for the resolution of the image saved by codesnippet that depends on the figure size in inches and the dpi
2018,hm im dumping them into a pdf so i hope the matplotlib backend is just embedding the frb
2018,well see
2018,so if you do codesnippet codesnippet will be the resolution you specify in codesnippet
2018,but then when you save the plot you might also need to do codesnippet or some other high dpi to actually get a high resolution image saved to disk
2018,hope that was clear its a confusing subtlety that working with matplotlib introduces
2018,im trying what youre saying and things are happening
2018,i get two prints about splatting now though which is odd
2018,i can imagine why that is just didnt really expect it
2018,id need to see your script but the way the plot system works is that we try to delay pixelizing until you actually need it
2018,its possible theres a logic error there and were doing it twice unnecessarily in this case
2018,if you look inside yts plotting code thats what the codesnippet and codesnippet decorators are doing
2018,hyperlink
2018,gotta run to a meeting now
2018,thanks again for all your help
2018,would anyone be able to explain to me why if i am making a volume render doing codesnippetsc ytcreate_sceneds lens_typeperspective fielddensity sc_listappendsc source sc0codesnippetthen doing codesnippetsourcetfhset_fielddensity sourcetfhset_bounds016e312e3 sourcetfhset_logfalse sourcetfhbuild_transfer_function sourcetfhsetup_defaultcodesnippetgives me a visual but setting codesnippet leaves the resulting image of codesnippet blank
2018,user sadly the limits are confusing with this change the limits to be the logged vals
2018,so change codesnippet to their log values
2018,yup
2018,hi ytites i have a quick question
2018,is this documentation still correct regarding generic loading generic arrays hyperlink
2018,nowhere in there do you set units
2018,that example should probably be updated
2018,hyperlink is more uptodate
2018,oh awesome thank you
2018,if you file an issue about that someone will fix it before the next release although wed appreciate a pr that updates it of course slightly_smiling_face
2018,of course
2018,the reason im asking is that i have a couple of colleagues here who are dealing with plant biology data and want to do analysis of it
2018,its cat scans of plants basically represented as stacks of 2d images
2018,and so they have been rolling their own tools
2018,but feel there might be something better out there
2018,smile
2018,cool i hope yt is useful for them
2018,i think sam skillman did something similar with an animated gif of a succession of ct scan crosssections
2018,we spent the day in my data viz class talking about volume rendering isosurfaces etc and the astro grad students were pushing yt as a solution to many problems so the grad student doing the cat scan stuff came up afterward and was asking questions
2018,i seem to recall that as well
2018,anyway this is superuseful i will try to get them up and running thanks
2018,cool slightly_smiling_face
2018,yeah thats how id do that
2018,user i did it with some dicom images i got as well and it worked alrighty
2018,iirc sam even did it by stacking the animated gif of disapproving sam
2018,if i have a particlebased dataset eg fire and i want to get the angular momentum vector of a data object but only include the gas particles is there a way to do this easily i know that the derived quantity for calculating codesnippet has flags for codesnippet ie grid data and codesnippet presumably for dm particles but this does not allow for subspecifying the gas particles in an allparticle frontend like gizmo
2018,now that we can do codesnippet with the demeshening im trying to figure out which direction to project along slightly_smiling_face
2018,no i dont think so right now
2018,it wouldnt be crazy to add a codesnippet keyword to the codesnippet derived quantity
2018,or to the other derived quantities that touch particle fields
2018,i guess in the demeshening if you only use gas youll use the gas particle fields
2018,so maybe that will work
2018,hmmoh you mean where codesnippet would be something like codesnippet to specify the ftype to only use gas
2018,because when im determining the angular momentum of the galaxy the net disk rotation of the gas particles gets overwhelmed by the dm angular momentum which is not aligned
2018,right
2018,setting the codesnippet and codesnippet didnt seem to align either confused
2018,so i havent tried to do what youre trying to do before
2018,im doing other things right now but im happy to look closer at this
2018,i dont think it would be very hard to add a codesnippet keyword
2018,no worries i figured id just bounce ideas around
2018,ok ill poke around at that
2018,and thats something that would be useful for other reasons eg to get the angular momentum of star particles
2018,wait
2018,yes i think now that more particlebased frontend users will be using yt this will be more useful
2018,are you sure you cant do this manually
2018,i can do it manually in that i can read in the file in hdf5 and calculate it without yt
2018,no
2018,i mean by accessing fields by particles
2018,angular momentum vector is a pretty simple process right
2018,yeah its simple
2018,sure that would work too
2018,i could do that i just wanted to see if there was something in the code
2018,sure sure im not trying to wellactually you
2018,ill see if i can add this particle_ftype kwarg
2018,would you be opposed to adding a codesnippet keyword to a few of the derived quantities
2018,user no i wouldnt
2018,i was just trying to figure out if there was a rightnow way of doing it for user
2018,slightly_smiling_face
2018,ill see if i can add this now
2018,thanks team
2018,for the additional check in the derived quantity do you prefer the kwarg to be codesnippet and then give it the codesnippet
2018,of the particles
2018,yeah i think thats the easiest way to phrase it and let it default to all for backward compatibility
2018,ok
2018,sounds like a plan
2018,also a basic git question if im pulling updates from the main repo and i want to get both updates to codesnippet as well as codesnippet how do i do that normally i just docodesnippetgit pull upstream mastercodesnippetbut i realize this wont pull updates to codesnippet but it seems like maybe a bad idea to do codesnippetgit pull upstream yt40codesnippet
2018,just make sure you have that branch checked out before pulling
2018,so codesnippet then codesnippet
2018,and codesnippet then codesnippet
2018,also this is why its a bad idea to commit directly to master or yt40
2018,because if you did that then this would generate a merge commit
2018,ok perfect
2018,thanks user
2018,user maybe you try giving a look at hyperlink and hyperlink
2018,those are two smale python packages to help you build plots with a scalebarcolorbar
2018,thanks user ill check those out i think i got something working using users suggestion but anything that makes colorbar customization easier will be beneficial
2018,does anyone have an idea of how you could link to quadpack from cython
2018,i know its been done for scipy but then everything is wrapped in a python function and the integrations become super slow
2018,is this something thats exposed via scipys lowlevelcallable
2018,ive never used that before
2018,otherwise youd need to make your own bindings for it i think
2018,unless scipy exposes their bindings and distributes them
2018,user i think i remember there being a way to supply callable c function handles somehow to scipy for calling its odes
2018,ah yes
2018,hyperlink
2018,the function can be a lowlevelcallable
2018,hyperlink
2018,hyperlink
2018,oh thats great now i have to figure out how to create a lowlevelcallable
2018,user regarding the issue with ghost zones the issue is actually more about computing facecentered data right
2018,ive got an almostworking version to get neighboring cells for octreebased data ex ramses then if you have the neighboring cell you can get the facecentered values with a simple linear interpolation
2018,user has joined the channel
2018,user if i remember right the clumps dont use face center values but the do need the kdtree iteration to get to neighbors that may mean ghost zones depending on how its implemented
2018,user in any case wed need an efficient way of accessing the neighboring cells
2018,absolutely
2018,so far im querying the index of the upto4 neighboring cells in a given direction which takes codesnippet time
2018,that sounds pretty darn awesome slightly_smiling_face
2018,for the volume renderer its facecentered data it also uses the kdtree to iterate over grids but we can do the same thing with the octree
2018,and for isocontours its just generating facecentered data i think
2018,and of course if we have ghost zones then fields like voriticity can be computed slightly_smiling_face
2018,would you know how to implement ghost zones if i write a function that returns the index of neighboring cells
2018,sure if the index corresponds to data at the same amr level just return that data by reading it
2018,if its at a lower level then sample the lower level data there are various methods we can use for the interpolation
2018,is lower coarser or finer for you
2018,coarser
2018,does ramses store the field data for nonleaf octs
2018,good question i dont know
2018,for finer data its harder you would need to do cascading interpolation on the other fine data that also is contained in the ghost oct youre generating data for
2018,presumably you can get that by walking the octree
2018,its made easier because there cant be more than one level difference between neighbors
2018,im not expert here on the interpolation algorithms you can use im also not sure what precise interpolation for coarsetofine and finetocoarse yt uses for amr data
2018,sure but if you go out to 4 neighbors like youre saying slightly_smiling_face
2018,but i guess you can just go out zone by zone
2018,so its always lt1 level difference
2018,i think the terms used for this in the amr literature is prolongation and restriction
2018,ah yeah sorry prolongation coarsetofine is interpolation
2018,you can use trilinear interpolation for this we can see if something fancier is necessary
2018,for restriction finetocoarse its a weighted averaging operation
2018,presumably for an octree its natural to do it recursively by averaging data in leaf octs onto nonleaf octs
2018,how can you access the underlying octree container from a ytregion object
2018,lets move this discussion to cbe6579czdevelopment
2018,lots of people in this channel that dont care about this
2018,user isocontours does use vertex centered but i believe that clump finding only uses ghost zones
2018,is that not what i said
2018,sorry
2018,can never keep stuff straight without doublechecking
2018,is there a way to format a ytquantity and still get the units right now im doing something like codesnippet
2018,formatting as a string should get it all in one go
2018,user i think there was a pull request recently about this
2018,hyperlink
2018,not sure this helps
2018,if i format it as a string i get a silly number of sig figs checking the pr
2018,hm that looks like exactly what i want and dont seem to have
2018,do i not have it because im on the 40 branch
2018,ah yeah
2018,i need to merge with master dont i
2018,you can just separately format the units though
2018,yeah thats what im doing at the moment
2018,just a little papercut not serious
2018,papercuts hurt
2018,hyperlink
2018,i have some surface brightness images that id like to plot alongside a projectionplot with the same styling any ideas on where to start
2018,hmm thats not really something we support
2018,how complex are these plots
2018,are there lots of annotations
2018,i think id do just fine with a pointer to where the code for the colorbar positioning and fontlabel config is
2018,you can get something resonably like a plotwindow plot with eg thiscodesnippetimport matplotlibimport matplotlibpyplot as pltpltimshowimage_data normmatplotlibcolorslognorm originlower cmapviridis extent75 75 75 75cb pltcolorbarcbset_labelrprojected density rmgrmcm2pltxlabelx kpcpltylabely kpcpltsavefigplotpng bbox_inchestightcodesnippet
2018,where codesnippet can come from yt via a codesnippet object
2018,as far as the code goes let me take a look
2018,interesting didnt know about the codesnippet argument to imshow
2018,so most of the action of setting up a plot is in this function
2018,hyperlink
2018,it calls into other code though so its not quite a 11 thing of just that one file
2018,you can think of plot window plot objects as containers for multiple plots one plot for each field requested by the user
2018,the plots for each field are contained in the codesnippet dictionary
2018,eg codesnippet
2018,where codesnippet is the thing you get back from codesnippet
2018,the plot object itself will be an instance of codesnippet which is a wrapper around a matplotlib figure
2018,codesnippet is a subclass of codesnippet which is defined here
2018,hyperlink
2018,theres a lot of interaction with matplotlib there as well as in codesnippet
2018,theres also codesnippet which doesnt have a colorbar and represents line plots thats used by codesnippet
2018,apologies if thats information overload slightly_smiling_face
2018,i think i will need much of what you just said and itll stick around for a while slightly_smiling_face
2018,yeah the plotting code kinda grew organically
2018,theres aspects of this problem that its hard to make pretty and neat
2018,but also i was still learning python when i wrote a lot of this code
2018,i was also just fiddling with the plot methods i have been trying to hide the axes for plots made with codesnippet heres my attemptcodesnippet prj ytoffaxisprojectionplotds ds center 000 normal los_vec fields selected_field width 4 kpc north_vectorup_vec weight_fielddensity prjset_xlabelkpc if iplot 1 print 40 prjset_ylabel helpprj prjset_yticks doesnt work prjhide_axes else prjset_ylabel kpccodesnippetbut it still shows the axes labels and the axes ticklabels anyway to hide this i looked into base_plot_typespy plot_windowpy off_axis_projectionpy but couldnt find anything
2018,hmm doesnt codesnippet have a codesnippet method
2018,yes i tried that but it doesnt seem to work
2018,works for me over here
2018,hyperlink
2018,codesnippetin 1 plot ytoffaxisprojectionplotds 111 gas densityin 2 plothide_axesout2 ltytvisualizationplot_windowoffaxisprojectionplot at 0x115242080gtin 3 plotsaveout3 galaxy0030_offaxisprojection_densitypngcodesnippet
2018,hmm doesnt work for me i wonder if it has to do with the other annotate functions that i call later in the code i will try moving part of my script
2018,ok cool if you can make an example i can run to reproduce the issue i might be able to help
2018,on stackoverflow they call this an mcve
2018,hyperlink
2018,oh okcodesnippet prj ytoffaxisprojectionplotds ds center 000 normal los_vec fields selected_field width 4 kpc north_vectorup_vec weight_fielddensity prjhide_axescodesnippetitself works didnt work probably because i accidentally also call codesnippet after
2018,ah i see
2018,to change the fontsize of the label what is the keyword arg i tried fontsize and size but it says typeerror set_ylabel got an unexpected keyword argument sizecodesnippet
2018,codesnippetprjset_font_size15codesnippet
2018,you might want to also look at the documentation for the yt plotting objects
2018,eg
2018,hyperlink
2018,you can also look at the docstrings inside ipython with the codesnippet operator
2018,eg
2018,codesnippetin 12 plotset_ylabelsignature plotset_ylabellabeldocstringallow the user to modify the yaxis titledefaults to the global valueparameterslabel str the new string for the yaxisgtgtgt plotset_ylabeltemperature kfile documentsytgitfixesytvisualizationplot_containerpytype methodcodesnippet
2018,theres also eg codesnippet for more customization
2018,hyperlink
2018,oh ok thanks
2018,user i found a way to make what i want happen but its dirtycodesnippet for axis in x y z plot ytprojectionplot density_plot plotplotsgas density pdfsavefigfiguredensity_plotfigure for i image in enumerateall_images density_plot_init_imagedataytytarrayimage m cbnormlog10 cblinthreshnone cmapinferno extent0 500 0 500 aspectnone pdfsavefigfiguredensity_plotfigurecodesnippet
2018,i hijacked one of the plots from a projectionplot and reinit the image to plot each of mine
2018,it should be possible to expose that in a nicer way
2018,if you want to take the time to put in a pr
2018,i understand if you dont
2018,could also just open an issue with that snippet
2018,ill open an issue for now and think on this tonight
2018,cool
2018,happy to help out
2018,teach someone to fish instead of giving them a fish etc etc slightly_smiling_face
2018,slightly_smiling_face
2018,so do i just ignore all the issue default text because im not reporting a bug
2018,oh yes thats just there as a guideline
2018,you can feel free to delete it
2018,im unsure how much credit youre due or want for that hack slightly_smiling_face
2018,where is the code that sets the colorbar label
2018,ive found some snippets but nothing thats helpful
2018,theres this which as far as i can tell is just validating the labelhyperlink
2018,and im sure this is important but i cant figure out where codesnippet is sethyperlink
2020,hello everyone i am new to yt and fairly new to python so i apologize if this is a fairly simple question but ive been unable to answer it by browsing the documentation i am using yt to read data produced by athena and im able to make some nice looking projection plots fairly easily my issue comes when trying to make more simple 2d line plots like you would typically make with say matplotlib i think my issue comes from not knowing how to access the data once yt has read it and stored it in fields is there a way to call the data from the fields and use pyplot to plot it ive tried using the lineplot function in yt but this isnt quite the plot i want to maketo be more specific im trying to make a plot of the average particle density as a function of x so i need to find the average value of particle density for all z cells all y cells and the 1st x cell and then repeat the process at each of the x cell locations hopefully this makes some sense id be happy to clarify further if it doesnt thanks for your help in advance
2020,user it sounds like you desire a codesnippet hyperlink if you want the average density as a function of x then your binning field would be codesnippet where you are profiling codesnippet a codesnippet operates on a data object therefore you can define a yt object relevant to your problem eg a box sphere or disk alternatively the codesnippet can use the entire data set by defining the object codesnippet
2020,user i did look into these but i was a bit confused of how to define the box i want profiled the code ran in a grid of 64 cells in the x y and z directions and in code units the sides go from 01 to 01
2020,try something along the lines ofcodesnippetimport yt import athdf fileds ytloadmy_athena_fileathdf create data object for profiledd dsall_data create profilemy_profile ytcreate_profiledd x density n_bins64 weight_fieldcell_volume logsxfalse create the profile plotplot ytprofileplotfrom_profilesmy_profile show the plotplotshowcodesnippet
2020,this will profile over the entire simulation domain
2020,ok i will try this thank you so much for your help
2020,if you want to restrict the analysis to some subsection of the domain then instead of codesnippet consult object creation wiki page hyperlink
2020,hope this helps smile
2020,user has joined the channel
2020,codesnippetcodesnippetcodesnippetcodesnippetcodesnippetcodesnippetcodesnippetcodesnippetimport codeimport ytfrom yt import ytarray arrays in yt modulefrom ytvisualizationapi import streamlines force linesimport matplotlibpylab as pl choose point in fieldx_point 0007089085922957821y_point 0038439192046320805z_point 0 load data dictionarytry import cpickle as pickleexcept importerror python 3x import picklewith opendatap rb as fp data pickleloadfpbx_d databxby_d databybz_d databz 3d array of dipole magnetic field printtypedatabbox nparray015 015 0 02 01 01 box borderds ytload_uniform_griddata bx_dshape length_unitmpc bboxbbox nprocs100 data dimensionc ytarrayx_point y_point z_point m define c the center of the box chosen pointc1 dsdomain_centerprintc1 c1printtypec1printcentercn 1 n the number of streamlinesscale dsdomain_width0 scale the spatial scale of the streamlines relative to the boxsizepos c create streamlines of the 3d vector velocity and integrate them through the box defined abovestreamlines streamlinesds pos bx by bz lengthnone length of integrationstreamlinesintegrate_through_volume create a 3d plot trace the streamlines through the 3d volume of the plotfigplfigureax axes3dfigaxscatterx_point y_point z_point marker o s40 cgreenprinttisk streamlinesstreamlinesfor stream in streamlinesstreamlines stream streamnpallstream 00 axis1 axplot3dstream0 stream1 stream2 alpha01 save the plot to diskplsavefigstreamlinespngpltshow
2020,hi could you help me with this code please i am trying to integrate force line in the given point i dont know where is mistake there is no streamline in the plot i tried this example hyperlink with the change of data and the change of number of streamlines thank you very much
2020,data dipole magnetic field
2020,hey is there a yt field call codesnippet or something like that im only able to find codesnippet but would love to see if i can get the number density values thanks
2020,yes there should be codesnippet is an enzo field which will be in enzo units
2020,one sec
2020,you can see codesnippet here hyperlink
2020,codesnippet
2020,is what you want
2020,hope this helps
2020,sweet found it thanks
2019,user any chance you could insert a debug and see what codesnippet is
2019,sure i added the line codesnippet right above codesnippetcodesnippetgenerate smoothing length 1430244it 0014 10028269its yt info 20190517 142923674 allocating for 5185e06 particlesinitializing coarse index 0 013 0000lt itsyt debug 20190517 142923684 ltytfrontendstipsydata_structurestipsyfile object at 0x113742bd0gtyt debug 20190517 142923688 spanning 7163e02 9002e03 in xyt debug 20190517 142923692 spanning 5661e02 6474e03 in yyt debug 20190517 142923696 spanning 1528e02 2801e02 in zyt debug 20190517 142923761 ltytfrontendstipsydata_structurestipsyfile object at 0x113742bd0gtyt debug 20190517 142923764 spanning 9839e01 3689e01 in xyt debug 20190517 142923767 spanning 1003e00 4364e01 in yyt debug 20190517 142923770 spanning 4846e01 9265e01 in zyt debug 20190517 142923784 ltytfrontendstipsydata_structurestipsyfile object at 0x113742bd0gtcodesnippet
2019,stacktracecodesnippetvalueerror traceback most recent call lastltipythoninput19427a547d7d9gt in ltmodulegt 9 dsname usersclaytonstrawntestnihaoinputg826e11g826e1100320 10 ds ytloaddsnamegt 11 print dsfield_listusersclaytonstrawnytytdata_objectsstatic_outputpyc in field_listself 556 property 557 def field_listselfgt 558 return selfindexfield_list 559 560 def create_field_infoselfusersclaytonstrawnytytdata_objectsstatic_outputpyc in indexself 514 raise runtimeerroryou should not instantiate dataset 515 self_instantiated_index self_index_classgt 516 self dataset_typeselfdataset_type 517 now we do things that we need an instantiated index for 518 first off we create our field_info nowusersclaytonstrawnytytgeometryparticle_geometry_handlerpyc in __init__self ds dataset_type 41 selffloat_type npfloat64 42 superparticleindex self__init__ds dataset_typegt 43 self_initialize_index 44 45 def _setup_geometryselfusersclaytonstrawnytytfrontendssphdata_structurespyc in _initialize_indexself 90 selfio_generate_smoothing_lengthselfdata_files selfkdtree 91 gt 92 supersphparticleindex self_initialize_index 93 94 def _generate_kdtreeself fnameusersclaytonstrawnytytgeometryparticle_geometry_handlerpyc in _initialize_indexself 148 except oserror 149 selfregionsreset_bitmasksgt 150 self_initialize_coarse_index 151 self_initialize_refined_index 152 wdir ospathdirnamefnameusersclaytonstrawnytytgeometryparticle_geometry_handlerpyc in _initialize_coarse_indexself 164 for i data_file in enumerateselfdata_files 165 pbupdateigt 166 for ptype pos in selfio_yield_coordinatesdata_file 167 ds selfds 168 if hasattrds _sph_ptype and ptype ds_sph_ptypeusersclaytonstrawnytytfrontendstipsyiopyc in _yield_coordinatesself data_file needed_ptype 311 mylogdebugstrdata_file 312 for axi ax in enumeratexyzgt 313 mi ppcoordinatesaxmin 314 ma ppcoordinatesaxmax 315 mylogdebugusersclaytonstrawnanaconda2envsmyenvlibpython27sitepackagesnumpycore_methodspyc in _amina axis out keepdims initial 30 def _amina axisnone outnone keepdimsfalse 31 initial_novaluegt 32 return umr_minimuma axis none out keepdims initial 33 34 def _suma axisnone dtypenone outnone keepdimsfalsevalueerror zerosize array to reduction operation minimum which has no identitycodesnippet
2018,it does do it in io order same for offaxis projections with volume rendering i believe it does fronttoback unless specifically asked not to
2019,can we do monday 10am pst
2019,monday actually doesnt work for me ill be grading a final all day after that i should be free all week same time tuesday
2019,user this seems like something we should fix on the yt side i know nathan had been unhappy with field parameters and this might be a lowhanging fix something for us to think about
2019,cool thanks
2020,user has joined the channel
2018,does anyone know if theres a way to rotate a sliceplot by 90 degrees
2018,user it looks like a very similar question was asked yesterday here will that solution work for you
2018,the one answered by nathan just above in case you didnt see it
2018,user oh duh i guess i should try reading first
2018,thanks for pointing me to that
2018,no prob it would not have occurred to me either i just remembered seeing it
2018,we should add a cookbook recipe for that
2018,how do i figure out what i can plot in a projection plot
2018,sorry i dont understand the question
2018,can you explain a little bit more what youre trying to do
2018,i want to figure out what my snapshot looks like as a sort of sanity checks id like to know wherehow the gas is distributed stars dark matter etc maybe some properties thereof lateri cobbled together this almost straight out of the yt docs my instinct is that i can replace the codesnippet keyword with something else and that theres a way to get my codesnippet to spit out a list of valid codesnippets but no luck so farcodesnippetimage_array ytoff_axis_projection ds center normal_vector0 1 0 width500 500 500 resolution1024 1024 itemgas density north_vector0 0 1codesnippet
2018,ah i see
2018,you want to look at dsfield_list
2018,and dsderived_field_list
2018,actually really just codesnippet
2018,all of the codesnippet and codesnippet fields can be plotted like youre doing
2018,for particle fields you can use the codesnippet machinery
2018,sorry can you remind me are you using the demeshening
2018,you work with sph data right
2018,that is correct slightly_smiling_face
2018,love me that yt40
2018,ok part of the issue is that youre using an indevelopment version of yt thats not fully working yet
2018,like im not sure that the deposit fields will work at the moment
2018,for offaxis projections anyway
2018,all of the gas fields will work though
2018,for dark matter and stars you probably should use the codesnippet machinery
2018,this is a good point though weve made it less clear what kind of fields there are in the demeshening we need to make this clear in the docs before we do a release
2018,wonders if we have an offaxis particle plot
2018,if we dont we should
2018,it would just mean rotating the particles before passing it to the regular particle plot
2018,thinking_face so youre saying i could just rotate the particle coordinates myself
2018,yes thats what offaxis projection plot does for sph fields
2018,hyperlink
2018,thats the cython routine that does that we could do the same thing for particle plots
2018,thanks so much for your help ill get around to trying this soon
2019,is there a splash or yt projection plotting thing for gpu
2019,user enh yt does not have a reliable one but its being worked on more slowly than id like its being worked on by me
2019,nope not in yt yet
2019,ah okay
2019,i kinda just taught myself cuda and im wondering why my crude simplified implementation of a density projection plot is not all that much faster than the yt one
2019,sph particles are _huge_ i never knew
2019,user im probably going to poke at this just occasionally but heres what ive come up with so farhyperlink
2019,user awesome
2018,user has joined the channel
2020,user has joined the channel
2020,user this is interesting and its possible that there are other issues that could be causing this would you be able to look at it with different color scaling perhaps using symmetric log that might help us see any possible artifacts
2020,yep here is symmetric log
2020,
2020,note i didnt restrict to the same limits as before
2020,
2020,also this is what the grid looks like it doesnt appear to be a boundary issue
2020,thats just an idea offhand but could it be some kind of normalisation wrt the volume of cells or the cell size
2020,ie if you divide the divergence by the cell sizevolume do you get the right answer
2020,i am not sure if that will do it because that would change the divergence by a factor of 8 which wouldnt be correct since the first set of images shows them being pretty close
2019,user codesnippet does not work your second suggestion worked however codesnippet is not working when called to work on both the x and y axis is this a known bug
2019,i dont think so if you can open an issue on github that would be great if you can please include an example script to trigger the issue you can use one of the testing datasets on hyperlink or eg codesnippet
2019,user this is for agora its basically just testing at this point because all the simulations are at pretty high redshifts still and the specific results i get wont matter that much until the simulations get closer to observationsindeed im just putting random sightlines through at different impact parameters and recording various data inflow vs outflow temperatures densities etc
2019,i guess you could choose random start and endpoints inside the domain
2019,eg between dsdomain_left_edge and dsdomain_right_edge
2019,thats what i ended up doing once i get virial radius information from the larger analysis suite i can use that to scale it too
2019,hi all im going a little bananas is there something special one needs to do to use yt in a notebook the following works fine in a regular ol python script
2019,import ytds ytloadusersjillnaiman1dataisolatedgalaxygalaxy0030galaxy0030p ytprojectionplotds y densitypsave
2019,but in a jupyter notebook i get
2019,runtimeerror ytquantity values must be numeric
2019,user how recent a version is it are you sure both the notebook and the console are using the same one
2019,also if you can give a bit more of the traceback thatd help
2019,how long until class slightly_smiling_face
2019,so i tried upgrading yt and checking its the same version stored in each
2019,like 4 hours so maybe no sci viz today stuck_out_tongue
2019,can you show the entire tb
2019,so like
2019,
2019,oh ho wait i think ive got more than 1 version of python 37
2019,well with some magic of setting special environments it now works
2019,hurray
2019,confused
2019,this is my excited face
2019,hooray
2019,user how are you loading your dataset can you share the script that generates the image you just posted
2019,just to make it clear exactly whats happening its hard to provide help without all the details slightly_smiling_face
2019,of course cheers here it is
2019,codesnippetdef slicesfoldernbmaxnbmin1time_unitmyr should find nbmax automatically locpath galdatapath folder figpath galfigpath folder for i in rangenbminnbmax1 load a dataset ds ytloadlocpathoutput_05iiinfo_05iitxt this is to make a slice plot and a projection plot p ytsliceplotds z density pset_axes_unitkpc pset_widthwidth unit pannotate_titlet 1f sdscurrent_timetime_unit psavefigpath save it as a pngcodesnippet
2019,so the codesnippet call is getting overrided by the call to codesnippet
2019,whats codesnippet
2019,codeblock
2019,hmm so your data arent being loaded with the correct units it seems
2019,i see
2019,it comes from a ramses simulation
2019,user would know more details about how ramses units are parsed but you should be able to pass codesnippet to codesnippet to override the assumptions yt is making about the units of your data
2019,i look at the manual about that thanks
2019,how did you produce your simulation matt
2019,is it the one you pasted on the ramses slack
2019,eg something like thiscodesnippetunits_override length_unit 10 mpc time_unit 10 myr mass_unit 10e14 msunds ytloaddataset_filename units_overrideunits_overridecodesnippet
2019,user it works cheers if i dont set_axes_unit not set_width slightly_smiling_face
2019,we do have support for inferring the units from the ramses output so something in that is broken for your data
2019,user so i simply ran the sedov example from the tuto joki gave me there without any change
2019,eg this code hyperlink
2019,if i recall correctly the default sedov explosion namelist has no units specified in this case units are assumed to be cgs by default which is why you get codesnippet
2019,you can either pass units on ramses side hyperlink or use the code user wrote above i would however argue strongly in favour of the first choice so that you are sure that everything is computed in the right units in the first place
2019,so i am very beginner with ramsesyt but i see conversion in namelist from cgs to user units but no name for them here
2019,codesnippetunits_paramsunits_density166000d24units_time31556926d13 1 myr in secondsunits_length308568025d21 1 kpc in cmcodesnippet
2019,i guess mass shoud be set to dalton too instead of having a density displayed in gcm3
2019,density in yt is a mass density you may want to plot the codesnippet field if you want something with units of inverse volume
2019,if you have these parameters in your namelist yt should be able to read the output properly with the right units if it fails this a bug
2019,either on ramses side or yts
2019,hi matt check the units in output_xxxxxinfo_xxxxxtxt to make absolutely sure they are read from the namelist
2019,user thanks
2019,user can it give them proper names
2019,user i have this block in infotxt
2019,codesnippetunit_l 0100000000000000e01unit_d 0100000000000000e01unit_t 0100000000000000e01codesnippet
2019,so ramses is not reading the namelist correctly
2019,indeed
2019,i think you probably have an older ramses version where the units are in another namelist
2019,these lines should match your codesnippet block are you sure you correctly closed it with a trailing codesnippet
2019,oh right that may be
2019,this is a run from slacks tuto unchanged i suppose i should ask on ramses slack now
2019,oh ok i should try to update then
2019,the namelist parameters were moved around a bit a couple of years ago i think
2019,its always fun figuring out if something is a bug in yt a bug in the simulation code a bug in your custom modifications to the simulation code
2019,glad we could help figure this out though slightly_smiling_face
2019,good luck with your journeys into computational astrophysics
2019,1
2019,thank you very much i suppose now i must refork repo and recompile cheers guys
2019,they were moved on september 2017 if i remember correctly so if your version of ramses is based on a public version older than this you probably dont have the namelist parameters at the same location
2019,im not sure what version im using im going to reinstall now
2019,ok it works now cheers slightly_smiling_face one thing though i try to annotate slices with simulation time through codesnippet but now codesnippet is 315569260000000 s instead of manually displaying the unit i want i guess there is a clean way to do that automatically with yt
2019,codesnippet
2019,yeah that slightly_smiling_face
2019,youre brilliant 1
2019,i ran the code again but this time on 128 cores instead of 64 which with having triggered adaptative mesh refinement is the only change from last time nevertheless on ytload i now get this error messagecodeblockany idea
2019,user does that file still exist
2019,ok it seems i have some folder tree issues sorry to have bothered you
2019,user these things happen wink
2019,user has joined the channel
2019,i have a piece of code that spend most of its time navigating an octree i know yt employs this particle index thing and ewah files to navigate data structures faster do you have any tips for octree work
2019,user possibly can you describe more about the piece of code
2019,its doing raytracing on an octree so when a ray exits one cell it spends a lot of time navigating to the cell the ray is entering
2019,user is it written in python cython etc
2019,c
2019,i know that theres a way to do spacefilling curve navigation of octrees but it will take me a minute to find the paper
2019,that sounds helpful ive done all the basic stuff to profile and optimize the code at this point im just curious as to whether there are better algorithms or like an alternative data structure i can keep next to the octree to find the cell i want faster
2019,im not sure it was either of these papers but i am on crummy wifi hyperlink hyperlink
2019,hyperlink
2019,the keywords that you might look for are viewpoint traversal
2019,first one has octree traveral in the title
2019,oo so does the last one
2019,this looks like good stuff thanks
2019,user let me know how it goes im very interested
2019,is there any way to pull my particle data out of a yt dataset without going through all the region selection machinery the rest of yt is pretty great and the units are invaluable but the amount of time i have to wait while it does all the loading machinery just to slurp everything off disk is annoying
2019,you could open the file handle with h5py
2019,yeah ive been doing that
2019,what sort of api are you looking for in yt
2019,the whole codesnippet is a totally workable api for me its just slow thats all
2019,i see its probably possible to shortcircuit index creation for that specific case
2019,from some cursory profiling it looks like the region that codesnippet returns goes through every point in my dataset and makes sure its in the region which is silly
2019,oh yes that can definitely be shortcircuited
2019,it isnt implemented but it could be as a quickpath check
2019,yeah we could make the all_data selector a special case slightly_smiling_face
2019,i believe we currently have a way to signify that an entire object is included in a selector
2019,we do this for shortcircuiting on for instance grids that are fully enclosed
2019,although i think wed still need to create the index
2019,so youd still have to wait for codesnippet to finish
2019,so whatever progressbar appears when it loads an ewah file is approximately instant
2019,thats definitely not a bother
2019,ah cool then were probably good
2019,any chance you can trigger the specific slowdown youre talking about with one of the data files on hyperlink
2019,to give us a benchmark slightly_smiling_face
2019,i shall see what i can do
2019,if these are your test datasets i can see why nobody has been bothered by this behavior before p
2019,i think the largest one is gizmo_cosmology_plus
2019,fire
2019,i might just be way towards one end of the spectrum shrug
2019,it looks to me like the snapshots in gizmo_cosmology_plus are the largest in the available downloads is that correct the thing im complaining about is hardly noticable with snapshots of that size again im reminded that i should nag people to get a massivefire snapshot contributed to the yt data examples
2019,gizmo_cosmology_plus is 363 mb each my snapshots are 13 gb each
2019,i dont know enough about this area to know if i could stick together a bunch of copies of one of your snapshots so you can reproduce this hm
2019,its cool can you by any chance do a profile of you doing an operation with one of your data files
2019,and share the script and profile data
2019,codesnippet
2019,and you can share codesnippet
2019,so _that_ is how you use codesnippet
2019,and then i can run the script with eg codesnippet and try to make the bit thats slow in your script faster slightly_smiling_face
2019,but yeah as is so often the case with scaling issues you only notice with sufficiently big data thank you for the report slightly_smiling_face
2019,i think this is a decent enough demo script to point at the relative difference but profile incomingcodesnippetimport ytimport h5pyimport timeds ytloadgizmo_cosmology_plussnap_n128l16_131hdf5data dsall_datastart timetimedataparttype0 coordinatesprintyt timetime startwith h5pyfilegizmo_cosmology_plussnap_n128l16_131hdf5 as f start timetime data fparttype0coordinates printh5py timetime startcodesnippet
2019,this is 10 seconds for yt and 002 for h5py if it were 10 seconds on my full snapshots id be quite content with the current status stuck_out_tongue
2019,
2019,and what are the timing differences for your dataset
2019,419 seconds in _count_particles_chunks thats probably not necessary
2019,yt 16 seconds h5py 1 second the script gets more complicated without yt because its a multifile snapshot
2019,interesting that timing doesnt agree with the profile i guess theres some profiling overhead
2019,anyway thanks will try to see if theres an easy way to shortcircuit this
2019,fun thread to follow
2019,the profile is probably tracking cpu time
2019,i ran the profile on a login node with 32 cores
2019,like under mpi
2019,i dont think anything in that script is threaded
2019,the machinery inside codesnippet is threaded in yt
2019,nope
2019,at least i dont think so slightly_smiling_face
2019,codesnippetreal 0m40207suser 14m2574ssys 0m9497scodesnippetthis is codesnippet on my demo script this looks like threading to me but ill admit ive seen spooky stuff come out of codesnippet before
2019,i guess it could be numpy if youre using the mkl numpy build from anaconda
2019,shrug
2019,reproduced it locally with codesnippet
2019,
2019,pyinstrument is nifty
2019,im probably using the mkl numpy build
2019,we can shortcut codesnippet for codesnippet since we can get the counts directly from the output
2019,desika has advised me to share a simba snapshot with yt as an example of a large dataset wherehow do i deliver the file
2019,if its less than 5 gb then yt upload some_filetargz
2019,if its bigger than that then a google drive link should work or if you have access to a public webspace you can just put it there and share a link
2019,please also make a pull request to the website adding the file let me find an example to look at
2019,hyperlink
2019,one of the yt developers who have access probably me will need to manually stage the file on the webserver running hyperlink before the pull request gets merged
2019,its 30 gbill see what i can do with google drive
2019,heres a link to the google drive upload hyperlinkill send you a pr tomorrow
2018,user has joined the channel
2018,hi im trying to generate light ray through a dense region in a halo when the ray path hit the dense region everything works fine but if i try to let it go through a less dense region then the rayt field cant be called with a bug saying
2018,
2018,is this an sph dataset
2018,its an enzo dataset
2018,hmm this might be a user question
2018,can we also see the rest of the traceback
2018,if you can make an example using one of the test enzo datasets on hyperlink that triggers this issue that would also help
2018,i dont know offhand if there are any zoomin sims there though
2018,shes trying to upload something but we have crap wifi here
2018,im uploading a file as a code snippet but the wifi its not happy ill copy the rest into this window
2018,so this is the code i useray_start nparrayhalo_center000015 halo_center100015 halo_center20001ray_end nparrayhalo_center000015 halo_center100015 halo_center20001printray_start ray_endrs dsarrray_start code_lengthre dsarrray_end code_lengthray dsrayrs re
2018,and the error when i call rayt52 5352 53valueerror traceback most recent call lastltipythoninput70893c526a201dgt in ltmodulegtgt 1 raytanaconda3libpython36sitepackagesytdata_objectsdata_containerspy in __getitem__self key 250 if f in self_container_fields 251 selffield_dataf gt 252 selfdsarrself_generate_container_fieldf 253 return selffield_dataf 254 elseanaconda3libpython36sitepackagesytdata_objectsselection_data_containerspy in _generate_container_fieldself field 248 return self_current_chunkdtcoords 249 elif field tgt 250 return self_current_chunktcoords 251 else 252 raise keyerrorfieldanaconda3libpython36sitepackagesytgeometrygeometry_handlerpy in cached_funcself 269 tr self_accumulate_valuesn1 270 elsegt 271 tr funcself 272 if self_cache 273anaconda3libpython36sitepackagesytgeometrygeometry_handlerpy in tcoordsself 378 cached_property 379 def tcoordsselfgt 380 selfdtcoords 381 return self_tcoords 382anaconda3libpython36sitepackagesytgeometrygeometry_handlerpy in cached_funcself 269 tr self_accumulate_valuesn1 270 elsegt 271 tr funcself 272 if self_cache 273anaconda3libpython36sitepackagesytgeometrygeometry_handlerpy in dtcoordsself 391 gdt gt objselect_tcoordsselfdobj 392 if gtsize 0 continuegt 393 ctindindgtsize gt 394 cdtindindgdtsize gdt 395 ind gtsizevalueerror could not broadcast input array from shape 31 into shape 29
2018,user and what did you change that made it work just the ray_start ray_end
2018,i changed the ray_start and ray_end to point to the densest region of the halo and everything turns out fine
2018,so this definitely seems like a bug to me
2018,its amr so empty regions shouldnt really be empty
2018,id need to poke around with an example triggering the error to say more sorry about the trouble
2018,its so much easier when you just tell us weve done something wrong wink
2018,and rayx is good its just rayt and raydts that give me bug
2018,t has special handling but that is a good hint
2018,whats the shape of rayx
2018,629
2018,and raydensity or other things look good as well
2018,youre using yt 350
2018,yes just installed yesterday
2018,for some reason for one grid codesnippet isnt returning an array of the correct shape
2018,what does that mean
2018,this is something thats happening deep inside yt
2018,for some reason youve hit a corner case in a lowlevel routine that is causing the error youre seeing
2018,hmmm anything i can fix in the meantime
2018,i dont know offhand my first approach here would be to fix the bug
2018,ive never seen an error like this before
2018,we can make a slice with the ray location overplotted and also overplot the grid locationssince this is a foggie simulation im not actually sure if this means we have relatively few or relatively many grids for the number of cells
2018,yeah im sorry i dont know what kind of corner case youre hitting
2018,id probably need to insert print statements into a cython function to understand whats happening
2018,you could as well but that might be a big ask
2018,the particular function that i suspect is buggy is codesnippet which is defined in codesnippet
2018,have you tried slightly changing the ray start and end positions
2018,well just decide that a spectrum through that part of the cgm is unimportant snobby_sniff
2018,lol
2018,again sorry for the trouble if you can make this particular dataset available for me to download i can try to poke at it if you can find a public dataset that triggers this behavior that would also work
2018,that might be hard though
2018,its like 26gb and an output we havent published from yet confused
2018,sure i understand it might be hard to share
2018,im not going to scoop you fwiw slightly_smiling_face
2018,i know slightly_smiling_face
2018,ok dumb wifi its not allowing me to upload any files or figures to show you where the start and end points are let me change the coordinates a bit to see how it goes
2018,literally the easiest way to get the output to yong was for her to fly to baltimore and plug one of my external harddrives into her laptop
2018,fun
2018,hmmm when i change the x position by 1e4 then everything turns out fine
2018,yeah i bet the position you chose was eg exactly on a grid boundary
2018,or something along those lines
2018,user but if you change by 1e6 or 1e5 it doesnt work i think in code units 1e4 is pretty big for this run
2018,ok now it works when i switch the ray direction by 1e6 in a certain axies not always work but most do
2018,im gonna take it as the solution for now thanks user
2018,and a dumb question how do i get the total length of the whole ray in physical unit from the start to end point
2018,the cartesian distance between the start and end point
2018,yes
2018,just calculate it
2018,oh there is not builtin function they would do that
2018,npsqrtend_point start_point2sumtokpc
2018,missed a sqrt
2018,got it thanks
2018,this comes up often enough its probably worth it do implement a codesnippet field for rays
2018,true
2018,that would be awesome so far there is no such thing call raydl right
2018,yes just dt
2018,which is normalized to the length of the ray
2018,dts
2018,yeah
2018,cool thanks a lot
2018,if you keep on hitting this issue id still really like to debug it slightly_smiling_face
2018,seems like my slack is still working hard to upload the two files i was trying to so please ignore them if they do make it through this crappy wifi
2018,heh
2018,yes ill report again
2018,thanks user
2018,i have an octree thats produced by a bespoke piece of codeis it possible to feed this into yt or is it likely to be easier for me to write my own projection code to make plots
2018,yes with codesnippet
2018,oh huh its not in the api docs
2018,hyperlink
2018,for an example of how to use that see hyperlink
2018,and see this function for how to create the octree mask hyperlink
2018,let me issue a pr to include codesnippet in the api docs
2019,i have some index files that look _way_ too big can i twiddle the numbers in the index filename to improve the situation
2019,ah theres an codesnippet argument to codesnippet are there any potential hazards with adjusting this parameter
2019,user a bit its tough to balance the first and second orders the compression should help with this theyre stored in a form of runlength encoding so if theyre humongous that might be worth figuring out why
2019,the first order being the order of decomp for the top level files and the second order being for any collisions
2019,what are the consequences of picking index orders that are too small for my common usage patterns the index is just a nusicance are there examples that exercise it
2019,you can set it to zero and it wont do any indexing at all indexing helps for when doing memorylazy ops or for when doing any type of subselection
2019,im not sure what you mean by a memorylazy op
2019,user ah so i mean any time that the full dataset doesnt have to be in memory but not indexing only hurts if youre trying to do spatial subselections
2019,interesting i think ill just turn off indexing in my application
2019,user has joined the channel
2019,hi allis it possible in codesnippet to set an entire codesnippet as a field parameter and access it from within a field function im hoping to use it like belowcodesnippetds ytloadsnapshot_134hdf5ad dsall_dataoctree dsoctreen_ref32adset_field_parameteroctree octreedef _gassmootheddensityfield data octree dataget_field_parameteroctree return octreeparttype0 density dsadd_fieldgassmootheddensity function_gassmootheddensity unitsgcm3 sampling_typeparticlecodesnippetbut codesnippet appears to be a codesnippet and not an actual codesnippet when accessed through the codesnippet function in the docs it says field parameters must be ytarray objects but something likeadset_field_parameteroctree octreemyoctree adget_field_parameteroctreeaccesses the complete octree object just fine i was hoping this would extend to accessing it via a fielddefining functionis it possible to do so
2019,user this is something that should be possible but likely isnt just because of some silly technical oversight on my part what id recommend doing which makes me feel a tad bit gross is to either use a global or assign it to the codesnippet dict and access it there this would have to happen before codesnippet is called
2019,user ah great thanks for the help
2019,user there may still be an issue in which case ill prep an example of how to force it to work
2018,out of curiosity is there a way to smooth a projectionslice yielding a fixed resolution buffer using eg a gaussian filter
2018,i know you can just use the fixed resolution buffer object to get a numpy array and then smooth it but then you cant use the yt plotting interface anymore
2018,user i believe this was implemented by user but to be honest the specifics have slipped my mind
2018,hey folks question is arepos data format supported by yt i assume its similar to that of gadget possibly identical but i dont see it explicitly listed on hyperlink
2018,user no theres an open pr from user though
2018,user i dont think its hooked up to the plotting interface no
2018,would be a nice improvement to wire that up
2018,ok thanks maybe this could be added as a callback
2018,ah ok thanks
2018,user yup
2019,user has joined the channel
2019,user has joined the channel
2019,user has joined the channel
2019,user has joined the channel
2020,hi is there a way to save data generated by codesnippet like pull the x y z data arrays from the slice and do some calculation myself thanks
2020,you can get the image from the codesnippet attribute of the plotcodeblock
2020,i think codesnippet is the bounds of the image i dont remember the api offhand and am on my phone
2020,thanks user yeah both of the code lines work
2019,theres no vr for particle data yet
2019,i think most people who do similar things use sph smoothing onto a uniform grid and then volume render the uniform grid
2019,user user wrote this script or some version of it at least a while ago that i sometimes modify for pretty picscodesnippetwritten by nathan golbaumimport ytimport numpy as npfrom ytunits import kpcds ytloadgadgetdiskgalaxysnapshot_200hdf5m c dsfind_maxgas densityle c 25kpcre c 25kpcag dsarbitrary_gridle re 2563fields density temperature velocity_x velocity_y velocity_zdata for f in fields printf dataf aggas f printdatafshapebbox nparraylistziple reds2 ytload_uniform_griddata 2563 length_unithyperlinkkpcbboxbboxsc ytcreate_sceneds2sccamerazoom2scsavecodesnippet
2019,oh dang thank you my volume rendering dreams are coming true smile
2020,whats the argument to codesnippet that sets the resolution for the index its a 2tuple but i cant remember what the keyword argument is and the documentation and source code are failing me
2020,it doesnt ring a bell though im not too experienced with the various ways one can use this function i wouldnt be surprised if this argument was frontendexclusivehave you looked at the arguments of codesnippet
2020,as far as i can tell all such functions just punt a huge pile of kwargs somewhere else
2020,ah ah ah its in a different part of the help page got it thanks
2020,then out of curiosity care to share the solution
2020,codesnippet
2018,i want to poke at the parttype0 coordinates field for a bunch of snapshots if i do it through codesnippet yt40 spends about 2 or 3 minute generating these indexes which are probably super helpful for things that im not doing is there a way to get at my arrays without generating those indexes
2018,i can rig something up with h5py but yt is just so nice
2018,no unfortunately the way its set up right now you need to generate the bitmap index before we do any io
2018,i guess a hack would be to make a trivial index
2018,eg index_order 1 1
2018,user you might be able to speed it up by setting the level of the index to very low order
2018,is that an argument to ytload
2018,yup
2018,yup
2018,sighs
2018,we should add some discussion about this to hyperlink
2018,its discussed in hyperlink though
2018,hm think that made it slower
2018,how big are these datasets
2018,massivefire
2018,how many particles or size on disk
2018,13 gb on disk
2018,and do you have write access to the directories the files are in
2018,eg does yt write ewah files
2018,if so it only actually generates the index on the first load the second time it just reads it from the ewah files
2018,so that might explain why its slower with index_order11
2018,oooooo
2018,but this is a good point i wonder if its possible to delay generating the bitmap index until we really need it
2018,awesome thanksdesika suggested i rig something up with symlinks if i ytload my symlinks instead of his files the indexes load instantaneously
2018,hmm interesting
2018,because there are ewah files generated next to the symlinks
2018,that should do it yeah
2018,it would make sense to have loadable ewah files too
2018,what do you mean matt
2018,from other locations
2018,ah yeah that came up yesterday
2018,not that i am encouraging lots more kwargs
2018,i think user wanted to wire something up
2018,eg have a configurable path to search for those files
2018,or write them
2018,but thats a good hack using symlinks
2018,agreed
2018,yeah i also thought about symlinks but my first attempt failed as i symlinked the folder and not the files so i still had the same issue symlinks fixed it for me eventually
2018,i think it would be cool to put into a config though and then i can have the ewah files generate in my data folder and not my home folder on cosma
2018,yeah its a bit funky to have all the individual snapshot file symliinks in one huge directory but hey it works and yt still figures it out
2018,user this kind of feedback is really valuable slightly_smiling_face
2018,aw thanks im never sure if simple questions like this are annoying or useful ux feedback
2018,assume the latter slightly_smiling_face
2018,is there an article or paper where i can read about the technique yt uses to make a density projection plot
2018,so ash is planning on writing a paper but for now probably the splash paper
2018,at least for scatter projections
2018,hyperlink
2018,im not actually sure offhand whether ash got around to doing gather projections
2018,i havent actually but iirc then ive added the machinery to the neighbor finding to only use 2 of 3 spatial dimensions so in principal it should be pretty straight forward if someone has a need for it im happy to have a stab my schedule is a lot calmer starting tomorrow
2018,that wasnt me saying what you should work on btw wink
2018,i know haha
2018,the research group im in uses a halo findercool tools package caesar that identifies particles by indexes into the array returned by codesnippet from some experimentation i think the order of the particles in that array is changing every time i ytload my dataset does this sound right
2018,no that doesnt sound right
2018,oh dear
2018,if you can make a runnable example demonstrating the behavior youre seeing im happy to take a look
2018,perferably with a nothuge dataset slightly_smiling_face
2018,hm i suspect this is because the dataset is split across multiple files
2018,so im not sure how to repro this with a small amount of data
2018,well you dont need 13 gb
2018,this is gizmo hdf5
2018,yeah
2018,if i could lop off everything but one particle in each file i bet that could reproduce this but i dont know how to do that
2018,it looks like we dont actually have a multifile gizmo test dataset on hyperlink
2018,maybe a smaller dataset that you can share with us
2018,or thats publicly available
2018,ill try the ones at data
2018,gizmo_64 and gizmo_cosmology_plus are both time series
2018,one file per snapshot
2018,and fire_m12i_ref11 is one file
2018,oh
2018,i thought you said _we actually have_
2018,you could also share the 13 gb one
2018,split over a few files or something
2018,i think the upload size limit for codesnippet is a couple gb
2018,im gonna go home soonish but will take a look tomorrow if you get a script that triggers the issue youre seeing please create an issue on github
2018,as a mental health thing i no longer have slack installed on my phone so i dont normally look outside of business hours
2018,okay thanks ill poke around on my own and check in tomorrow
2018,i seem to recall i may have also bumped into something like this before
2018,i can have a check with a dataset and see if i can see it
2018,i can confirm i also experience this user
2018,as a temp fix you could pass in the data by sorting by a particular index ie codesnippet if present that should ensure your consistency
2018,thanks for the sanity check now to see what i can do about this i guess
2020,im trying to take advantage of the hyperion grid constructor that can load in amr grids such as enzo from a yt datasethyperlinkan issue im running into is that id like to be able to pass in a subregion of the original dataset generating a codesnippet doesnt work though since the codesnippet function in hyperion wants access to the derived_field_list and perhaps other issuesbut this was the first error thrownsince regions dont have the full attributes of a ds iecodesnippetpdb regderived_field_list attributeerror ytregion object has no attribute derived_field_listcodesnippetis it possible to construct a dslike object that is just a subregion of the original loaded ds via a bounding box or something like that
2020,yes by using codesnippet
2020,and then reloading the saved ytdata dataset youll get from that and passing that to hyperion
2020,note ive never done that before
2020,oh cool i never heard of this ill check it out right now
2020,thanks user this definitely saves though it doesnt seem like all the fields get written for examplecodesnippetimport ytds ytloadgalaxy0030ad dsall_dataprintadall creation_timeset up a regionbox_len dsquan01code_lengthcenter dsdomain_centermin_region center0box_lencenter1box_lencenter2box_lenmax_region center0box_lencenter1box_lencenter2box_lenreg dsregioncentermin_regionmax_regionnow save the region to disk as a dsregsave_as_datasettemp_enzoh5load the region back upds1 ytloadtemp_enzoh5ad1 ds1all_dataprintad1all creation_timecodesnippetreturnscodesnippetpd3env desikanarayananlogin2 galaxy0030 python reg2dspyyt info 20200116 155445046 parameters current_time 00060000200028298yt info 20200116 155445046 parameters domain_dimensions 32 32 32yt info 20200116 155445046 parameters domain_left_edge 0 0 0yt info 20200116 155445046 parameters domain_right_edge 1 1 1yt info 20200116 155445046 parameters cosmological_simulation 00parsing hierarchy 100 173173 0000lt0000 1151276itsyt info 20200116 155445071 gathering a field list this may take a moment000000000e00 000000000e00 000000000e00 137082069e16 137189892e16 137880524e16 syt info 20200116 155447169 saving field data to yt dataset temp_enzoh5yt info 20200116 155447393 parameters current_time 00060000200028298 code_timeyt info 20200116 155447393 parameters domain_dimensions 2 2 2yt info 20200116 155447393 parameters domain_left_edge 0 0 0 code_lengthyt info 20200116 155447393 parameters domain_right_edge 1 1 1 code_lengthyt info 20200116 155447394 parameters cosmological_simulation 00yt info 20200116 155447431 allocating for 0000e00 particles index particle type allyt info 20200116 155447432 identified 1000e00 octstraceback most recent call last file reg2dspy line 22 in ltmodulegt printad1all creation_time file homedesikanarayananytytdata_objectsdata_containerspy line 249 in __getitem__ f self_determine_fieldskey0 file homedesikanarayananytytdata_objectsdata_containerspy line 1335 in _determine_fields finfo selfds_get_field_infoftype fname file homedesikanarayananytytdata_objectsstatic_outputpy line 739 in _get_field_info raise ytfieldnotfoundftype fname selfytutilitiesexceptionsytfieldnotfound could not find field all creation_time in temp_enzoh5codesnippet
2020,is there maybe an argument i want to pass when saving the region or calling codesnippet that would save all of the fields
2020,i dont know offhand maybe look at the docs for the ytdata frontend or the docstring of save_as_dataset
2020,will do
2020,this slight modification workscodeblock
2020,thanks for the pointer to codesnippet user
2020,very quick question how do you save a yt figure to pdf
2020,codesnippet
2020,of course face_palmskintone2
2020,thanks smile
2020,while im at it how do you update the frbs resolution again
2020,codesnippet
2020,thatll do it thanks a lot
2020,note that the actual resolution of the figure saved by matplotlib will be determined by the dpi of the figure and the figure size
2020,yup this much i know already but thanks for pointing it out slightly_smiling_face
2020,does anyone know a way of finding the velocity dispersion of the gas particles in a particular galaxy plotted against radius
2020,im using ramses and hop catalogs
2020,i dont know if thecodeblockparameter has anything to do with it
2020,in the derived field quantities
2020,basically really confused as to how to go about getting this just for the gas mesh not particles sorry
2020,no thats the divergence not the velocity dispersion
2020,i did something like this for my phd
2020,it was easiest for me to interpolate the amr data onto a uniform resolution grid and then calculate the velocity dispersion on that uniform grid
2020,hyperlink
2020,the velocity dispersion would be very tricky to add into yt in a way that makes sense for a galaxy sim since you need to subtract away the local streaming velocity before calculating the dispersion locally
2020,but thats relatively straightforward to calculate if you know where your galaxy is and what its angular momentum vector is
2020,for 3d volume rendering is there a way to specify the aspect ratios my simulation box is a very long rectangle 1150
2020,no not really
2020,do you think that would be hard to add if thats a simple thing i could try and make a pr
2020,im not sure how youd do it
2020,i can think of hacky ways to do it eg by manually overriding the values of codesnippet codesnippet and codesnippet
2020,but i dont know if they would work offhand
2020,i dont think they do user already suggested this to me and i tried without success i ended up modifying all metadata in our output
2020,i guess another way to do it would be to make your image much narrower along your long axis you can volume render to an image with an arbitrary axis ratio
2020,oh how can i do that the only way i know is by playing with the resolution but im afraid that would result in a ridiculous resolution like 51251250
2020,yeah thats what i mean
2020,you could do it at very very high resolution along the coarse axes i guess
2020,sorry to not have an easy fix for you
2020,ok no problem ill keep my scripts to modify the metadata then slightly_smiling_face
2019,user has joined the channel
2020,user user wouldnt it be possible to compute the velocity dispersion in the 27 neighbouring cells using ghost zones
2020,yes
2020,how would i do thiswhere is the literature on ghost zones
2020,so yt does have the ability to generate fields that need ghost zones i didnt suggest that because youd have to write the fields which is hard youd also have to subtract off the local streaming velocity which might be hard to do
2020,look inside yt for fields that use codesnippet with a parameter set to a number not equal to zero
2020,but if youre only interested in the local velocity dispersion why do you want to remove the local streaming velocity it shouldnt matter that theres a bulk motion
2020,codesnippet is how yts field system generates field data with spatial locality
2020,user i found it did when i did this
2020,the velocity dispersions in disk galaxies are like 10 kms in the atomic ism but the circular velocity might be 100 kms for a mwmass galaxy
2020,but how do you define the local streaming velocity
2020,the local circular velocity
2020,its all in my paper one sec
2020,oh right that makes sense
2020,i guess it depends how you define the velocity dispersion slightly_smiling_face
2020,user if you want to use ghost zones with ramses youll have to use my branch see the pullrequest here hyperlink that adds support for ghost zones in ramses
2020,appendix a of hyperlink
2020,is the ghost zones method the only one user
2020,user
2020,so for ramses data corentin just recently added support for yt to generate ghost zones
2020,corentin was linking to the pr that implements that feature he added
2020,its not yet merged
2020,so if you want to go that route youd for now need to use a version of yt with his pr applied
2020,ok so im looking through this pr and it seems like its just making a box and then creating a projection plot of the density gradient so not sure how this is going through the neighbouring cellsnot sure what about this is the ghost zone
2020,to calculate a density gradient you need ghost zones
2020,yt can generate ghost zones any field that needs nonlocal data uses that functionality
2020,corentins pr adds that functionality for oct amr data its already there for patch amr data
2020,like heres an example of a field in yt that is generated using ghost zones hyperlink
2020,the xcomponent of the vorticity
2020,its calculated using a finite difference
2020,normally fields in yt are fully local and arent calculated using spatial data
2020,optionally they can be eg in the linked field
2020,corentins pr makes it possible to use these fields for oct amr codes
2020,in principle you could write a velocity dispersion field that uses yts ghost zone functionality
2018,is there a way to get an frb from a codesnippet object in the same way you can from a codesnippet or codesnippet
2018,it doesnt appear so but i just wanted to double check if there were a hack to get the image as a numpy array
2018,user yes its in an attribute i believe it is data
2018,oh interesting
2018,i was trying frb ill give that a shot thanks
2018,right its not exactly a frb so its called a different thing note that the x and y bins are exposed as x and y on the profile object itself not sure about on the plot object
2018,hmmnot seeing attribute hanging off it with codesnippet or any other suggestive name nor on the codesnippet object
2018,maybe im doing this wrong
2018,its somewhere in there and im reasonably certain its in the docs somewhere but im away from my computer keep looking might have an underscore likely accessible via dict like access
2018,profile
2018,its a codesnippet instance
2018,user
2018,hyperlink
2018,you can visualize it using codesnippet
2018,oh ok great
2018,thanks guys
2020,hi im having some difficulty with getting yt to run ive recently started porting stuff over to python 3 and my attempts to test have all been marred by fnv_hash it says that there is no module named that within the ytutilitieslib there are some files called fnv_hashcpdxpyx but none of those seem to be the one its looking for does anyone have a fix in mind for this fresh installations of yt seem to maintain this problem
2020,how did you install yt
2020,if it was from source did you build the cython extensions with eg codesnippet
2020,the fnv_hash is one of the c extensions in yt and those need to be compiled
2020,if you install yt from condaforge or via pip youll get a binary distribution where all of these c bits have already been compiled
2020,ah gotcha i forgot to build
2020,whoops
2020,wait no i did use pip to install yt
2020,unless youre not supposed to do pip install yt anymore
2020,here ill include some screenshots of my yt folder
2020,no you are
2020,or you can anyway
2020,what specific commands did you enter to install yt
2020,pip install yt
2020,
2020,here are the two pictures
2020,
2020,ok it looks like it installed correctly on windows the compiled code is in the pyd files
2020,what errors do you get when you try to import yt
2020,if you can copypaste them or screenshot them that would help me to see exactly what youre doing and whats going wrong
2020,so running pip from the command line give me
2020,error command errored out with exit status 1 command cusersalbertoappdatalocalprogramspythonpython38pythonexe c import sys setuptools tokenize sysargv0 cusersalbertoappdatalocaltemppipinstallk664m7quytsetuppy __file__cusersalbertoappdatalocaltemppipinstallk664m7quytsetuppyfgetattrtokenize open open__file__codefreadreplacern nfcloseexeccompilecode __file__ exec egg_info eggbase cusersalbertoappdatalocaltemppipinstallk664m7quytpipegginfo cwd cusersalbertoappdatalocaltemppipinstallk664m7quyt complete output 26 lines traceback most recent call last file cusersalbertoappdatalocalprogramspythonpython38libsitepackagessetuptoolsmsvcpy line 489 in _find_latest_available_vc_ver return selffind_available_vc_vers1 indexerror list index out of range
2020,but running from a different command line works fine
2020,which is the yt files im using now
2020,it looks like setuptools is broken in what you copypasted
2020,do you have more than one python environment it sort of sounds like you installed yt with one version of python but are importing it with another
2020,just a guess though its hard to debug stuff like this over the internet
2020,thats probably the case im trying to get python 38 working but maybe the installation was done with my 37 environment instead
2020,in which case how should i handle the fact that pip doesnt seem to want to work for python 38
2020,worse comes to worse i can just go back to 37
2020,is what you copypasted all you see
2020,pretty much
2020,googling your error message leads to threads where theres also a mention about needing msvc c 140
2020,ah yeah
2020,yt doesnt have python38 wheels yet do we
2020,ah well in that case ill just drop back to 37
2020,not a big deal
2020,so youre not getting a wheel and pip is dying when it tries to build yt from source because you dont have the compilers installed
2020,if you install the compilers it should work fwiw
2020,gotcha alright well thanks for the help
2020,have a nice weekend
2020,hyperlink
2020,you too
2019,user has joined the channel
2019,hi im trying to load gizmo data into yt but when i try to do anything with the loaded data i get a zerodivisionerror float division heres the full traceback
2019,hi user is this error reproduceable with one of the yt sample datasetshyperlinkalso do you mind sharing the full script please
2019,sure here you go
2019,heres a picture of the rest of it im not sure if its reproducible with yt sample data ill try
2019,heres the data set if that will help
2019,ah what version of yt are you using im using yt 4x which is still in devlepment mode and am able to get this snapshot to loadcodesnippetin 4 dsfield_listyt info 20190313 093507767 allocating for 2700e04 particlesyt info 20190313 093507767 bounding box cannot be inferred from metadata reading particle positions to infer bounding boxyt info 20190313 093507774 load this dataset with bounding_box099254775 099533606 099219495 099507153 099014074 09967863 to avoid io overhead from inferring bounding_boxout4parttype0 coordinates parttype0 density parttype0 internalenergy parttype0 masses parttype0 particlechildidsnumber parttype0 particleidgenerationnumber parttype0 particleids parttype0 smoothinglength parttype0 velocities all coordinates all density all internalenergy all masses all particlechildidsnumber all particleidgenerationnumber all particleids all smoothinglength all velocitiescodesnippet
2019,so i wonder if there was an issue that was resolved in one of the commits between where you are and the code version im using
2019,oh that
2019,thats great im using 351 and the same thing happened with the yt sample dataset gizmo_mhd_mwdisk
2019,awesome i dont know what version this issue was fixed in but the first thing i would try to do is update yt really quickly to see if that fixes it
2019,i can also dig up the 4x installation instructions too
2019,yeah could i have the 4x installation instructions 351 is the latest version at least according to anaconda
2019,i think this is ithyperlink
2019,i think through step 4 is sufficient
2019,awesome thanks so much
2019,cool hopefully this works let me know
2019,ok i will after i get through these annoying installation problems
2019,hi just coming into this discussion now
2019,let me try and download your test dataset and see if i can reproduce the issue
2019,if this is happening with yt 351 we should try to fix it there
2019,yt 40 hasnt been released yet so i dont think we should direct people to that in this channel unless they really need it
2019,or theyre interested in helping out with development
2019,ah i see so this is the expected behavior in yt 3x and it is something that was fixed in 40
2019,for noncosmological gadget datasets you need to specify the bounding box when you load the dataset
2019,in yt 40 we added a thing to do an io pass over the data and compute a sufficiently large bounding box
2019,so yeah in principle we could fix this in master but probably not worth the effort since it would be a fair bit of work
2019,it looks like this working in yt 3x
2019,codesnippetds ytloadsnapshot_000hdf5 bounding_box1 1 1 1 1 1codesnippet
2019,user
2019,ah sorry i had missed that this wasnt a cosmological data seti should have seen taht
2019,awesome thanks
2019,hi guys hopefully a quick one i am trying to find the percent of the plt file the corresponds to each level of amr is there a quick way of doing this i was trying to use codesnippet to attempt this but i cant find a way for the field to be profile to be something like count as opposed to a field variable
2019,user yup you can probably come up with a quicker estimate which includes overlappingrefined zones by doing codesnippet but a profile of codesnippet with codesnippet will also show you an unweighted summation
2019,but not overlappingrefined
2019,you could also look at the codesnippet field
2019,codesnippet means that the profile is a sum over field values
2019,and not a weighted average
2019,so you could make a 1d profile where the x bins are the codesnippet field and the profiled field is codesnippet
2019,oh a profile of ones that would make sense how would implement that exactly right now i have something like codesnippet but what would i change the codesnippet to to get ones
2019,codesnippet
2019,perfect i will give that a try thanks
2019,you might need to set codesnippet or the codesnippet to get the binning you want slightly_smiling_face
2019,probably want to make grid_level be nonlogged too i imagine slightly_smiling_face
2019,yeah that too slightly_smiling_face
2019,codesnippet
2019,yep i got those adjustments
2020,heyim trying to install yt40
2020,using codesnippetgit clone hyperlinkcd ytgit checkout yt40git pullpip install user e cd codesnippet
2020,im attaching the error message that comes when i do the codesnippet
2020,any ideas why this is happening
2020,thanks
2020,hi i would suggest trying to upgrade conda codesnippet andor pip codesnippet though tbf im not sure whats causing your error
2019,i am no expert in sfr in yt but isnt it because the smallest lookback time is codesnippet this is because you bin stellar particles by formation time and the codesnippet is the central value of each bin so anything that formed between codesnippet and codesnippet ago falls in the same bin which is assigned a codesnippet of codesnippet
2020,there has been a lot of confusion in the trident community about how to best install yt4 from scratch so im updating the installation instructions for both trident and yt4 it used to be that yt4 required the codesnippet package where one had to download the github repository and install it locally i see there is now a pip package for codesnippet is that currently a dependency of yt4 or has that code been brought directly into yt i just want to know if i should have users install it explicitly thanks in advance
2020,or maybe someone has already updated the yt installation docs for the yt4 branch if thats the case can someone just point me to them
2020,yeah as im trying to build yt4 from scratch on a vanilla ubuntu install im getting failures even seemingly unrelated to cykdtree so id love to chat with people about the proper yt4 installation procedures ive been going off modifications on what used to be the gold standard for installing yt4 the trident demesh instuctions hyperlink
2020,is there something messing with the slice plot function
2020,codesnippetsp3 dsspherecenter048741004756570497294 radius500 kpcproj3 ytprojectionplotds y gas density centersp3center width80 kpc data_sourcesp3codesnippetyields
2020,whereascodeblockyields
2020,and this image comes out whether or not im setting data_sourcesp3 or using the center as centersp3center
2020,and similar things are happening for a lot of other galaxies
2020,this is a ramses dataset
2020,user has joined the channel
2018,user yeah right nowits hard i think we can make it better but i dont know if i have the bandwidth to lead it right now want to chat about it a bit and see if its in your wheelhouse
2019,thank you for addressing the issue
2019,user has joined the channel
2018,user is there a way to query a unit registry object for all units of the same dimensionality that already exist
2018,other than iterating and checking if theyre equivalent i mean
2018,this seems to work
2018,codesnippet
2018,where codesnippet is imported from ytunitsdimensions
2018,ah thats very concise thank you
2018,id take a pr that added that as a method on the codesnippet class if you want to make that a helper method or something
2018,i will indeed do that
2019,user unk but would be worth doing if you have sample data i can whip something up after next weds
2019,oh cool i dont yet but am working with mike tremmel to see if hes got any equivalent data sets that are both tipsy and nchilada format for powderday input ill definitely pass on when i get them from him
2019,user has joined the channel
2019,is the image in this paragraph supposed to have a quiver field on it hyperlink
2019,user it is and it used to see hyperlink looks like a regression
2020,user has joined the channel
2020,user i have just started using yt for the past few weeks i am trying to extract data points along a line between 2 points
2020,codesnippetimport ytfrom ytunits import kpcds ytloadusersn22dummyprecision_415pltgvdsprint_statsdsfield_listprint dsfield_listpoint_obj dspoint100 0019 095kpcdensity_at_point point_objdurationray dsray8 0 08 9 05 08printraydurationprintdensity_at_pointcodesnippet
2020,i am not sure what i am doing wrong in here
2020,it doesnt print the data it just says dimensionless
2020,codesnippetyt info 20200515 095825582 parameters current_time 300yt info 20200515 095825583 parameters domain_dimensions 1001 39 51yt info 20200515 095825583 parameters domain_left_edge 0 0 1yt info 20200515 095825583 parameters domain_right_edge 20 075 0 level grids cells cells3 0 136 1990989 126 136 1990989t 300000000e01 300000000e01 s 950642634e07 yearssmallest cell width 6475e27 mpc width 6475e21 pc width 1336e15 au width 1998e02 cmboxlib g boxlib v boxlib duration boxlib ex boxlib ey boxlib ez dimensionlesscodesnippet
2020,i want to extract the data for duration along a line between 2 points
2020,arent your points out of the domain
2020,codesnippetyt info 20200515 095825583 parameters domain_left_edge 0 0 1yt info 20200515 095825583 parameters domain_right_edge 20 075 0 codesnippet
2020,ah my bad works good is there a way to print corresponding coordinates
2020,what do you mean with corresponding you can use codesnippet and codesnippet i believe
2020,the ray function spits out the following data i would like to extract the corresponding x y z coordinates for each data point
2020,codesnippet149536445 13892176 123081842 105004701 086141738 067979444 052100306 038255975 02683003 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 codesnippet
2020,user ah thats a good question the ray will give you the t along its length as well which is the parameter along the starttoend scaled 0 1 at which it enters a given cell
2020,so if you query codesnippet or codesnippet or codesnippet that is the cell center which means they wont necessarily monotonically increasedecrease along the ray but you can also compute the specific location by taking codesnippet and multiplying it by the codesnippet and adding codesnippet
2020,ok let me check in this case all i want to do is to check the length of the ray where the data point becomes zero
2020,hi may i ask you a question about the code below what does this error mean pleaseerror the data dict appears to be invalid the data dictionary must map from field names to numpy array unit spec tuplesand how to correct itmany thankscodesnippetimport numpy as npimport matplotlibpyplot as pltfrom numpy import arrayfrom scipyinterpolate import regulargridinterpolatorinterpn from scipyintegrate import solve_ivp rungekutta method import matplotlib as mplfrom mpl_toolkitsmplot3d import axes3d 3d graphfrom mpl_toolkitsmplot3d import proj3d 3d graphfrom matplotlibpatches import fancyarrowpatchimport matplotlibpatches as mpatchesimport mathfrom matplotlib import patchesimport codeimport ytfrom yt import ytarray arrays in yt modulefrom ytvisualizationapi import streamlines force linesimport matplotlibpylab as pl configuration filefrom configparser import configparsercfg configparsercfgreadsettingcfg font settingimport font constantsq 16e19 electron chargem 91e31 electron massv_par 2000 parallel volocity v_per 2000 perpendicular velocitynum 150 grid resolution x0npzeros6 vector 6 dim give zeros into it 3 components positions 3 components velocitydef get_bgrid b_theta 0 if grid2any lt 0 b_z grid0 b_r 0 elif grid2any lt nppi b_z 025 grid0 npcosgrid2 075 grid0 b_r 0253 grid0 grid0 npsingrid2 else b_z 05 grid0 b_r 0 return b_r b_theta b_zimport numpy as np grid limitsrmin 0000001rmax 1theta_min 0theta_max 2nppizmin 0zmax 2 definition of spacer nplinspacermin rmax num numtheta nplinspacetheta_min theta_max num numz nplinspacezmin zmax num numb_r b_theta b_z get_bgridnpmeshgridr theta zprintb_rprinttypeb_rprintb_rshape choose point in field where force line will be integratedr_point 0025theta_point 005nppiz_point 0 dictionary of numpy arrays magnetic field datadata dictb1b_r b2b_theta b3b_z b_r datab1b_theta datab1b_z datab1printdata 3d array of dipole magnetic field bbox nparray015 015 0 02 01 01 borderds ytload_uniform_griddata b_rshape length_unitmpc bboxbbox nprocs100 data dimenzecodesnippet
2020,in codesnippet your codesnippet is equal to a scalar 0
2020,thank you very much
2020,user has joined the channel
2020,and this please i got an error one of the requested xi is out of bounds in dimension 0the script creates a magnetic fields and then should compute streamlines with yt in given point and then it should compute the trajectory of the particle which initial position and velocities are in the list x0 x00 means radius and this value is negative row 168 is the problem in the setting of bbox for streamlines many thankshyperlink
2019,user has joined the channel
2019,yes lets do tuesday 10am pst
2019,ok sorry for making this difficult but im tied up at 10am tomorrow too now with a student after that the quarter is over though later tuesday afternoon would work for me
2019,no worries tomorrow later in the day is pretty bad but weds i could do around 315pm
2019,er thats central which would be 115pm your time
2019,ok sounds good my number is 19167492940
2019,in ytree is there a way to add a vector analysis fields id like to calculate and save density and temperature profiles for some halos in the arbor if possible user
2018,hi i am trying to use feed vtr data into yt which i have read and parsed the data is from a finite difference cfd simulation fluid field the cfd mesh is rectilinear i have an array of grid point positions and field values at that position what would be the best way to load the data into yt i am trying to use load_particles but i get the following error
2018,
2018,this is a single uniform resolution grid if so you want to use codesnippet
2018,if its an amr simulation you want to use codesnippet
2018,sometimes i use grid stretching so the grid points are not uniformly distributed
2018,its not amr
2018,ah ok then codesnippet
2018,theres a helper function to calculate the connectivity if you dont already have it
2018,hyperlink
2018,thanks user
2018,hi all i would like to know if it is possible to plot a line on a phaseplot
2018,i can pass the data to load_hexagonal_mesh fine but i cannot seem to plot the field properly
2018,
2018,how can i probe the data stored in ds
2018,hello all i have a question regarding assigning a colorbar to an rgb image if i recall correctly then whatever i get from the projection operation in yt is an image and i do not have any issues assigning a colormap to the result now when reading in an rgb image what is the best way to assign a color map to this because the colormap that i plot for it is disconnected from the rgb data what is the difference between the yt image that i got through projection projto_frb and the rgb image
2018,user this is 2d data can you give it some extent in z
2018,user to get an rgb image using a colorbar from a grayscale image you can do something like this
2018,
2018,also sorry but small gripe screenshots of jupyter notebooks make me sad
2018,you can share notebooks with github gists or with nbviewer
2019,hello i was wondering how i could best view a dat file as an image
2019,also i tried to use ytload to load a dataset but it doesnt recognise the format what can i do
2019,what sort of data is this
2019,dat is a file extension we need a bit more info to help where did the file come from what style of data is it gridded particle unstructured mesh
2019,when you say you want to view it as an image you mean to want to make a slice through a 3d grid or does the original data file represent a 2d image
2019,user has joined the channel
2020,user is this a bug and should i report this
2020,please do although im not 100 sure its a bug i think a bug report would be a good place to walk through it however
2020,hi all i am having a difficult time with gradient fields in yt particularly i am looking at the divergence of velocity and using yt vs the computed within the code amrex based i would expect the fields to be just about exactly the same since both yt and the code use simple centered differences
2020,
2020,the first one divupng is from the code and the second one velocity_divergencepng is from yt
2020,any thoughts on what this could be
2019,hi all how do i change the font size of my legend and axis labels i found the solution suggested before through the use of the label in my_labels loop however it does not work once i use codesnippet i tried changing the order as well but to no avail can someone help
2019,codesnippet
2019,i think if you do codesnippet before applying your customizations it would also work so long as your customizations are the last thing that happen before you call codesnippet
2019,you can also construct the plot manually using matplotlib and the profile objects sometimes thats simpler codesnippet is there mostly for making quick plots
2019,codesnippet has the ability to output 2d slices through the simulation domain in a specific variable eg density loading such a slice into codesnippet gives a dataset with codesnippet returning the dimensions of the entire 3d mesh while codesnippet and codesnippet return the full extent of the simulation domain where really the slice only contains data through the midplane z0 of the simulation my question is there a way to plot the x and y density gradients from such a 2d slice of density i tried setting codesnippet but codesnippet reportscodeblockwhen attempting codesnippet
2019,i think by adding support in yt for data like this cc user dunno offhand if theres a workaround without modifying the athena frontend in yt
2019,thanks user
2019,user is there an example file you can share
2019,attached
2019,
2018,user has joined the channel
2018,having a little trouble building the docs not sure what it isnt finding output hyperlink log file hyperlink
2018,so its dying in the confighelp extension not sure why its doing that
2018,but you can turn it off in the sphinx confpy file
2018,codesnippetextensions sphinxextautodoc sphinxextintersphinx sphinxextmathjax sphinxextviewcode sphinxextnapoleon yt_cookbook yt_colormaps config_help yt_showfieldscodesnippet
2018,just delete codesnippet
2018,thats in codesnippet
2018,awesome that worked thanks
2018,off to the ncsa staff picnic if you run into more issues ill get back to you eventually slightly_smiling_face
2018,question about how yt handles memory if i want to say make a projection do i need to have available at least as much memory as the size of that output slices presumably take lessis there a good way to estimate how much memory ill need for slice
2018,for enzo data
2018,yes
2018,slices need to read in data from the grids the slice intersects with
2018,projections need to read in data from every grid unless you use a codesnippet
2018,right but does it happen all at once in the projection
2018,no theres a loop hyperlink
2018,im not sure offhand how much ram the codesnippet object needs though
2018,i guess it might be a lot depending on your amr hierarchy
2018,the codesnippet is a 2d representation of the projected amr hierarchy
2018,its a resolveeverywhere cosmological box not a zoom
2018,how many grids are there
2018,codesnippet
2018,lots
2018,each chunk in that loop over chunks should be a collection of grids
2018,i dont often work with enzo data that big its possible theres a scaling issue youre running into id need to measure
2018,it looks like theres a debug logging statement you could look at which says how much memory the quadtree is using
2018,i havent even tried to do anything yet because its a big dataset and i need to figure out how many nodes etc to request
2018,ah i see
2018,waiting on an interactive node to get a more precise estimate of number of grids
2018,yeah if the interactive node is bigmem you could measure by looking at top
2018,i mean if it has a ton of ram like 512 gb or something enough to hold the whole field in memory
2018,whatever field youre projecting
2018,oh no it doesnt
2018,oooh thats a good point though if im just projecting say density i dont have to read the entire thing into memory just the fraction that is density info
2018,yeah just the one field
2018,we also need to have the amr hierarchy in memory
2018,but if its less than a million grids that doesnt matter
2018,i think its several hundred thousand i had to increase maxsubgrids to 400000 any guess for a regular enzo dataset what the fraction of the total data volume would be one field
2018,it depends on eg how many species fields there are
2018,maximum a fifth or so i guess
2018,density vx vy vx internal energy
2018,and then however many species fields you have
2018,and particle fields too
2018,nod
2018,and if you have a ton of dark matter particles the particle fields can actually be the bulk of the data ondisk
2018,i probably do have a ton of dark matter particles
2018,many minutes later i have 261406 grids but this helps me estimate how much i need thanks
2018,thats pretty big slightly_smiling_face
2018,it just started smile
2018,projections should be memory conservative but the large number of grids can be a bottleneck like nathan said its possible there is a caching of coordinate info somewhere which ill take a look at that could also lead to memory overhead
2019,user has joined the channel
2020,i am wondering why the points in the plot that do not correspond to my grid domain as showing up in purple and not just transparant they seem to be set to zero values my color bar lower range is 265 kmsany way i can remove this i triedcodesnippetcodesnippetas the documentation says if unset background color is set to the bottom value of the color map which seems to correspond with what i have but that doesnt seem to do anything though i dont have any more ideas to try
2020,user interestingly i think that it has changed in very recent versions so that the polar plots have white by default for the background
2020,weird but the set_background_color should normally work
2020,it should yes can you try recreating this using a dataset formed by codesnippet or spherical
2020,i currently dont have access to my laptop i will try when i am home
2020,user has joined the channel
2018,short questionis there an easy way to rotate a projection slice plot
2018,you mean at an arbitrary angle or you just want to flip the axes
2018,for the former use an offaxis sliceprojection plot and set the north_vector
2018,for the latter something like this
2018,codesnippetin 1 dscoordinatesx_axisz 1in 2 dscoordinatesx_axis2 1in 3 dscoordinatesy_axisz 0in 4 dscoordinatesy_axis2 0in 5 plot ytsliceplotds z densityin 6 plotsaveout6 galaxy0030_slice_z_densitypngcodesnippet
2018,hyperlink
2018,here x gt 0 y gt 1 z gt 2
2018,user
2018,thanks
2018,does sliceplot have any internal resolution setting
2018,eg does it make a frb along the way
2018,yes
2018,slcset_buff_size lets you control the resolution of the frb
2018,thanks
2018,slcfrb is a reference to the frb object
2018,im 12288 zones across
2018,so i want more pixels
2018,also keep in mind that matplotlib doesnt let us directly control the resolution of the image you get back from codesnippet
2018,sure
2018,so you also would need to set the dpi via the codesnippet keyword argument to codesnippet and the figure size via codesnippet
2018,i embiggened the figure
2018,or you can just get the image buffer from the frb and handle that manually
2018,also mike its so effing humid in new york today
2018,your state hates me
2018,yeah
2018,where are you
2018,nyc
2018,currently at my grandmothers apartment
2018,i thought for sure matt would like my embiggen reference
2018,tragically there are no simpsons emojis installed on this slack group smile
2018,there is hypnotoad
2018,user perfectly cromulant reaction emoji
2018,user has joined the channel
2018,hey user i wanted to come back to this if you have a chance i have a working version of the conversion that steps through tree by tree then node by node within each tree because its a triple quad nested for loop though its kinda unbearably slowi think that at the end of the day what i need is just a way to expose the raw data in all the nodes across all the trees is this stored anywhere in ytree i can get a list of all the nodes by doingcodesnippetall_nodes arborselect_halostreetree uidgt0codesnippetbut this seems hacky and like there should be a better way additionally id need to do something likecodesnippetvals nparraynodekey for node in all_nodescodesnippetin order to build the type of array that im looking forideally these arrays would be sorted by codesnippet which does seem unique across the entire arbor such that codesnippet gives you the value for halo codesnippet but i can handle the sorting if need beis the data for all of the nodes exposed anywhere in this way
2019,user i suspect i know what the deal is with this but wont be able to look for a few hours my guess is that its reading an empty chunk not sure why and perhaps it just needs to continue
2018,hi folks quick question
2018,at one point it was easy to plot a 1d phase plot ie line plot over a 2d phase plot
2018,so one could show eg both the distribution and the mean values
2018,i cannot find that in the docs any more is this feature gone
2018,i mean you can always go back to raw matplotlib and do it but if theres a very simple way to do it im not seeing it
2018,i dont think it was ever documented
2018,i also dont thin it would be hard to add a helper that does that
2018,gotcha one of my grad students was asking me about it and i wasnt seeing it anywhere
2018,thanks
2018,im pretty sure if anyone did it before they did it manually with matplotlib
2018,my memory is definitely failing me then
2018,thanks
2018,i want to do an operation between a ytarray and a numpyndarray i know the units are right is there a better way than just passing the ytarray to codesnippet to remove the units
2018,user theres a shorthand for getting raw ndarray out of ytarray codesnippet
2018,codesnippet
2018,whats the difference between codesnippet and codesnippet
2018,d returns a view
2018,v returns a copy
2018,codesnippet is short for codesnippet
2018,and codesnippet is short for codesnippet
2018,i see
2018,user has joined the channel
2018,user has joined the channel
2018,user has joined the channel
2018,user has joined the channel
2018,thanks i think my netcdf4 package is uptodate my workaround was indeed to run the script on a machine which did not have netcdf4 installed
2018,user has joined the channel
2018,hi all should i expect to be able to run the clump finder on data from ramses im getting codesnippet from codesnippet and before i spend too much time debugging i wanted to check if what im trying to do just isnt supported
2018,oh no that wont work sorry disappointed
2018,one way to do this is to save the data as a covering grid or arbitrary grid and reload that resampled data using codesnippet
2018,but yes sorry the clump finder only works with block amr data like enzo or flash not octree amr data
2018,the codesnippet approach basically reloads your data as a patch amr dataset
2018,i think you could use codesnippet as well
2018,britton will probably chime in with ideas slightly_smiling_face
2018,nathan do you have a sense for what it would take to make this work straight away with octree data
2018,saving the covering grid with codesnippet should work for the clump finder though i havent tested it
2018,it will definitely be helpful for preserving the unit systems of the dataset
2018,ok great ill give that a go slightly_smiling_face thanks
2018,user we need a way to generate ghost zones for octree amr data
2018,user has ideas specifically for ramses data
2018,we really need ghost zones because the blocks are so small basically the entire volume needs data from neighboring blocks to get decent facecentered data estimates
2018,ah i see ok
2018,in matplotlib i can write multiple plots to a single pdf document using a pdfpages is there a way to do this with a projectionplot
2018,first ive heard of codesnippet maybe i could hack together an example
2018,i was kinda hoping thered be some underlying matplotlib handle i could grab but i cant quite follow the inheritance structure here it smells like theres a matplotlib figure or something involved but i cant find it
2018,ah cool this appears to work
2018,codesnippetplot ytsliceplotds z density temperaturewith pdfpagesmultipagepdf as pdf pdfsavefigfigureplotplotsdensityfigure pdfsavefigfigureplotplotstemperaturefigurecodesnippet
2018,user
2018,i was a little worried that it only worked with pyplot but codesnippet takes a codesnippet keyword argument so we just need to pass a reference to the matplotlib figure containing the yt plot
2018,since this isnt going through yts save function there might be some small amount of rendering weirdness
2018,in particular i doubt the math fonts will come out correctly unless you also use the matplotlib style context manager yt uses to override matplotlibs defaults
2018,call you point me to this context manager
2018,its codesnippet heres the place in the code it gets used hyperlink
2018,you would say codesnippet
2018,i wish it wasnt necessary to do that
2018,but unfortunately matplotlib doesnt have an api to set that without going through the style system
2018,hyperlink
2018,at one point we had a codesnippet thing that worked with oldschool codesnippet i think but it was not as nice as what youre doing here
2018,im trying to fiddle around and its taking an hour to generate a single projectionplot any suggestions on what i can do to cut that down doesnt have to be pretty
2018,just trying to get a feel for things here
2018,use a smaller test dataset
2018,eg codesnippet
2018,use a region to select only a subset of the data
2018,is this an sph dataset
2018,if it is you could try the yt40 branch
2018,which will be like two orders of magnitude faster depending on the data size
2018,gizmo so yes ill check out the branch
2018,it seems like projectionplot is making a projection of the whole simulation even though i just want 5x5 kpc
2018,yeah then definitely check out yt40 for gizmo processing its the way to go user
2018,if you need help on installing check out this hyperlink
2018,also see ytep0032 and my and meagan langs scipy 2017 talk
2018,we also chat about demeshening stuff in the c046hvb59particles channel
2018,the scipy talk is on youtube
2018,wow that makes a huge difference
2018,pretty much two orders of magnitude
2018,1 hour gt 4 minutes
2018,user ive been using 40 for mostly everything or at least trying to its great
2018,yes i use yt40 exclusively for my fire analysis
2018,also for reference the ytep and scipy talks are linked in the demesh notebook
2018,user has a way to make it oncpus faster by using openmp
2020,thanks for your reply editing rockstarpy and the rockstar interface worked for me but yes yt cant read the particle datauser pygadgetreader seems to be capable of doing so thank you for letting me know
2020,awesome glad to hear
2020,when i use npdot on two ytarrays the units dont seem to combine correctly for example calling hyperlinkdotarray_with_velocity_units array_with_length_units produces an array with velocity units not an array with l2s i was wondering what i was doing wrong
2020,nevermind i think i figured it out
2019,user has joined the channel
2018,user has joined the channel
2018,question related to codesnippet if i have a simulation that is 643 with one level of amr codesnippet and codesnippet should return the same thing right
2018,user yes although there may be very minor differences around single precision level
2018,assuming xloxhi etc are 0 and 1 that is
2018,okay thanks user i am writing up some code to do an analysis that can change between the two functions simply this way i can see if scaling up the number of cores and running out of ram is the actual cause for codesnippet not giving all the data but also not producing an error
2018,user ahh great idea
2018,i should note there is also one very significant difference codesnippet will always generate an codesnippet object which is why it will be different codesnippet is generated differently
2018,thanks but the resulting data should be the same minus some differences about 1e8 level for single precision and maybe needing to transpose data right
2018,should be
2018,okay cool ill keep you updated
2019,user has joined the channel
2020,do you know an easy way to get plancks constant and the speed of light from yt without having to define them myself
2020,hi userin yt version 36 you can get physical constants from ytunitsphysical_constants for instancecodesnippetimport yth_planck ytunitsphysical_constantsplanck_constant_cgsc_light ytunitsphysical_constantsccodesnippetin previous versions they are in ytunits instead of ytunitsphysical_constantsalternatively you can use the standalone unyt module which was derived from yts unit system hyperlink
2020,im trying to render 2 different fields with different colormaps defined in the transfer function but the resulting image always seems to use a single colormap
2020,heres an image
2020,i made 2 regions and the density is in region 1 on the left and temperature in region 2 on the right
2020,heres the code
2020,any suggestions on how to get it to use different colormaps in each region
2020,nevermind
2020,turns out i didnt understand the colormaps i was using
2020,it is doing the proper thing
2020,carry on
2020,user has joined the channel
2018,ah sorry user i accidentally signed out of yt slack last week will try to see if the bug still exists with the test datasets and send along an example script thanks
2018,hi im currently the only person working on bringing codesnippetto codesnippet and the task proved too vast for myself alone given the time i can afford to dedicate to it im planning on selling codesnippet out too my dev community next time we gather to discuss our code so i was wondering if there exists some material designed to that end like a letter titled _why you should use codesnippet and not rewrite the wheel for the nth time in your career_ or something if not at least i know i wont be wasting my time when i write a presentation on this very matter slightly_smiling_faceof course the website in itself is a wonderful place to start but im looking for something more developer oriented that will make them feel like its a burden out of their workflow instead of an additional task they will never complete
2018,a few of us have given public talks about yt with slides available on the web maybe something like that would be a good thing to show i think user gave one pretty recently i have one from a few years ago now i can try to dig it up
2018,this is quite out of date i think nathans would be better its aroundhyperlink
2018,i dont know how its out of date but it sure is some quality material i definitely can use this thank you very much ok_hand
2018,user ive reported the issue on github using one of the test datasets slightly_smiling_face
2018,thanks
2018,youre very welcome its out of date in that there are more supported codes and quite a bit moreimproved functionality since i gave this about 35 years ago i think the philosophy is still the same ie that we take many different data formats and allow you to think of physically meaningful structures etc
2018,im uploading my slides you might also want to look at matts paper on community building which i think is relevant
2018,hyperlink
2018,aaaaah you outquicked me nathan i was nearly there smile
2018,you already sent me this a few weeks back very interesting paper indeed and very relevant
2018,hyperlink
2018,thank you both very much
2018,ill keep you tuned
2018,ive got some slides for a presentation that i gave for an astro visualization conference 6 months ago im happy to share them with you if you want
2018,its a bunch of cool images and movies with some explanation as to the methods so maybe not exactly what youre looking for
2018,but its 140 mb so let me know if you are interested and ill upload them to you no worries if not though
2018,iirc users talk at the 2015 stsci conference mocking the universe hyperlink probably touched on many of these ideas
2018,thanks mollyone thing to note about that talk is that i misspoke and did not mention cameron when i was talking about folks there that had contributed i think his name is there in the slides but i messed up with verbal attribution
2018,user id be happy to share my slides from various talks or chat too i am on a phone but will send them up here when i get out a keyboard
2020,sorry to bring this up again after so many weeks didnt have time to work on it for a whilebut i was wondering if you have found any other problemsim still not convinced things are working properly the normalization is still not right i get 06 of cosmic mean at z 2 and 026 at z 3 ive tested this with both illustris and tng in both cases taking the smoothing length from mrho13 and increasing or decreasing the number of grid cells does not make much of a difference
2020,hi robin yes i have been working on thismy initial results so far seem to suggest codesnippet smoothing with codesnippet should return answers which are very close to the cosmic meanhowever ive identified a few issues with codesnippet but i need to think about the best way to fix them
2020,the answer will never be exactly equal to the value from the simulations as the simulations solve an equation iteratively for density and smoothing length see eq 398 of hyperlink we dont do that we just take the smoothing length to be the distance to the 32nd nearest neighbour we also use a different kernel as such it is not clear the answers should ever perfectly agreei think if codesnippet smoothing is enabled then things should be close
2020,im tracking the issue here hyperlink and ive been spending a bit of time on it switching to eq 9 of the splash paper may also improve agreement but im yet to implement that
2020,thank you for continuing to work on thisalthough i agree that it will never come out exactly the same as the critical density for the reasons you mentioned i would expect the difference to be more on the order of a few percent not factors of 26 that i am still getting with gather smoothing its also a bit worrisome that it gets worse with increasing redshiftwhich simulation are you using for the tests and have you tried it on multiple redshift snapshots
2020,hey what is the procedure one should use to make a fixedgrid interpolation of data from an sph simulation
2020,i think typically you use sph codesnippet and you can use either the codesnippet technique or the codesnippet the codesnippet is more sph in nature eg no chance of zero density anywhere but is a little slower the codesnippet in yt can do this
2020,and what if i want to deposit the dark matter particles
2020,oh nevermind it just works
2020,in a smoothed way or summed
2020,i wanted to do the same as cic deposition for dm particle onto a fixedresolution mesh for a gadget dataset
2020,but i guess this code does this doesnt itcodesnippetimport ytds ytloadsomepathfoohdf5grid dsr128j 128j 128jgridparttype0 particle_masscodesnippet
2020,yeah or maybe you can force with codesnippet
2020,following hyperlink
2020,i guess you want codesnippet but yeah
2020,arent codesnippet gas particles
2020,yeah i just used them as thats what you pasted in your example
2020,i guess codesnippet is what you want
2020,correct i made a typo sorry for the confusion i was inquiring about dm particles so the codesnippet should have been codesnippet
2020,btw it it normal that for codesnippet ie gas particles a keyerror is raised when i try to do codesnippet with error message codesnippet
2020,yeah i expect that
2020,because if we detect a codesnippet we default to sph smoothing
2020,we should probably add something which allows that to be overridden
2020,and lets gas be treated like any other particle if the user really wants that
2020,gotcha
2020,well for sph newbies like me its probably for the best that you cant easily use gas particles as regular pointlike ones otherwise i would have just used them this way and would have missed all the amazing stuff you coded for sph particles
2020,maybe it would be worth changing the error tocodeblock
2020,wdyt
2020,yeah agreed and we should probably add a way to force them to point particles if the user is certain they want that
2020,it just got me super confused because for me codesnippet is _not_ a particle type so i am not expecting yt to treat it as such
2020,and so i wrongly assumed their was a bug or something instead of going forth and trying codesnippet
2020,yeah its a bit wierd in the internals the codesnippet gets turned into something else and its the something else which is then getting errord
2020,this function is where it happens hyperlinkit sort of sniffs out a codesnippet and then wrongly assumes the input is in the formatcodesnippet
2020,so another question how would one deposit dm particle _as_ sph particles
2020,is codesnippet doing the trick
2020,i think so but i think youd have to do this firstcodesnippet reload dm particles into a stream datasetad dsall_datapt parttype1fields particle_mass fparticle_position_ax for ax in xyzdata field adpt field for field in fieldsds_dm ytload_particlesdata data_sourcead generate the missing sph fieldsds_dmadd_sph_fieldscodesnippet
2020,following hyperlink
2020,thanks that seems to be working slightly_smiling_face
2020,awesome user worked really hard on this stuff
2019,is there a way to run rockstar halo finder on different snapshots one by one and save the halo catalogs in the same directory instead of overwriting them
2019,thank you this is very helpful
2020,user where did you clone it to you could check if codesnippet contains the folder where you installed it to and if not append it to it as a test
2016,user has joined the channel
2016,user set the channel purpose getting help with yt
2019,good morning i want to make a movie that shows two slice plots sidebyside how can i combine two slice plots into one
2019,user my usual way is to use fixed resolution buffers directly and operate on them in matplotlib to create image i want
2019,hyperlink
2019,user thanks
2019,if you already used sliceplot or projectionplot they also expose the buffer via frb attribute
2019,user has joined the channel
2017,user has joined the channel
2020,thank u guys for ur help i will
2019,user unfortunately i dont know the answer to your question the best to ask is user i guess though some people may be away during august
2019,user you can load a uniform grid into yt see details here hyperlink which you can then use to do volume rendering see details here hyperlink
2019,hi user im happy to try and help out im around generally but im in the uk so there will probably be a delay in getting back to you if its late here
2019,as to your question this is mostly in the domain of rockstarconsistenttrees but i can relay my experiences consistenttrees corrects various issues relating the linking of ancestors and descendants but it can often change the properties of the halos one thing that might help is that the consistenttrees file should have a field called halo_id which is the id of the halo within the rockstar catalog you should be able to use this to then load that halo catalog and get its position from there not the best but i think itll work let me know if you want to talk this over some more
2019,user has joined the channel
2019,does anybody know if xray intensity fields are still supported in ytadd_xray_emissivity_field in addition to xray emissivity fields it used to also return xray_intensity_e_min_e_max_kev but no longer does has this functionality been moved elsewhere
2019,user
2019,user this only works if you provide a nonzero redshift
2019,but i think its always been that way
2019,hyperlink
2019,i see that makes sense in retrospect it only broke when i started using a z 0 output thanks
2019,in reality it probably makes sense to provide an option to set a distance so you can do this for an object that isnt necessarily cosmological
2019,but we dont have that yet
2019,is that module still supported i thought it had been removed
2019,i think youre thinking of the photon simulator which is now a separate package
2019,its now hyperlink
2019,but these xray emission fields are still in yt
2020,user has joined the channel
2020,in yt4x there seems to be a derived field for enzo codesnippet which doesnt exist in yt3x however in yt3x there is codesnippet which also exists in 4x interestingly the quantities arent equivalent to one another does anyone know what the difference in the two is
2020,for examplecodesnippetimport ytimport numpy as npds ytloadgalaxy0030ad dsall_dataprintnpsumadgas matter_massnpsumadgas masscodesnippetfor the yt example galaxy galaxy0030 results incodeblock
2020,codesnippet in yt3 is definitely gasparticles and im pretty sure codesnippet in yt4 is gas mass alias that would alias codesnippet in grid codes
2020,ah this makes sense thanks user
2020,no prob ok source code seems to confirm this too
2020,user has joined the channel
2019,i created a pull request for this hyperlink
2019,user has joined the channel
2018,user is correct you must manually integrate rays by multiplying the path length of each element of a ray codesnippet by the field in question and then summing
2018,oh theres also a unit conversion right because the sum of dts should be 10 regardless of the distance
2019,user has joined the channel
2019,im sure there are method to rotate a plot_2d but all i can find in the cookbook about that relates to 3d volume rendering could someone point me the right direction
2019,you mean to flip the x and y axes
2019,try this
2019,codesnippetdscoordinatesx_axis1 0dscoordinatesx_axisy 0dscoordinatesy_axis0 1dscoordinatesy_axisy 1codesnippet
2019,this comes up often enough we should make a cookbook recipe or something
2019,ah that actually answers another question i was wondering but here i mean an arbitrary angle rotation
2019,ie i would like to replot in a x y frame withx x cost y sinty x sint y cost
2020,hi all im working with an amrex dataset that has temperature pressure etc but no viscosity id like to use cantera through python to calculate viscosity as a derived field in yt however im running into the issue that codesnippet in cantera expects scalar values for t and p while i have these as fields in yt codesnippet etc which wants derived fields to work as ufuncs according to the documentation ive tried using codesnippet and codesnippet to pass in the t and p fields to cantera but am getting errors that look like codesnippet and codesnippet any advice on how to best accomplish this ive never tried something like this so im a little lost
2020,can you make a bug report on github
2020,please include a short script we can run to reproduce the error locally
2020,if you can make that script use one of the test datasets on hyperlink
2020,also the derived fields dont need to be ufuncs themselves
2020,fwiw
2020,i can probably provide a workaround if i have some code to look at
2020,user
2020,user yeah let me see if i can reproduce it with one of the test datasets and ill post some simplified code to github
2018,user has joined the channel
2020,thanks neutrinoceros and awesome name
2020,anytime smile
2020,it looks like codesnippet and codesnippet arent implemented for python3 yeti get a notimplemented error for the following code with python3 both yt 351 and 360 just installed 360 to check it on the bright side i still have yt 321 for python2 which works codesnippetcodesnippetcodesnippet codesnippetcodesnippet codesnippet
2020,is it possible to view the web documentation from an older version or would i need to read source code
2020,the docs from the main release versions are on the site eg hyperlink just replace it with xy if youre looking for a specific version
2019,user has joined the channel
